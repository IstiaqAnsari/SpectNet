{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_layers import Conv1D_zerophase_linear, Conv1D_linearphase, Conv1D_zerophase,\\\n",
    "    DCT1D, Conv1D_gammatone, Conv1D_linearphaseType, Attention\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Activation, AveragePooling1D, Add\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax\n",
    "import numpy as np\n",
    "import tables,h5py\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from ResultAnalyser import Result\n",
    "from utils import Confused_Crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agge 5 cilo \n"
     ]
    }
   ],
   "source": [
    "loadpath = None\n",
    "num_filt = (8, 4)\n",
    "num_dense = 20\n",
    "lr = 0.01\n",
    "bn_momentum = 0.99\n",
    "eps = 1.1e-5\n",
    "bias = False\n",
    "l2_reg = 0.04864911065093751\n",
    "l2_reg_dense = 0.\n",
    "kernel_size = 5\n",
    "print(\"Agge 5 cilo \")\n",
    "maxnorm = 10000.\n",
    "dropout_rate = 0.5\n",
    "dropout_rate_dense = 0.\n",
    "padding = 'valid'\n",
    "activation_function = 'relu'\n",
    "subsam = 2\n",
    "FIR_train= True\n",
    "trainable = True\n",
    "hp_lambda = np.float32(0)\n",
    "lr_decay =0.0001132885\n",
    "random_seed = 1\n",
    "num_class =2\n",
    "num_class_domain = 18\n",
    "tipe= 1\n",
    "decision = 'majority' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    return t\n",
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=2)\n",
    "\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heartnet(load_path,activation_function='relu', bn_momentum=0.99, bias=False, dropout_rate=0.5, dropout_rate_dense=0.0,\n",
    "             eps=1.1e-5, kernel_size=5, l2_reg=0.0, l2_reg_dense=0.0,lr=0.0012843784, lr_decay=0.0001132885, maxnorm=10000.,\n",
    "             padding='valid', random_seed=1, subsam=2, num_filt=(8, 4), num_dense=20,FIR_train=False,trainable=True,type=1,\n",
    "             num_class=2, num_class_domain=1,hp_lambda=0,batch_size=1024):\n",
    "    \n",
    "    #num_dense = 20 default \n",
    "    input = Input(shape=(2500, 1))\n",
    "\n",
    "    coeff_path = '../data/filterbankcoeff60.mat'\n",
    "    coeff = tables.open_file(coeff_path)\n",
    "    b1 = coeff.root.b1[:]\n",
    "    b1 = np.hstack(b1)\n",
    "    b1 = np.reshape(b1, [b1.shape[0], 1, 1])\n",
    "\n",
    "    b2 = coeff.root.b2[:]\n",
    "    b2 = np.hstack(b2)\n",
    "    b2 = np.reshape(b2, [b2.shape[0], 1, 1])\n",
    "\n",
    "    b3 = coeff.root.b3[:]\n",
    "    b3 = np.hstack(b3)\n",
    "    b3 = np.reshape(b3, [b3.shape[0], 1, 1])\n",
    "\n",
    "    b4 = coeff.root.b4[:]\n",
    "    b4 = np.hstack(b4)\n",
    "    b4 = np.reshape(b4, [b4.shape[0], 1, 1])\n",
    "\n",
    "    ## Conv1D_linearphase\n",
    "\n",
    "    # input1 = Conv1D_linearphase(1 ,61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b1[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "    # input2 = Conv1D_linearphase(1, 61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b2[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "    # input3 = Conv1D_linearphase(1, 61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b3[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "    # input4 = Conv1D_linearphase(1, 61, use_bias=False,\n",
    "    #                 # kernel_initializer=initializers.he_normal(random_seed),\n",
    "    #                 weights=[b4[30:]],\n",
    "    #                 padding='same',trainable=FIR_train)(input)\n",
    "\n",
    "    ## Conv1D_linearphase Anti-Symmetric\n",
    "    #\n",
    "    input1 = Conv1D_linearphaseType(1 ,60, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b1[31:]],\n",
    "                    padding='same',trainable=FIR_train, type = type)(input)\n",
    "    input2 = Conv1D_linearphaseType(1, 60, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b2[31:]],\n",
    "                    padding='same',trainable=FIR_train, type = type)(input)\n",
    "    input3 = Conv1D_linearphaseType(1, 60, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b3[31:]],\n",
    "                    padding='same',trainable=FIR_train, type = type)(input)\n",
    "    input4 = Conv1D_linearphaseType(1, 60, use_bias=False,\n",
    "                    # kernel_initializer=initializers.he_normal(random_seed),\n",
    "                    weights=[b4[31:]],\n",
    "                    padding='same',trainable=FIR_train, type = type)(input)\n",
    "    t1 = branch(input1,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t2 = branch(input2,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t3 = branch(input3,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t4 = branch(input4,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    #Conv1D_gammatone\n",
    "\n",
    "    # input1 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    # input2 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    # input3 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    # input4 = Conv1D_gammatone(kernel_size=81,filters=1,fsHz=1000,use_bias=False,padding='same')(input)\n",
    "    \n",
    "    xx = Concatenate(axis=-1)([t1,t2,t3,t4])\n",
    "    \n",
    "    xx = res_block(xx,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    xx = res_block(xx,64,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "    xx = res_block(xx,128,kernel_size,3,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    xx = res_block(xx,128,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "    xx = res_block(xx,256,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    xx = res_block(xx,256,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "    xx = res_block(xx,256,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=False)\n",
    "    xx = res_block(xx,256,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=False)\n",
    "    \n",
    "    xx = Conv1D(256, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=2,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(xx)\n",
    "    \n",
    "    merged = Flatten()(xx)\n",
    "    \n",
    "    dann_in = GradientReversal(hp_lambda=hp_lambda,name='grl')(merged)\n",
    "    dsc = Dense(50,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'domain_dense')(dann_in)   \n",
    "    dsc = Dense(num_class_domain, activation='softmax', name = \"domain\")(dsc)          \n",
    "    merged = Dense(num_dense,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(merged)\n",
    "    merged = Dense(num_class, activation='softmax', name=\"class\")(merged)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=[merged,dsc])\n",
    "    \n",
    "    if load_path:\n",
    "        model.load_weights(filepath=load_path, by_name=False)\n",
    "    \n",
    "    #if load_path:  # If path for loading model was specified\n",
    "    #model.load_weights(filepath='../../models_dbt_dann/fold_a_gt 2019-09-09 16:53:52.063276/weights.0041-0.6907.hdf5', by_name=True)\n",
    "    # models/fold_a_gt 2019-09-04 17:36:52.860817/weights.0200-0.7135.hdf5\n",
    "    \n",
    "    #if optim=='Adam':\n",
    "    #    opt = Adam(lr=lr, decay=lr_decay)\n",
    "    #else:  \n",
    "    opt = SGD(lr=lr,decay=lr_decay)\n",
    "    model.compile(optimizer=opt, loss={'class':'categorical_crossentropy','domain':'categorical_crossentropy'}, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    print(t.shape)\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling1D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad, output_shape=zeropad_output_shape)(p)\n",
    "    print(t.shape)\n",
    "    print(p.shape)\n",
    "    \n",
    "    t = Add()([t,p])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.333333333333332"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "52/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1248, 64)\n",
      "(?, 1248, 64)\n",
      "(?, 1248, 64)\n",
      "(?, 1248, 64)\n",
      "(?, 1248, 64)\n",
      "(?, 1248, 64)\n",
      "(?, 416, 128)\n",
      "(?, 416, 128)\n",
      "(?, 416, 128)\n",
      "(?, 416, 128)\n",
      "(?, 416, 128)\n",
      "(?, 416, 128)\n",
      "(?, 208, 256)\n",
      "(?, 208, 256)\n",
      "(?, 208, 256)\n",
      "(?, 208, 256)\n",
      "(?, 208, 256)\n",
      "(?, 208, 256)\n",
      "(?, 104, 256)\n",
      "(?, 104, 256)\n",
      "(?, 104, 256)\n",
      "(?, 52, 256)\n",
      "(?, 52, 256)\n",
      "(?, 52, 256)\n"
     ]
    }
   ],
   "source": [
    "model = heartnet(loadpath,activation_function, bn_momentum, bias, dropout_rate, dropout_rate_dense,\n",
    "                             eps, kernel_size, l2_reg, l2_reg_dense, lr, lr_decay, maxnorm,\n",
    "                             padding, random_seed, subsam, num_filt, num_dense, FIR_train, trainable, tipe,\n",
    "                             num_class=num_class,num_class_domain=9,hp_lambda=hp_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_41 (Con (None, 2500, 1)      30          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_42 (Con (None, 2500, 1)      30          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_43 (Con (None, 2500, 1)      30          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_44 (Con (None, 2500, 1)      30          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 2496, 8)      40          conv1d_linearphase_type_41[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 2496, 8)      40          conv1d_linearphase_type_42[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 2496, 8)      40          conv1d_linearphase_type_43[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 2496, 8)      40          conv1d_linearphase_type_44[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 2496, 8)      32          conv1d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 2496, 8)      32          conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 2496, 8)      32          conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 2496, 8)      32          conv1d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 2496, 8)      0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 2496, 8)      0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 2496, 8)      0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 2496, 8)      0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 2496, 8)      0           activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 2496, 8)      0           activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 2496, 8)      0           activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 2496, 8)      0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2496, 32)     0           dropout_131[0][0]                \n",
      "                                                                 dropout_132[0][0]                \n",
      "                                                                 dropout_133[0][0]                \n",
      "                                                                 dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 1248, 64)     10240       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 1248, 64)     256         conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 1248, 64)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 1248, 64)     0           activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_136 (Conv1D)             (None, 1248, 64)     20480       dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 1248, 64)     256         conv1d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 1248, 64)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1248, 32)     0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 1248, 64)     0           activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1248, 64)     0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 1248, 64)     0           dropout_136[0][0]                \n",
      "                                                                 lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_137 (Conv1D)             (None, 1248, 64)     20480       add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 1248, 64)     256         conv1d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 1248, 64)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 1248, 64)     0           activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_138 (Conv1D)             (None, 1248, 64)     20480       dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 1248, 64)     256         conv1d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 1248, 64)     0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 1248, 64)     0           activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 1248, 64)     0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 1248, 64)     0           dropout_138[0][0]                \n",
      "                                                                 max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_139 (Conv1D)             (None, 416, 128)     40960       add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 416, 128)     512         conv1d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 416, 128)     0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 416, 128)     0           activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 416, 128)     81920       dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 416, 128)     512         conv1d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 416, 128)     0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 416, 64)      0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 416, 128)     0           activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 416, 128)     0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 416, 128)     0           dropout_140[0][0]                \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 416, 128)     81920       add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 416, 128)     512         conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 416, 128)     0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 416, 128)     0           activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_142 (Conv1D)             (None, 416, 128)     81920       dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 416, 128)     512         conv1d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 416, 128)     0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 416, 128)     0           activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 416, 128)     0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 416, 128)     0           dropout_142[0][0]                \n",
      "                                                                 max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_143 (Conv1D)             (None, 208, 256)     163840      add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 208, 256)     1024        conv1d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 208, 256)     0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 208, 256)     0           activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_144 (Conv1D)             (None, 208, 256)     327680      dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 208, 256)     1024        conv1d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 208, 256)     0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 208, 128)     0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 208, 256)     0           activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 208, 256)     0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 208, 256)     0           dropout_144[0][0]                \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_145 (Conv1D)             (None, 208, 256)     327680      add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 208, 256)     1024        conv1d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 208, 256)     0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 208, 256)     0           activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 208, 256)     327680      dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 208, 256)     1024        conv1d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 208, 256)     0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 208, 256)     0           activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 208, 256)     0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 208, 256)     0           dropout_146[0][0]                \n",
      "                                                                 max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 104, 256)     327680      add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 104, 256)     1024        conv1d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 104, 256)     0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 104, 256)     0           activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 104, 256)     327680      dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 104, 256)     1024        conv1d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 104, 256)     0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 104, 256)     0           activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 104, 256)     0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 104, 256)     0           dropout_148[0][0]                \n",
      "                                                                 max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 52, 256)      327680      add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 52, 256)      1024        conv1d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 52, 256)      0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 52, 256)      0           activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 52, 256)      327680      dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 52, 256)      1024        conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 52, 256)      0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 52, 256)      0           activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 52, 256)      0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 52, 256)      0           dropout_150[0][0]                \n",
      "                                                                 max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 24, 256)      327680      add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 6144)         0           conv1d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "grl (GradientReversal)          (None, 6144)         0           flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "class_dense (Dense)             (None, 20)           122880      flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "domain_dense (Dense)            (None, 50)           307200      grl[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 2)            42          class_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "domain (Dense)                  (None, 9)            459         domain_dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,585,933\n",
      "Trainable params: 3,580,237\n",
      "Non-trainable params: 5,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model_test.png', show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_path = '../data/filterbankcoeff60.mat'\n",
    "coeff = tables.open_file(coeff_path)\n",
    "b1 = coeff.root.b1[:]\n",
    "b1 = np.hstack(b1)\n",
    "b1 = np.reshape(b1, [b1.shape[0], 1, 1])\n",
    "\n",
    "b2 = coeff.root.b2[:]\n",
    "b2 = np.hstack(b2)\n",
    "b2 = np.reshape(b2, [b2.shape[0], 1, 1])\n",
    "\n",
    "b3 = coeff.root.b3[:]\n",
    "b3 = np.hstack(b3)\n",
    "b3 = np.reshape(b3, [b3.shape[0], 1, 1])\n",
    "\n",
    "b4 = coeff.root.b4[:]\n",
    "b4 = np.hstack(b4)\n",
    "b4 = np.reshape(b4, [b4.shape[0], 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=../data/filterbankcoeff60.mat, title='', mode='r', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/N (Array(1, 1)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/b1 (Array(61, 1)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/b2 (Array(61, 1)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/b3 (Array(61, 1)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None\n",
       "/b4 (Array(61, 1)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3,760,013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def _bn_relu(layer, dropout=0, **params):\n",
    "    from keras.layers import BatchNormalization\n",
    "    from keras.layers import Activation\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation(params[\"conv_activation\"])(layer)\n",
    "\n",
    "    if dropout > 0:\n",
    "        from keras.layers import Dropout\n",
    "        layer = Dropout(params[\"conv_dropout\"])(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def add_conv_weight(\n",
    "        layer,\n",
    "        filter_length,\n",
    "        num_filters,\n",
    "        subsample_length=1,\n",
    "        **params):\n",
    "    from keras.layers import Conv1D \n",
    "    layer = Conv1D(\n",
    "        filters=num_filters,\n",
    "        kernel_size=filter_length,\n",
    "        strides=subsample_length,\n",
    "        padding='same',\n",
    "        kernel_initializer=params[\"conv_init\"])(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def add_conv_layers(layer, **params):\n",
    "    for subsample_length in params[\"conv_subsample_lengths\"]:\n",
    "        layer = add_conv_weight(\n",
    "                    layer,\n",
    "                    params[\"conv_filter_length\"],\n",
    "                    params[\"conv_num_filters_start\"],\n",
    "                    subsample_length=subsample_length,\n",
    "                    **params)\n",
    "        layer = _bn_relu(layer, **params)\n",
    "    return layer\n",
    "\n",
    "def resnet_block(\n",
    "        layer,\n",
    "        num_filters,\n",
    "        subsample_length,\n",
    "        block_index,\n",
    "        **params):\n",
    "    from keras.layers import Add \n",
    "    from keras.layers import MaxPooling1D\n",
    "    from keras.layers.core import Lambda\n",
    "\n",
    "    def zeropad(x):\n",
    "        y = K.zeros_like(x)\n",
    "        return K.concatenate([x, y], axis=2)\n",
    "\n",
    "    def zeropad_output_shape(input_shape):\n",
    "        shape = list(input_shape)\n",
    "        assert len(shape) == 3\n",
    "        shape[2] *= 2\n",
    "        return tuple(shape)\n",
    "\n",
    "    shortcut = MaxPooling1D(pool_size=subsample_length)(layer)\n",
    "    zero_pad = (block_index % params[\"conv_increase_channels_at\"]) == 0 \\\n",
    "        and block_index > 0\n",
    "    if zero_pad is True:\n",
    "        shortcut = Lambda(zeropad, output_shape=zeropad_output_shape)(shortcut)\n",
    "\n",
    "    for i in range(params[\"conv_num_skip\"]):\n",
    "        if not (block_index == 0 and i == 0):\n",
    "            layer = _bn_relu(\n",
    "                layer,\n",
    "                dropout=params[\"conv_dropout\"] if i > 0 else 0,\n",
    "                **params)\n",
    "        layer = add_conv_weight(\n",
    "            layer,\n",
    "            params[\"conv_filter_length\"],\n",
    "            num_filters,\n",
    "            subsample_length if i == 0 else 1,\n",
    "            **params)\n",
    "    layer = Add()([shortcut, layer])\n",
    "    return layer\n",
    "\n",
    "def get_num_filters_at_index(index, num_start_filters, **params):\n",
    "    return 2**int(index / params[\"conv_increase_channels_at\"]) \\\n",
    "        * num_start_filters\n",
    "\n",
    "def add_resnet_layers(layer, **params):\n",
    "    layer = add_conv_weight(\n",
    "        layer,\n",
    "        params[\"conv_filter_length\"],\n",
    "        params[\"conv_num_filters_start\"],\n",
    "        subsample_length=1,\n",
    "        **params)\n",
    "    layer = _bn_relu(layer, **params)\n",
    "    for index, subsample_length in enumerate(params[\"conv_subsample_lengths\"]):\n",
    "        num_filters = get_num_filters_at_index(\n",
    "            index, params[\"conv_num_filters_start\"], **params)\n",
    "        layer = resnet_block(\n",
    "            layer,\n",
    "            num_filters,\n",
    "            subsample_length,\n",
    "            index,\n",
    "            **params)\n",
    "    layer = _bn_relu(layer, **params)\n",
    "    return layer\n",
    "\n",
    "def add_output_layer(layer, **params):\n",
    "    from keras.layers.core import Dense, Activation\n",
    "    from keras.layers.wrappers import TimeDistributed\n",
    "    print(layer)\n",
    "    layer = TimeDistributed(Dense(params[\"num_categories\"]))(layer)\n",
    "    return Activation('softmax')(layer)\n",
    "def add_output_Flatten(layer,**params):\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers.core import Dense, Activation\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(params[\"num_categories\"])(layer)\n",
    "    return layer\n",
    "\n",
    "def add_compile(model, **params):\n",
    "    from keras.optimizers import Adam\n",
    "    optimizer = Adam(\n",
    "        lr=params[\"learning_rate\"],\n",
    "        clipnorm=params.get(\"clipnorm\", 1))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "def build_network(**params):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input\n",
    "    print(\"Hellow motherfucker\")\n",
    "    inputs = Input(shape=params['input_shape'],\n",
    "                   dtype='float32',\n",
    "                   name='inputs')\n",
    "\n",
    "    if params.get('is_regular_conv', False):\n",
    "        layer = add_conv_layers(inputs, **params)\n",
    "    else:\n",
    "        layer = add_resnet_layers(inputs, **params)\n",
    "\n",
    "    #output = add_output_layer(layer, **params)\n",
    "    output = add_output_Flatten(layer,**params)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    if params.get(\"compile\", True):\n",
    "        add_compile(model, **params)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"input_shape\":(256,1),\n",
    "    \"num_categories\":2,\n",
    "    \"conv_subsample_lengths\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    #\"conv_subsample_lengths\": [1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    \"conv_filter_length\": 16,\n",
    "    \"conv_num_filters_start\": 32,\n",
    "    \"conv_init\": \"he_normal\",\n",
    "    \"conv_activation\": \"relu\",\n",
    "    \"conv_dropout\": 0.2,\n",
    "    \"conv_num_skip\": 2,\n",
    "    \"conv_increase_channels_at\": 4,\n",
    "\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "\n",
    "    \"train\": \"examples/irhythm/train.json\",\n",
    "    \"dev\": \"examples/irhythm/dev.json\",\n",
    "    \"save_dir\": \"saved\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellow motherfucker\n"
     ]
    }
   ],
   "source": [
    "model = build_network(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 256, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 256, 32)      544         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 32)      128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 32)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 256, 32)      16416       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 32)      128         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 32)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 32)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 256, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 256, 32)      16416       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 32)      0           max_pooling1d_1[0][0]            \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 32)      128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 32)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 128, 32)      16416       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 32)      128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 32)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 32)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 128, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 128, 32)      16416       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 32)      0           max_pooling1d_2[0][0]            \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 32)      128         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 32)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 128, 32)      16416       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 32)      128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 32)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 32)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 128, 32)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 128, 32)      16416       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 32)      0           max_pooling1d_3[0][0]            \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 32)      128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 32)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 32)       16416       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 32)       128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 32)       0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 32)       0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 64, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 64, 32)       16416       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 32)       0           max_pooling1d_4[0][0]            \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 32)       128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 32)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 64, 64)       32832       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64)       256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 64, 32)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64, 64)       0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 64)       0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 64, 64)       65600       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64)       0           lambda_1[0][0]                   \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64)       256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64)       0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 32, 64)       65600       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 64)       256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 64)       0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 64)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 32, 64)       0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 32, 64)       65600       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 64)       0           max_pooling1d_6[0][0]            \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 64)       256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 64)       0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 32, 64)       65600       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 64)       256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 64)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 64)       0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 32, 64)       0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 32, 64)       65600       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 64)       0           max_pooling1d_7[0][0]            \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 64)       256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 64)       0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 16, 64)       65600       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 64)       256         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 64)       0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 64)       0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 16, 64)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 16, 64)       65600       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 64)       0           max_pooling1d_8[0][0]            \n",
      "                                                                 conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 64)       256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 64)       0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 16, 128)      131200      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 128)      512         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 128)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 16, 64)       0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 128)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16, 128)      0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 16, 128)      262272      dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 128)      0           lambda_2[0][0]                   \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 128)      512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 128)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 8, 128)       262272      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 128)       512         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 128)       0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 8, 128)       0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 8, 128)       0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 8, 128)       262272      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 128)       0           max_pooling1d_10[0][0]           \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 128)       512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 128)       0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 8, 128)       262272      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 128)       512         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 128)       0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 8, 128)       0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 8, 128)       0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 8, 128)       262272      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 128)       0           max_pooling1d_11[0][0]           \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 128)       512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 128)       0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 4, 128)       262272      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 128)       512         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 128)       0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 4, 128)       0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 4, 128)       0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 4, 128)       262272      dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 128)       0           max_pooling1d_12[0][0]           \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 128)       512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 128)       0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 4, 256)       524544      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 256)       1024        conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 256)       0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 4, 128)       0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 4, 256)       0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4, 256)       0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 4, 256)       1048832     dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 4, 256)       0           lambda_3[0][0]                   \n",
      "                                                                 conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 256)       1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 256)       0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 2, 256)       1048832     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2, 256)       1024        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 256)       0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 2, 256)       0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 2, 256)       0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 2, 256)       1048832     dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 256)       0           max_pooling1d_14[0][0]           \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 2, 256)       1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 256)       0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 2, 256)       1048832     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2, 256)       1024        conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 256)       0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 2, 256)       0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 2, 256)       0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 2, 256)       1048832     dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 256)       0           max_pooling1d_15[0][0]           \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 2, 256)       1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 256)       0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 1, 256)       1048832     activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 256)       1024        conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1, 256)       0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 1, 256)       0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 1, 256)       0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 1, 256)       1048832     dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 1, 256)       0           max_pooling1d_16[0][0]           \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1, 256)       1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1, 256)       0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            514         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,473,378\n",
      "Trainable params: 10,465,634\n",
      "Non-trainable params: 7,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model_Resnet.png', show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt,math\n",
    "import sys\n",
    "eps = sys.float_info.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p22 = (-12,12)\n",
    "p33 = (-12,-12)\n",
    "p44 = (12,-12)\n",
    "p11 = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = (0,0)\n",
    "p1 = (4,5)\n",
    "p2 = (12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(origin, point, angle=90):\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "    qx = ox + math.cos(math.radians(angle)) * (px - ox) - math.sin(math.radians(angle)) * (py - oy)\n",
    "    qy = oy + math.sin(math.radians(angle)) * (px - ox) + math.cos(math.radians(angle)) * (py - oy)\n",
    "    return qx, qy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXpoint(p1,p2,dist):\n",
    "    m = (p2[1]-p1[1])/(p2[0]-p1[0]+eps)\n",
    "    d = (math.atan(m))\n",
    "    if(p2[0]>p1[0]):\n",
    "        x = p1[0]+dist*math.cos(abs(d))\n",
    "    elif(p2[0]<p1[0]):\n",
    "        x = p1[0]-dist*math.cos(abs(d))\n",
    "    else: x = p1[0]\n",
    "    if(p2[1]>p1[1]):\n",
    "        y = p1[1]+dist*math.sin(abs(d))\n",
    "    elif(p2[1]<p1[1]):\n",
    "        y = p1[1]-dist*math.sin(abs(d))\n",
    "    else: y = p1[1]\n",
    "    return x,y\n",
    "def getX2point(p1,p2,p):\n",
    "    x = p2[0] + (p[0]-p1[0])\n",
    "    y = p2[1] + (p[1]-p1[1])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = (20,5)\n",
    "pout = rotate(p1,getXpoint(p1,p2,4))\n",
    "pout2 = getX2point(p1,p2,pout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [x for (x,y) in [p1,p2]]\n",
    "y = [y for (x,y) in [p1,p2]]\n",
    "x2 = [x for (x,y) in [pout,pout2]]\n",
    "y2 = [y for (x,y) in [pout,pout2]]\n",
    "D = 30\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot([-D,D],[0,0])\n",
    "plt.plot([0,0],[-D,D])\n",
    "plt.plot(x,y,'ro')\n",
    "plt.plot(x2,y2,'bo')\n",
    "plt.axis([-D, D, -D, D])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
