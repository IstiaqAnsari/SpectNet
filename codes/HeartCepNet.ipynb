{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from keras.initializers import Initializer\n",
    "from keras import backend as K\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.topology import InputSpec\n",
    "import tensorflow as tf,keras\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Input, MaxPooling1D,MaxPooling2D,Conv1D,Activation,Dense, activations, initializers,Conv2D\n",
    "from keras.layers import Flatten, regularizers,Reshape, constraints, Dropout,Multiply,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from keras.backend.common import normalize_data_format\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from custom_layers import Conv1D_gammatone, Conv1D_zerophase\n",
    "import scipy\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCC(Layer): \n",
    "    def __init__(self, rank,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 output_format='signal',\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(MFCC, self).__init__(**kwargs)\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n",
    "                                                      'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.output_format = output_format\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "    \n",
    "        \n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',trainable=False)\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = K.pow(K.abs(inputs),2)\n",
    "        outputs = K.conv1d(\n",
    "            outputs,\n",
    "            self.kernel,\n",
    "            strides=self.strides[0],\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format)\n",
    "        outputs = K.log(outputs)\n",
    "#         outputs = tf.signal.dct(outputs,type=2,axis=-1,norm='ortho')\n",
    "        if(self.output_format=='image'):\n",
    "            outputs = K.expand_dims(outputs,axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            if(self.output_format=='image'):\n",
    "                return (input_shape[0],) + tuple(new_space) + (self.filters,) + (1,)\n",
    "            else:\n",
    "                return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "            \n",
    "        if self.data_format == 'channels_first':\n",
    "            raise NotImplementedError(\"Output formate image/signal not handled\")\n",
    "            space = input_shape[2:]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format,\n",
    "            'output_format':self.output_format,\n",
    "            'kernel_initializer' : initializers.serialize(self.kernel_initializer)\n",
    "        }\n",
    "        base_config = super(MFCC, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_colormap(x):\n",
    "    import matplotlib._cm_listed as cmlist\n",
    "    cm = tf.convert_to_tensor(np.array(cmlist._viridis_data))\n",
    "    b = 255*(x-K.min(x))/(K.max(x)-K.min(x))\n",
    "    b = K.cast(b,dtype='int64')\n",
    "    wow = K.gather(cm,b)\n",
    "    return K.cast(wow,dtype='float32')\n",
    "def colormap_output_shape(input_shape):\n",
    "    return tuple( list(input_shape)+[3] )\n",
    "\n",
    "class TO_colormap(Layer):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super(TO_colormap, self).__init__(**kwargs)\n",
    "        import matplotlib._cm_listed as cmlist\n",
    "        self.cm = tf.convert_to_tensor(np.array(cmlist._viridis_data))\n",
    "        self.input_spec = InputSpec(min_ndim=3)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernelA = self.add_weight(name='kernelA',\n",
    "                                       shape=(input_shape[1], 3),\n",
    "                                       initializer='uniform')\n",
    "        \n",
    "        self.built = True\n",
    "        super(TO_colormap, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        b = 255*(x-K.min(x))/(K.max(x)-K.min(x))\n",
    "        b = K.cast(b,dtype='int64')\n",
    "        wow = K.gather(self.cm,b)\n",
    "        return K.cast(wow,dtype='float32')\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple( list(input_shape)+[3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mfcc_kernel_init(Initializer):\n",
    "#     def __init__(self):\n",
    "        \n",
    "    def __call__(self, shape, dtype=K.floatx()):\n",
    "        self.shape = shape\n",
    "        (kernel_size,in_channels,out_channels) = shape\n",
    "        if(in_channels!=out_channels):\n",
    "            raise ValueError(\"Input and Output Channels must be same. Got {0} input channels and {0} output channels\".format(in_channels,out_channels))\n",
    "        mat = K.eye(in_channels,dtype=dtype)\n",
    "        mat_n = [mat for i in range(kernel_size)]\n",
    "        return K.stack(mat_n)\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"shape\":self.shape\n",
    "        }\n",
    "# def mfcc_kernel_init(shape, dtype=K.floatx()):\n",
    "#     (kernel_size,in_channels,out_channels) = shape\n",
    "#     if(in_channels!=out_channels):\n",
    "#         raise ValueError(\"Input and Output Channels must be same. Got {0} input channels and {0} output channels\".format(in_channels,out_channels))\n",
    "#     mat = K.eye(in_channels,dtype=dtype)\n",
    "#     mat_n = [mat for i in range(kernel_size)]\n",
    "#     return K.stack(mat_n)\n",
    "class Freq_Init(Initializer):\n",
    "    def __init__(self, minf=0., maxf=500):\n",
    "        self.minf = minf\n",
    "        self.maxf = maxf\n",
    "    def __call__(self, shape, dtype=K.floatx()):\n",
    "        (kernel_size,in_channels) = shape\n",
    "        start = self.hz2mel(self.minf)\n",
    "        end = self.hz2mel(self.maxf)\n",
    "        n = ( end-start)/(kernel_size-1)\n",
    "        mel =  K.expand_dims(K.arange(start,end+1,n,dtype=dtype),axis=1)\n",
    "        return self.mel2hz(mel)\n",
    "    def hz2mel(self,hz):\n",
    "        return 2595 * (K.log(1.0+(hz*1.0)/700.)/K.log(10.0))\n",
    "    def mel2hz(self,mel):\n",
    "        return 700*(10**(mel/2595.0)-1)\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'minf': self.minf,\n",
    "            'maxf': self.maxf\n",
    "        }\n",
    "def hz2mel(hz):\n",
    "    return 2595 * np.log10(1+hz/700.)\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "def erb(f):\n",
    "    return 24.7*(4.37*10**-3*f+1)\n",
    "class beta_init(Initializer):\n",
    "    def __init__(self, val = 100):\n",
    "        self.val = val\n",
    "    def __call__(self,shape,dtype=K.floatx()):\n",
    "        (kernel_size,in_channels) = shape\n",
    "        beta_weights = tf.convert_to_tensor(np.ones((kernel_size,1))*self.val,dtype=K.floatx())\n",
    "        return beta_weights\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'val': self.val\n",
    "        }\n",
    "# def beta_init(shape, dtype=K.floatx()):\n",
    "#     (kernel_size,in_channels) = shape\n",
    "#     beta_weights = tf.convert_to_tensor(np.ones((kernel_size,1))*100,dtype=K.floatx())\n",
    "#     return beta_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(kernel_size=5,fs=1000,winlen=0.025,winstep=0.01,filters=26,random_seed=1,padding='valid',bias=False,\n",
    "           lr=0.0012843784,lr_decay=0.0001132885,subsam=2,num_filt=(26,32),num_dense=20,trainable=True,batch_size=1024,\n",
    "           l2_reg=0.0,l2_reg_dense=0.0,bn_momentum=0.99,dropout_rate=0.5,dropout_dense=0.0,eps = 1.1e-5,maxnorm=10000,\n",
    "           activation_function='relu'):\n",
    "    input = Input(shape=(2500, 1))\n",
    "    t = Conv1D_gammatone(kernel_size=81, strides=1,filters=filters,\n",
    "                         fsHz=fs,use_bias=False,padding='same',\n",
    "                         fc_initializer=Freq_Init(minf=50.0,maxf=fs/2),\n",
    "                         amp_initializer=initializers.constant(10**4),\n",
    "                        beta_initializer=beta_init(val=100),name=\"gamma\"\n",
    "                        )(input)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = MFCC(rank = 1,filters=filters,kernel_size=int(winlen*fs),output_format='signal',strides=int(winstep*fs),\n",
    "              kernel_initializer = mfcc_kernel_init(), name=\"mfcc\")(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    \n",
    "    t = branch(t,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    t = res_block(t,32,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    t = res_block(t,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(20,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(t)\n",
    "    t = Dense(2, activation='softmax', name=\"class\")(t)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=5\n",
    "fs=2000\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "filters=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gamma (Conv1D_gammatone)        (None, 2500, 26)     79          input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2500, 26)     104         gamma[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mfcc (MFCC)                     (None, 123, 26)      33800       batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 123, 26)      104         mfcc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 119, 26)      3380        batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 119, 26)      104         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 119, 26)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 119, 26)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 115, 32)      4160        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 115, 32)      128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 115, 32)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 115, 32)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 115, 32)      5120        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 115, 32)      128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 115, 32)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 115, 32)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 115, 32)      5120        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 115, 32)      128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 115, 32)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 115, 32)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 115, 32)      0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 115, 32)      0           dropout_10[0][0]                 \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 58, 64)       10240       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 58, 64)       256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 58, 64)       0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 58, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 58, 64)       20480       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 58, 64)       256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 58, 64)       0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 58, 64)       0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 57, 32)       0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 57, 64)       0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 57, 64)       0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 57, 64)       0           lambda_4[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 3648)         0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "class_dense (Dense)             (None, 20)           72960       flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 2)            42          class_dense[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 156,589\n",
      "Trainable params: 122,184\n",
      "Non-trainable params: 34,405\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Network(kernel_size,fs,winlen,winstep,filters)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6331a8e5dd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mfcc_res.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='mfcc_res.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad_len(x):\n",
    "    return x[:,:-1,:]\n",
    "def zeropad_len_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[1] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=2)\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)\n",
    "def res_block(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling1D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad, output_shape=zeropad_output_shape)(p)\n",
    "        if(t.shape[1]!=p.shape):\n",
    "            t = Lambda(zeropad_len, output_shape=zeropad_len_output_shape)(t)\n",
    "\n",
    "    t = Add()([t,p])\n",
    "    return t\n",
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt2, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad_len_Ax1(x):\n",
    "    print(x.shape)\n",
    "    return x[:,:-1,:,:]\n",
    "def zeropad_len_Ax2(x):\n",
    "    return x[:,:,:-1,:]\n",
    "def zeropad_len_output_shape_Ax1(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4\n",
    "    shape[1] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad_len_output_shape_Ax2(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4\n",
    "    shape[2] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad2d(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=3)\n",
    "def zeropad_output_shape2d(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4\n",
    "    shape[-1] *= 2\n",
    "    return tuple(shape)\n",
    "def branch2d(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "    \n",
    "    pad1,pad2 = padding\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv2D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=pad1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv2D(num_filt2, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=pad2,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    return t\n",
    "def res_block2d(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv2D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv2D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling2D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad2d, output_shape=zeropad_output_shape2d)(p)\n",
    "#         print(\"T\", t.shape, \"P\", p.shape)\n",
    "        if(t.shape[1]!=p.shape[1]):\n",
    "            t = Lambda(zeropad_len_Ax1, output_shape=zeropad_len_output_shape_Ax1)(t)\n",
    "        if(t.shape[2]!=p.shape[2]):\n",
    "            t = Lambda(zeropad_len_Ax2, output_shape=zeropad_len_output_shape_Ax2)(t)\n",
    "#         print(\"T\", t.shape, \"P\", p.shape, \"PORe\")\n",
    "    t = Add()([t,p])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Network2D(kernel_size=5,fs=1000,winlen=0.025,winstep=0.01,filters=26,random_seed=1,padding='valid',bias=False,\n",
    "           lr=0.0012843784,lr_decay=0.0001132885,subsam=2,num_filt=(16,32),num_dense=20,trainable=True,batch_size=1024,\n",
    "           l2_reg=0.0,l2_reg_dense=0.0,bn_momentum=0.99,dropout_rate=0.5,dropout_dense=0.0,eps = 1.1e-5,maxnorm=10000,\n",
    "           activation_function='relu'):\n",
    "    input = Input(shape=(2500, 1))\n",
    "    \n",
    "#     t = Conv1D(26, kernel_size=5,\n",
    "#                 kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "#                 padding='same',\n",
    "#                 use_bias=bias,\n",
    "#                 kernel_constraint=max_norm(maxnorm),\n",
    "#                 trainable=trainable,\n",
    "#                 kernel_regularizer=l2(l2_reg))(input)\n",
    "    \n",
    "    \n",
    "    t = Conv1D_gammatone(kernel_size=81,strides=1,filters=filters,\n",
    "                         fsHz=fs,use_bias=False,padding='same',\n",
    "                         fc_initializer=Freq_Init(minf=50.0,maxf=fs/2),\n",
    "                         amp_initializer=initializers.constant(10**4),\n",
    "                        beta_initializer=beta_init(val=100),name=\"gamma\"\n",
    "                        )(input)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = MFCC(rank = 1,filters=filters,kernel_size=int(winlen*fs),output_format='signal',strides=int(winstep*fs),\n",
    "              kernel_initializer = mfcc_kernel_init(), name=\"mfcc\")(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Reshape(target_shape=(-1,filters,1))(t)\n",
    "    t = Conv2D(32, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding='valid',\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "#     t = branch2d(t,num_filt,kernel_size,random_seed,('valid','valid'),bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = MaxPooling2D((2,1))(t)\n",
    "#     t = branch2d(t,(32,64),(kernel_size,3),random_seed,('valid','valid'),bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = MaxPooling2D((2,1))(t)\n",
    "#     t = branch2d(t,(64,128),kernel_size,random_seed,('valid','valid'),bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = MaxPooling2D((2,1))(t)\n",
    "#     t = branch2d(t,(128,256),kernel_size,random_seed,('same','same'),bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = res_block2d(t,32,5,1,'valid',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "#     t = res_block2d(t,64,5,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "#     t = res_block2d(t,128,5,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = MaxPooling2D((2,1))(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(20,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(t)\n",
    "    t = Dense(2, activation='softmax', name=\"class\")(t)\n",
    "    opt = Adam(lr=.001,decay=.001,epsilon=eps)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2500, 1)           0         \n",
      "_________________________________________________________________\n",
      "gamma (Conv1D_gammatone)     (None, 2500, 26)          79        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2500, 26)          104       \n",
      "_________________________________________________________________\n",
      "mfcc (MFCC)                  (None, 123, 26)           33800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 123, 26)           104       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 123, 26, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 119, 22, 32)       800       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 83776)             0         \n",
      "_________________________________________________________________\n",
      "class_dense (Dense)          (None, 20)                1675520   \n",
      "_________________________________________________________________\n",
      "class (Dense)                (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 1,710,449\n",
      "Trainable params: 1,676,544\n",
      "Non-trainable params: 33,905\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from HeartCepNet import heartnet2D as Network2D\n",
    "kernel_size=5\n",
    "fs=2000\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "filters=26\n",
    "# model = heartnet2D(kernel_size,fs,winlen,winstep,filters)\n",
    "model = Network2D(kernel_size,fs,winlen,winstep,filters)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='mfcc_res2D.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mfcc',\n",
       " 'trainable': True,\n",
       " 'rank': 1,\n",
       " 'filters': 26,\n",
       " 'kernel_size': (50,),\n",
       " 'strides': (20,),\n",
       " 'padding': 'valid',\n",
       " 'data_format': 'channels_last',\n",
       " 'output_format': 'signal',\n",
       " 'kernel_initializer': {'class_name': 'mfcc_kernel_init',\n",
       "  'config': {'shape': (50, 26, 26)}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('gamma').get_config()\n",
    "json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2500, 1), (100, 2))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(100,2500,1)\n",
    "y = np.ones((100,1))\n",
    "y = to_categorical(y)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "checkpoint_name = \"kophobe/\" + 'weights.{epoch:04d}-{acc:.4f}.hdf5'\n",
    "modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                                            monitor='acc',save_best_only=False, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 2.0548 - acc: 0.6700\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.9834 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.8869 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.9321 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.8066 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 318us/step - loss: 0.8059 - acc: 0.9500\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.8059 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.8059 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.8059 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.8059 - acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f493b671a90>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=10,callbacks=[modelcheckpnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'gamma',\n",
       " 'trainable': True,\n",
       " 'rank': 1,\n",
       " 'filters': 26,\n",
       " 'kernel_size': 81,\n",
       " 'strides': (1,),\n",
       " 'padding': 'same',\n",
       " 'data_format': 'channels_last',\n",
       " 'dilation_rate': (1,),\n",
       " 'activation': 'linear',\n",
       " 'use_bias': False,\n",
       " 'fsHz': 2000,\n",
       " 'fc_initializer': {'class_name': 'Freq_Init',\n",
       "  'config': {'minf': 50.0, 'maxf': 1000.0}},\n",
       " 'n_order_initializer': {'class_name': 'Constant', 'config': {'value': 4.0}},\n",
       " 'amp_initializer': {'class_name': 'Constant', 'config': {'value': 10000}},\n",
       " 'beta_initializer': {'class_name': 'beta_init', 'config': {'val': 100}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('gamma').get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 49.99713 ],\n",
       "        [ 74.963776],\n",
       "        [100.74481 ],\n",
       "        [127.385704],\n",
       "        [154.90889 ],\n",
       "        [183.35715 ],\n",
       "        [212.74887 ],\n",
       "        [243.1247  ],\n",
       "        [274.50607 ],\n",
       "        [306.9366  ],\n",
       "        [340.44635 ],\n",
       "        [375.0635  ],\n",
       "        [410.83527 ],\n",
       "        [447.79825 ],\n",
       "        [485.99066 ],\n",
       "        [525.4497  ],\n",
       "        [566.2174  ],\n",
       "        [608.3448  ],\n",
       "        [651.88324 ],\n",
       "        [696.8601  ],\n",
       "        [743.35284 ],\n",
       "        [791.3709  ],\n",
       "        [840.995   ],\n",
       "        [892.27625 ],\n",
       "        [945.25085 ],\n",
       "        [999.9997  ]], dtype=float32), array([[10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.],\n",
       "        [10000.]], dtype=float32), array([[100.002304],\n",
       "        [100.00532 ],\n",
       "        [100.00802 ],\n",
       "        [100.010635],\n",
       "        [100.00658 ],\n",
       "        [ 99.99929 ],\n",
       "        [100.00703 ],\n",
       "        [100.002045],\n",
       "        [100.00634 ],\n",
       "        [100.0082  ],\n",
       "        [100.00458 ],\n",
       "        [ 99.9945  ],\n",
       "        [100.00159 ],\n",
       "        [100.009476],\n",
       "        [ 99.99923 ],\n",
       "        [ 99.99807 ],\n",
       "        [ 99.99646 ],\n",
       "        [ 99.995415],\n",
       "        [100.0047  ],\n",
       "        [ 99.99927 ],\n",
       "        [100.003624],\n",
       "        [100.00308 ],\n",
       "        [100.006195],\n",
       "        [100.00725 ],\n",
       "        [ 99.99604 ],\n",
       "        [100.00073 ]], dtype=float32), array([[4.]], dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
