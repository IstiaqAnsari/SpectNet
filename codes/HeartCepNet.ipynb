{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from keras import backend as K\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.topology import InputSpec\n",
    "import tensorflow as tf,keras\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Input, MaxPooling1D ,Conv1D,Activation,Dense, activations, initializers,Conv2D\n",
    "from keras.layers import Flatten, regularizers, constraints, Lambda,Dropout,Multiply,Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from keras.backend.common import normalize_data_format\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from custom_layers import Conv1D_gammatone, Conv1D_zerophase\n",
    "import scipy\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCC(Layer): \n",
    "    def __init__(self, rank,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(MFCC, self).__init__(**kwargs)\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n",
    "                                                      'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "    \n",
    "        \n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',trainable=False)\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = K.pow(K.abs(inputs),2)\n",
    "        outputs = K.conv1d(\n",
    "            outputs,\n",
    "            self.kernel,\n",
    "            strides=self.strides[0],\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format)\n",
    "        outputs = K.log(outputs)\n",
    "#         outputs = tf.signal.dct(outputs,type=2,axis=-1,norm='ortho')\n",
    "        \n",
    "        \n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "        if self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format\n",
    "        }\n",
    "        base_config = super(_Conv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_kernel_init(shape, dtype=K.floatx()):\n",
    "    (kernel_size,in_channels,out_channels) = shape\n",
    "    if(in_channels!=out_channels):\n",
    "        raise ValueError(\"Input and Output Channels must be same. Got {0} input channels and {0} output channels\".format(in_channels,out_channels))\n",
    "    mat = K.eye(in_channels,dtype=dtype)\n",
    "    mat_n = [mat for i in range(kernel_size)]\n",
    "    return K.stack(mat_n)\n",
    "def freq_init(shape,dtype=K.floatx(),minf=0,maxf=500,filters=26):\n",
    "    return K.expand_dims(K.arange(minf,hz2mel(maxf)+1,(hz2mel(maxf))/(filters-1),dtype=dtype),axis=1)\n",
    "def hz2mel(hz):\n",
    "    return 2595 * np.log10(1+hz/700.)\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "def erb(f):\n",
    "    return 24.7*(4.37*10**-3*f+1)\n",
    "def beta_init(shape, dtype=K.floatx()):\n",
    "    beta_weights = erb(freq_init((filters,1),minf=0,maxf=500,filters=26))\n",
    "    return beta_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(kernel_size=5,fs=1000,winlen=0.025,winstep=0.01,filters=26,random_seed=1,padding='valid',bias=False,\n",
    "           lr=0.0012843784,lr_decay=0.0001132885,subsam=2,num_filt=(26,32),num_dense=20,trainable=True,batch_size=1024,\n",
    "           l2_reg=0.0,l2_reg_dense=0.0,bn_momentum=0.99,dropout_rate=0.5,dropout_dense=0.0,eps = 1.1e-5,maxnorm=10000,\n",
    "           activation_function='relu'):\n",
    "    input = Input(shape=(2500, 1))\n",
    "    t = Conv1D_gammatone(kernel_size=81,strides=1,filters=filters,\n",
    "                         fsHz=fs,use_bias=False,padding='same',\n",
    "                         fc_initializer=freq_init,\n",
    "                         amp_initializer=initializers.constant(10**4),\n",
    "                        beta_initializer=beta_init,name=\"gamma\"\n",
    "                        )(input)\n",
    "    t = MFCC(rank = 1,filters=filters,kernel_size=int(winlen*fs),strides=int(winstep*fs),\n",
    "              kernel_initializer = mfcc_kernel_init, name=\"mfcc\")(t)\n",
    "    t = branch(t,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    t = res_block(t,32,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    t = res_block(t,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(20,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(t)\n",
    "    t = Dense(2, activation='softmax', name=\"class\")(t)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=5\n",
    "fs=2000\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "filters=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_83 (InputLayer)           (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gamma (Conv1D_gammatone)        (None, 2500, 26)     79          input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mfcc (MFCC)                     (None, 123, 26)      33800       gamma[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_338 (Conv1D)             (None, 119, 26)      3380        mfcc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 119, 26)      104         conv1d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 119, 26)      0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_332 (Dropout)           (None, 119, 26)      0           activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_339 (Conv1D)             (None, 115, 32)      4160        dropout_332[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 115, 32)      128         conv1d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 115, 32)      0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_333 (Dropout)           (None, 115, 32)      0           activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_340 (Conv1D)             (None, 115, 32)      5120        dropout_333[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 115, 32)      128         conv1d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 115, 32)      0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_334 (Dropout)           (None, 115, 32)      0           activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_341 (Conv1D)             (None, 115, 32)      5120        dropout_334[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 115, 32)      128         conv1d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 115, 32)      0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_335 (Dropout)           (None, 115, 32)      0           activation_335[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling1D) (None, 115, 32)      0           dropout_333[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 115, 32)      0           dropout_335[0][0]                \n",
      "                                                                 max_pooling1d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_342 (Conv1D)             (None, 58, 64)       10240       add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 58, 64)       256         conv1d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 58, 64)       0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_336 (Dropout)           (None, 58, 64)       0           activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_343 (Conv1D)             (None, 58, 64)       20480       dropout_336[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 58, 64)       256         conv1d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 58, 64)       0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_337 (Dropout)           (None, 58, 64)       0           activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling1D) (None, 57, 32)       0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 57, 64)       0           dropout_337[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 57, 64)       0           max_pooling1d_98[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 57, 64)       0           lambda_82[0][0]                  \n",
      "                                                                 lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 3648)         0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "class_dense (Dense)             (None, 20)           72960       flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 2)            42          class_dense[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 156,381\n",
      "Trainable params: 122,081\n",
      "Non-trainable params: 34,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Network(kernel_size,fs,winlen,winstep,filters)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='mfcc_res.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad_len(x):\n",
    "    return x[:,:-1,:]\n",
    "def zeropad_len_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[1] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=2)\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)\n",
    "def res_block(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling1D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad, output_shape=zeropad_output_shape)(p)\n",
    "        if(t.shape[1]!=p.shape):\n",
    "            t = Lambda(zeropad_len, output_shape=zeropad_len_output_shape)(t)\n",
    "\n",
    "    t = Add()([t,p])\n",
    "    return t\n",
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt2, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
