{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from keras.initializers import Initializer\n",
    "from keras import backend as K\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.topology import InputSpec\n",
    "import tensorflow as tf,keras\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Input, MaxPooling1D,MaxPooling2D,Conv1D,Activation,Dense, activations, initializers,Conv2D\n",
    "from keras.layers import Flatten, regularizers,Reshape, constraints, Dropout,Multiply,Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from keras.backend.common import normalize_data_format\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from custom_layers import Conv1D_gammatone, Conv1D_zerophase\n",
    "import scipy\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCC(Layer): \n",
    "    def __init__(self, rank,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 output_format='signal',\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(MFCC, self).__init__(**kwargs)\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n",
    "                                                      'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.output_format = output_format\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "    \n",
    "        \n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',trainable=False)\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = K.pow(K.abs(inputs),2)\n",
    "        outputs = K.conv1d(\n",
    "            outputs,\n",
    "            self.kernel,\n",
    "            strides=self.strides[0],\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format)\n",
    "        outputs = K.log(outputs)\n",
    "#         outputs = tf.signal.dct(outputs,type=2,axis=-1,norm='ortho')\n",
    "        if(self.output_format=='image'):\n",
    "            outputs = K.expand_dims(outputs,axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            if(self.output_format=='image'):\n",
    "                return (input_shape[0],) + tuple(new_space) + (self.filters,) + (1,)\n",
    "            else:\n",
    "                return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "            \n",
    "        if self.data_format == 'channels_first':\n",
    "            raise NotImplementedError(\"Output formate image/signal not handled\")\n",
    "            space = input_shape[2:]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format\n",
    "        }\n",
    "        base_config = super(_Conv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_colormap(x):\n",
    "    import matplotlib._cm_listed as cmlist\n",
    "    cm = tf.convert_to_tensor(np.array(cmlist._viridis_data))\n",
    "    b = 255*(x-K.min(x))/(K.max(x)-K.min(x))\n",
    "    b = K.cast(b,dtype='int64')\n",
    "    wow = K.gather(cm,b)\n",
    "    return K.cast(wow,dtype='float32')\n",
    "def colormap_output_shape(input_shape):\n",
    "    return tuple( list(input_shape)+[3] )\n",
    "\n",
    "class TO_colormap(Layer):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super(TO_colormap, self).__init__(**kwargs)\n",
    "        import matplotlib._cm_listed as cmlist\n",
    "        self.cm = tf.convert_to_tensor(np.array(cmlist._viridis_data))\n",
    "        self.input_spec = InputSpec(min_ndim=3)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernelA = self.add_weight(name='kernelA',\n",
    "                                       shape=(input_shape[1], 3),\n",
    "                                       initializer='uniform')\n",
    "        \n",
    "        self.built = True\n",
    "        super(TO_colormap, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        b = 255*(x-K.min(x))/(K.max(x)-K.min(x))\n",
    "        b = K.cast(b,dtype='int64')\n",
    "        wow = K.gather(self.cm,b)\n",
    "        return K.cast(wow,dtype='float32')\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple( list(input_shape)+[3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_kernel_init(shape, dtype=K.floatx()):\n",
    "    (kernel_size,in_channels,out_channels) = shape\n",
    "    if(in_channels!=out_channels):\n",
    "        raise ValueError(\"Input and Output Channels must be same. Got {0} input channels and {0} output channels\".format(in_channels,out_channels))\n",
    "    mat = K.eye(in_channels,dtype=dtype)\n",
    "    mat_n = [mat for i in range(kernel_size)]\n",
    "    return K.stack(mat_n)\n",
    "class Freq_Init(Initializer):\n",
    "    def __init__(self, minf=0., maxf=500):\n",
    "        self.minf = minf\n",
    "        self.maxf = maxf\n",
    "    def __call__(self, shape, dtype=K.floatx()):\n",
    "        (kernel_size,in_channels) = shape\n",
    "        start = self.hz2mel(self.minf)\n",
    "        end = self.hz2mel(self.maxf)\n",
    "        n = ( end-start)/(kernel_size-1)\n",
    "        mel =  K.expand_dims(K.arange(start,end+1,n,dtype=dtype),axis=1)\n",
    "        return self.mel2hz(mel)\n",
    "    def hz2mel(self,hz):\n",
    "        return 2595 * (K.log(1.0+(hz*1.0)/700.)/K.log(10.0))\n",
    "    def mel2hz(self,mel):\n",
    "        return 700*(10**(mel/2595.0)-1)\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'minf': self.minf,\n",
    "            'maxf': self.maxf\n",
    "        }\n",
    "def hz2mel(hz):\n",
    "    return 2595 * np.log10(1+hz/700.)\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "def erb(f):\n",
    "    return 24.7*(4.37*10**-3*f+1)\n",
    "def beta_init(shape, dtype=K.floatx()):\n",
    "    (kernel_size,in_channels) = shape\n",
    "    beta_weights = tf.convert_to_tensor(np.ones((kernel_size,1))*100,dtype=K.floatx())\n",
    "    return beta_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(kernel_size=5,fs=1000,winlen=0.025,winstep=0.01,filters=26,random_seed=1,padding='valid',bias=False,\n",
    "           lr=0.0012843784,lr_decay=0.0001132885,subsam=2,num_filt=(26,32),num_dense=20,trainable=True,batch_size=1024,\n",
    "           l2_reg=0.0,l2_reg_dense=0.0,bn_momentum=0.99,dropout_rate=0.5,dropout_dense=0.0,eps = 1.1e-5,maxnorm=10000,\n",
    "           activation_function='relu'):\n",
    "    input = Input(shape=(2500, 1))\n",
    "    t = Conv1D_gammatone(kernel_size=81, strides=1,filters=filters,\n",
    "                         fsHz=fs,use_bias=False,padding='same',\n",
    "                         fc_initializer=Freq_Init(minf=50.0,maxf=fs/2),\n",
    "                         amp_initializer=initializers.constant(10**4),\n",
    "                        beta_initializer=beta_init,name=\"gamma\"\n",
    "                        )(input)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = MFCC(rank = 1,filters=filters,kernel_size=int(winlen*fs),output_format='signal',strides=int(winstep*fs),\n",
    "              kernel_initializer = mfcc_kernel_init, name=\"mfcc\")(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    \n",
    "    t = branch(t,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    t = res_block(t,32,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    t = res_block(t,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(20,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(t)\n",
    "    t = Dense(2, activation='softmax', name=\"class\")(t)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=5\n",
    "fs=2000\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "filters=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gamma (Conv1D_gammatone)        (None, 2500, 26)     79          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mfcc (MFCC)                     (None, 123, 26)      33800       gamma[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 119, 26)      3380        mfcc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 119, 26)      104         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 119, 26)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 119, 26)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 115, 32)      4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 115, 32)      128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 115, 32)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 115, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 115, 32)      5120        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 115, 32)      128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 115, 32)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 115, 32)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 115, 32)      5120        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 115, 32)      128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 115, 32)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 115, 32)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 115, 32)      0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 115, 32)      0           dropout_4[0][0]                  \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 58, 64)       10240       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 58, 64)       256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 58, 64)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 58, 64)       0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 58, 64)       20480       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 58, 64)       256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 58, 64)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 58, 64)       0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 57, 32)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 57, 64)       0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 57, 64)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 57, 64)       0           lambda_2[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3648)         0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "class_dense (Dense)             (None, 20)           72960       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 2)            42          class_dense[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 156,381\n",
      "Trainable params: 122,081\n",
      "Non-trainable params: 34,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Network(kernel_size,fs,winlen,winstep,filters)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6331a8e5dd22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mfcc_res.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='mfcc_res.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad_len(x):\n",
    "    return x[:,:-1,:]\n",
    "def zeropad_len_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[1] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=2)\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)\n",
    "def res_block(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling1D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad, output_shape=zeropad_output_shape)(p)\n",
    "        if(t.shape[1]!=p.shape):\n",
    "            t = Lambda(zeropad_len, output_shape=zeropad_len_output_shape)(t)\n",
    "\n",
    "    t = Add()([t,p])\n",
    "    return t\n",
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt2, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad_len_Ax1(x):\n",
    "    print(x.shape)\n",
    "    return x[:,:-1,:,:]\n",
    "def zeropad_len_Ax2(x):\n",
    "    return x[:,:,:-1,:]\n",
    "def zeropad_len_output_shape_Ax1(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4\n",
    "    shape[1] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad_len_output_shape_Ax2(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4\n",
    "    shape[2] -= 1\n",
    "    return tuple(shape)\n",
    "def zeropad2d(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=3)\n",
    "def zeropad_output_shape2d(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 4\n",
    "    shape[-1] *= 2\n",
    "    return tuple(shape)\n",
    "def branch2d(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "    \n",
    "    pad1,pad2 = padding\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv2D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=pad1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv2D(num_filt2, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=pad2,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    return t\n",
    "def res_block2d(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv2D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv2D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling2D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad2d, output_shape=zeropad_output_shape2d)(p)\n",
    "#         print(\"T\", t.shape, \"P\", p.shape)\n",
    "        if(t.shape[1]!=p.shape[1]):\n",
    "            t = Lambda(zeropad_len_Ax1, output_shape=zeropad_len_output_shape_Ax1)(t)\n",
    "        if(t.shape[2]!=p.shape[2]):\n",
    "            t = Lambda(zeropad_len_Ax2, output_shape=zeropad_len_output_shape_Ax2)(t)\n",
    "#         print(\"T\", t.shape, \"P\", p.shape, \"PORe\")\n",
    "    t = Add()([t,p])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Reshape in module keras.layers.core:\n",
      "\n",
      "class Reshape(keras.engine.base_layer.Layer)\n",
      " |  Reshape(target_shape, **kwargs)\n",
      " |  \n",
      " |  Reshapes an output to a certain shape.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      target_shape: target shape. Tuple of integers.\n",
      " |          Does not include the batch axis.\n",
      " |  \n",
      " |  # Input shape\n",
      " |      Arbitrary, although all dimensions in the input shaped must be fixed.\n",
      " |      Use the keyword argument `input_shape`\n",
      " |      (tuple of integers, does not include the batch axis)\n",
      " |      when using this layer as the first layer in a model.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      `(batch_size,) + target_shape`\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |  ```python\n",
      " |      # as first layer in a Sequential model\n",
      " |      model = Sequential()\n",
      " |      model.add(Reshape((3, 4), input_shape=(12,)))\n",
      " |      # now: model.output_shape == (None, 3, 4)\n",
      " |      # note: `None` is the batch dimension\n",
      " |  \n",
      " |      # as intermediate layer in a Sequential model\n",
      " |      model.add(Reshape((6, 2)))\n",
      " |      # now: model.output_shape == (None, 6, 2)\n",
      " |  \n",
      " |      # also supports shape inference using `-1` as dimension\n",
      " |      model.add(Reshape((-1, 2, 2)))\n",
      " |      # now: model.output_shape == (None, 3, 2, 2)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Reshape\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, target_shape, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Network2D(kernel_size=5,fs=1000,winlen=0.025,winstep=0.01,filters=26,random_seed=1,padding='valid',bias=False,\n",
    "           lr=0.0012843784,lr_decay=0.0001132885,subsam=2,num_filt=(16,32),num_dense=20,trainable=True,batch_size=1024,\n",
    "           l2_reg=0.0,l2_reg_dense=0.0,bn_momentum=0.99,dropout_rate=0.5,dropout_dense=0.0,eps = 1.1e-5,maxnorm=10000,\n",
    "           activation_function='relu'):\n",
    "    input = Input(shape=(2500, 1))\n",
    "    t = Conv1D_gammatone(kernel_size=81,strides=1,filters=filters,\n",
    "                         fsHz=fs,use_bias=False,padding='same',\n",
    "                         fc_initializer=Freq_Init(minf=50.0,maxf=fs/2),\n",
    "                         amp_initializer=initializers.constant(10**4),\n",
    "                        beta_initializer=beta_init,name=\"gamma\"\n",
    "                        )(input)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = MFCC(rank = 1,filters=filters,kernel_size=int(winlen*fs),output_format='signal',strides=int(winstep*fs),\n",
    "              kernel_initializer = mfcc_kernel_init, name=\"mfcc\")(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Reshape(target_shape=(-1,filters,1))(t)\n",
    "#     t = Lambda(to_colormap,output_shape = colormap_output_shape)(t)\n",
    "#     t = TO_colormap()(t)\n",
    "    t = branch2d(t,num_filt,kernel_size,random_seed,('valid','valid'),bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = MaxPooling2D((2,1))(t)\n",
    "    t = branch2d(t,(32,64),(kernel_size,3),random_seed,('valid','valid'),bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = MaxPooling2D((2,1))(t)\n",
    "    t = branch2d(t,(64,128),kernel_size,random_seed,('valid','valid'),bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = MaxPooling2D((2,1))(t)\n",
    "    t = branch2d(t,(128,256),kernel_size,random_seed,('same','same'),bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = res_block2d(t,32,5,1,'valid',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "#     t = res_block2d(t,64,5,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "#     t = res_block2d(t,128,5,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     t = MaxPooling2D((2,1))(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(20,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(t)\n",
    "    t = Dense(2, activation='softmax', name=\"class\")(t)\n",
    "    opt = Adam(lr=.001,decay=.001,epsilon=eps)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 2500, 1)           0         \n",
      "_________________________________________________________________\n",
      "gamma (Conv1D_gammatone)     (None, 2500, 26)          79        \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 2500, 26)          104       \n",
      "_________________________________________________________________\n",
      "mfcc (MFCC)                  (None, 123, 26)           33800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 123, 26)           104       \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 123, 26, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 119, 22, 16)       400       \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 119, 22, 16)       64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 119, 22, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 119, 22, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 115, 18, 32)       12800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 115, 18, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 115, 18, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 115, 18, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 57, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 53, 16, 32)        15360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 53, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 53, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 53, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 49, 14, 64)        30720     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 49, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 49, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 49, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 24, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 20, 10, 64)        102400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 20, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 20, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 20, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 6, 128)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 16, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 6, 128)         409600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 8, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 8, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 6, 256)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 8, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "class_dense (Dense)          (None, 20)                245760    \n",
      "_________________________________________________________________\n",
      "class (Dense)                (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 1,878,049\n",
      "Trainable params: 1,842,705\n",
      "Non-trainable params: 35,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from HeartCepNet import heartnet2D\n",
    "kernel_size=5\n",
    "fs=2000\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "filters=26\n",
    "# model = heartnet2D(kernel_size,fs,winlen,winstep,filters)\n",
    "model = Network2D(kernel_size,fs,winlen,winstep,filters)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='mfcc_res2D.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 2500, 1), (10, 2))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(10,2500,1)\n",
    "y = np.ones((10,1))\n",
    "y = to_categorical(y)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 1.1416 - acc: 0.3000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7836e-05 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bb9039ad0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
