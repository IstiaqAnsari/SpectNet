{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(1,'/media/mhealthra2/Data/rakib/gits/pytorch-summary/torchsummary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary2 import summary,summary_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary,summary\n",
    "from math import floor,ceil\n",
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\t\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = Conv_Gammatone(1,64,81,1000)\n",
    "#         self.conv1 = nn.Conv1d(1,32,81,stride=1,padding=0,bias=False)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "#         self.linear1 = nn.Linear(1248,2)\n",
    "        self.soft = nn.Softmax(dim=0)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "#         x = self.linear1(x)\n",
    "        x = self.soft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "    Conv_Gammatone-1             [-1, 64, 2420]             192\n",
      "         MaxPool1d-2             [-1, 64, 1210]               0\n",
      "           Softmax-3             [-1, 64, 1210]               0\n",
      "================================================================\n",
      "Total params: 192\n",
      "Trainable params: 192\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.36\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 2.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wow = summary(net.cuda(),(1,2500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(wow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fc', Parameter containing:\n",
      "tensor([[  0.0000],\n",
      "        [  6.0146],\n",
      "        [ 12.0808],\n",
      "        [ 18.1991],\n",
      "        [ 24.3701],\n",
      "        [ 30.5940],\n",
      "        [ 36.8713],\n",
      "        [ 43.2027],\n",
      "        [ 49.5884],\n",
      "        [ 56.0291],\n",
      "        [ 62.5250],\n",
      "        [ 69.0768],\n",
      "        [ 75.6849],\n",
      "        [ 82.3497],\n",
      "        [ 89.0718],\n",
      "        [ 95.8517],\n",
      "        [102.6898],\n",
      "        [109.5867],\n",
      "        [116.5428],\n",
      "        [123.5587],\n",
      "        [130.6349],\n",
      "        [137.7719],\n",
      "        [144.9702],\n",
      "        [152.2304],\n",
      "        [159.5529],\n",
      "        [166.9383],\n",
      "        [174.3873],\n",
      "        [181.9001],\n",
      "        [189.4776],\n",
      "        [197.1202],\n",
      "        [204.8284],\n",
      "        [212.6029],\n",
      "        [220.4441],\n",
      "        [228.3528],\n",
      "        [236.3294],\n",
      "        [244.3745],\n",
      "        [252.4888],\n",
      "        [260.6728],\n",
      "        [268.9271],\n",
      "        [277.2523],\n",
      "        [285.6490],\n",
      "        [294.1180],\n",
      "        [302.6596],\n",
      "        [311.2747],\n",
      "        [319.9638],\n",
      "        [328.7275],\n",
      "        [337.5665],\n",
      "        [346.4815],\n",
      "        [355.4730],\n",
      "        [364.5419],\n",
      "        [373.6887],\n",
      "        [382.9141],\n",
      "        [392.2186],\n",
      "        [401.6031],\n",
      "        [411.0683],\n",
      "        [420.6149],\n",
      "        [430.2434],\n",
      "        [439.9547],\n",
      "        [449.7495],\n",
      "        [459.6284],\n",
      "        [469.5921],\n",
      "        [479.6415],\n",
      "        [489.7772],\n",
      "        [500.0000]], requires_grad=True))\n",
      "('beta', Parameter containing:\n",
      "tensor([[100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.],\n",
      "        [100.]], requires_grad=True))\n",
      "('amp', Parameter containing:\n",
      "tensor([[100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.],\n",
      "        [100000.]], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for x in net.conv1.named_parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for x,y in net.named_parameters():\n",
    "#     print(x)\n",
    "    print(y.requires_grad)\n",
    "#     print(x[0], x[1].shape)\n",
    "#     print(x[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "def register_hook(module):\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "        module_idx = len(summary)\n",
    "        \n",
    "        \n",
    "        m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "        summary[m_key] = OrderedDict()\n",
    "        summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "        summary[m_key][\"input_shape\"][0] = batch_size\n",
    "        if isinstance(output, (list, tuple)):\n",
    "            summary[m_key][\"output_shape\"] = [\n",
    "                [-1] + list(o.size())[1:] for o in output\n",
    "            ]\n",
    "        else:\n",
    "            summary[m_key][\"output_shape\"] = list(output.size())\n",
    "            summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "        params = 0\n",
    "        \n",
    "        ### updated part\n",
    "        for (name,weight) in module.named_parameters():\n",
    "            params += torch.prod(torch.LongTensor(list(weight.shape)))\n",
    "            summary[m_key][\"trainable\"] = weight.requires_grad\n",
    "        ###\n",
    "           \n",
    "        ### previously was this\n",
    "#         if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "#             params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "#             summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "        ###\n",
    "    \n",
    "    \n",
    "        if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "            params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "        summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "    if (\n",
    "        not isinstance(module, nn.Sequential)\n",
    "        and not isinstance(module, nn.ModuleList)\n",
    "        and not (module == model)\n",
    "    ):\n",
    "        hooks.append(module.register_forward_hook(hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "if device == \"cuda\" and torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (1,2500)\n",
    "if isinstance(input_size, tuple):\n",
    "    input_size = [input_size]\n",
    "x = [torch.rand(2, *in_size).type(dtype) for in_size in input_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = OrderedDict()\n",
    "hooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict(), [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary,hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv_Gammatone(1, 64, kernel_size=(81,), stride=(1,), bias=False)\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (soft): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = net.cuda()\n",
    "model.apply(register_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "model(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in hooks:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------\")\n",
    "line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "print(line_new)\n",
    "print(\"================================================================\")\n",
    "total_params = 0\n",
    "total_output = 0\n",
    "trainable_params = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_Gammatone-1\n",
      "\n",
      "MaxPool1d-2\n",
      "\n",
      "Softmax-3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in summary:\n",
    "    print(layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_Gammatone-1\n",
      "tensor(192)\n",
      "    Conv_Gammatone-1              [2, 64, 2420]             192\n",
      "MaxPool1d-2\n",
      "0\n",
      "         MaxPool1d-2              [2, 64, 1210]               0\n",
      "Softmax-3\n",
      "0\n",
      "           Softmax-3              [2, 64, 1210]               0\n"
     ]
    }
   ],
   "source": [
    "for layer in summary:\n",
    "    print(layer)\n",
    "    print(summary[layer][\"nb_params\"])\n",
    "    # input_shape, output_shape, trainable, nb_params\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "        layer,\n",
    "        str(summary[layer][\"output_shape\"]),\n",
    "        \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "    )\n",
    "    total_params += summary[layer][\"nb_params\"]\n",
    "    total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "    if \"trainable\" in summary[layer]:\n",
    "        if summary[layer][\"trainable\"] == True:\n",
    "            trainable_params += summary[layer][\"nb_params\"]\n",
    "    print(line_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(192)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_channels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-bac9259948f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'in_channels' is not defined"
     ]
    }
   ],
   "source": [
    "Parameter(torch.Tensor(in_channels, out_channels // groups, *kernel_size))\n",
    "Parameter(torch.Tensor(1, filters, kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hz2mel(hz):\n",
    "        return 2595 * np.log10(1+hz/700.)\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[20.],\n",
       "        [20.],\n",
       "        [20.],\n",
       "        [20.],\n",
       "        [20.]], requires_grad=True)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameter(torch.ones((5,1))*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.utils import _single\n",
    "class Conv_Gammatone(Module):\n",
    "\n",
    "    __constants__ = ['stride', 'padding', 'dilation', 'groups', 'bias',\n",
    "                     'padding_mode', 'output_padding', 'in_channels',\n",
    "                     'out_channels', 'kernel_size']\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,fsHz, stride=1,\n",
    "                 padding=0, dilation=1, transposed=False, output_padding=(0,),\n",
    "                 groups=1, bias=False, padding_mode='zeros',fc=(0,500),beta_val=100,amp_val=10**5,n_order=4):\n",
    "        super(Conv_Gammatone, self).__init__()\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.filters = out_channels\n",
    "        self.kernel_size = _single(kernel_size)\n",
    "        self.stride = _single(stride)\n",
    "        self.padding = _single(padding)\n",
    "        self.dilation = _single(dilation)\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        self.fsHz = fsHz\n",
    "        if isinstance(fc,tuple):\n",
    "            (minf,maxf)=fc\n",
    "        else:\n",
    "            minf = 0\n",
    "            maxf = fc\n",
    "        self.fc = Parameter(torch.from_numpy(self.mel2hz(np.linspace(self.hz2mel(minf),self.hz2mel(maxf),\n",
    "                            self.filters,dtype=np.float32))).unsqueeze(-1))\n",
    "        \n",
    "        self.beta = Parameter(torch.ones((self.filters,1))*beta_val)\n",
    "        \n",
    "        self.amp = Parameter(torch.ones((self.filters,1))*amp_val)\n",
    "        \n",
    "        self.n_order = (torch.tensor(n_order,dtype=torch.float))\n",
    "        \n",
    "#         self.weight = torch.([self.fc, self.beta, self.amp])\n",
    "        \n",
    "        self.register_parameter('bias', None)\n",
    "    def impulse_gammatone(self):\n",
    "        device = 0\n",
    "#         print(self.amp.get_device())\n",
    "#         print(self.beta.get_device())\n",
    "#         print(self.fc.get_device())\n",
    "#         print(self.n_order.get_device())\n",
    "        \n",
    "        self.t = torch.arange(0,self.kernel_size[0]/self.fsHz,\n",
    "                            1/self.fsHz,dtype = torch.float).unsqueeze(-1).transpose(1,0)\n",
    "    \n",
    "        self.t = self.t.type(torch.FloatTensor)\n",
    "        self.n_order = self.n_order.type(torch.FloatTensor)\n",
    "#         print(\"device\",self.t.get_device())\n",
    "#         print(self.n_order.get_device())\n",
    "#         print(self.amp.get_device())\n",
    "        power = torch.pow(self.t,self.n_order-1)\n",
    "#         print(\"power \", power.get_device())\n",
    "        power = power.to(device = device)\n",
    "#         print(\"power \", power.get_device())\n",
    "        \n",
    "        at = self.amp.to(device=device)*power\n",
    "        \n",
    "#         print(\"exp\")\n",
    "#         print((-2*torch.tensor(np.pi).to(device)).get_device())\n",
    "#         print(\":/ \"torch.mm(self.beta,self.t.to(device)).get_device())\n",
    "        \n",
    "        exp = torch.exp(-2*torch.tensor(np.pi).to(device)*torch.mm(self.beta.to(device),self.t.to(device)))\n",
    "        cos = torch.cos(2*torch.tensor(np.pi).to(device)*torch.mm(self.fc.to(device),self.t.to(device)))\n",
    "        return at*exp*cos\n",
    "    def forward(self, input):\n",
    "        gammatone = self.impulse_gammatone().unsqueeze(1)\n",
    "        if self.padding_mode == 'circular':\n",
    "            expanded_padding = ((self.padding[0] + 1) // 2, self.padding[0] // 2)\n",
    "            return F.conv1d(F.pad(input, expanded_padding, mode='circular'),\n",
    "                            gammatone, self.bias, self.stride,\n",
    "                            _single(0), self.dilation, self.groups)\n",
    "        return F.conv1d(input, gammatone, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "    \n",
    "    \n",
    "#     def reset_parameters(self):\n",
    "#         init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "#         if self.bias is not None:\n",
    "#             fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "#             bound = 1 / math.sqrt(fan_in)\n",
    "#             init.uniform_(self.bias, -bound, bound)\n",
    "    def hz2mel(self,hz):\n",
    "        return 2595 * np.log10(1+hz/700.)\n",
    "    def mel2hz(self,mel):\n",
    "        return 700*(10**(mel/2595.0)-1)\n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Conv_Gammatone, self).__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow = Conv_Gammatone(1,26,81,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 1, 81])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wow.impulse_gammatone().unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
