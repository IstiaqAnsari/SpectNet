{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from keras import backend as K\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.topology import InputSpec\n",
    "import tensorflow as tf\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Input, MaxPooling1D ,Conv1D,Activation,Dense, activations, initializers, Flatten, regularizers, constraints, Lambda,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from keras.backend.common import normalize_data_format\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from Gradient_Reverse_Layer import GradientReversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    '''Custom Layer for ResNet used for BatchNormalization.\n",
    "\n",
    "    Linear learnable weight vector , does dot multiplication on a vector\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).'''\n",
    "\n",
    "    def __init__(self, weights=None, axis=-1,init='he_normal',**kwargs):\n",
    "        self.axis = axis\n",
    "        self.init = initializers.get(init)\n",
    "        self.kernel = weights\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape)>2:\n",
    "            raise ValueError(\"Input to attention layer hasn't been flattened\")\n",
    "        self.input_dim = input_shape[-1]            \n",
    "        self.kernel = self.add_weight(shape=(self.input_dim,),\n",
    "                                      initializer=initializers.Ones(),\n",
    "                                      name='kernel',\n",
    "                                      constraint=constraints.NonNeg()\n",
    "                                      #constraint=constraints.min_max_norm(min_value=0.0, max_value=1.0)\n",
    "                                      #constraint=constraints.UnitNorm(axis=self.axis)\n",
    "                                     )\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: self.input_dim})            \n",
    "        self.built = True\n",
    "    def call(self, inputs):\n",
    "        output = tf.multiply(inputs,self.kernel)\n",
    "        return output\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    def get_config(self):\n",
    "        config = {\"kernel\": self.kernel, \"axis\": self.axis}\n",
    "        base_config = super(Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = Attention(weights=[np.ones(10)],name = 'wow',trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const:0' shape=(3,) dtype=float32>,\n",
       " <tf.Tensor 'Const_1:0' shape=(1, 3) dtype=float32>,\n",
       " <tf.Tensor 'Const_2:0' shape=(2, 3) dtype=float32>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.convert_to_tensor(np.array([1,2,3]).astype(np.float32))\n",
    "b = tf.convert_to_tensor(np.array([1,2,3]).astype(np.float32).reshape(1,3))\n",
    "c = tf.convert_to_tensor(np.array([[1,2,3],[4,5,6]]).astype(np.float32).reshape(2,3))\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<tf.Tensor 'lambda_1/mul:0' shape=(1, 3, 3) dtype=float32>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.multiply(c,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Multiply()([b,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 4. 9.]]\n"
     ]
    }
   ],
   "source": [
    "print((tf.Session().run(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.1099719,  0.4618892,  0.4047528], dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.50968225"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-.09050519+.05788201-.47705907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'attention_6',\n",
       " 'trainable': True,\n",
       " 'kernel': <tf.Variable 'attention_6/kernel:0' shape=(3,) dtype=float32_ref>,\n",
       " 'axis': -1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "print(list(range(25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network():\n",
    "    input = Input(shape=(10, 1))\n",
    "    t = Lambda(lambda x:x[:,:5,:])(input)\n",
    "    t1 = Lambda(lambda x:x[:,5:,:])(input)\n",
    "    t = Conv1D(3, kernel_size=1,\n",
    "                kernel_initializer=initializers.he_normal(),\n",
    "                padding='valid')(t)\n",
    "    \n",
    "    t1 = Conv1D(3, kernel_size=1,\n",
    "                kernel_initializer=initializers.he_normal(),\n",
    "                padding='valid')(t1)\n",
    "    t = Concatenate(axis=1)([t,t1])\n",
    "    t = Flatten()(t)\n",
    "    #t1 = Flatten()(t1)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    \n",
    "#     model = Model(inputs=input, outputs=[t,t1])\n",
    "#     model.compile(optimizer=opt, loss=['categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 5, 1)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 5, 1)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5, 3)         6           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 5, 3)         6           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 3)        0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 30)           0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Flatten at 0x7f7af143fb10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('flatten_1')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_model in module keras.engine.saving:\n",
      "\n",
      "load_model(filepath, custom_objects=None, compile=True)\n",
      "    Loads a model saved via `save_model`.\n",
      "    \n",
      "    # Arguments\n",
      "        filepath: one of the following:\n",
      "            - string, path to the saved model, or\n",
      "            - h5py.File or h5py.Group object from which to load the model\n",
      "        custom_objects: Optional dictionary mapping names\n",
      "            (strings) to custom classes or functions to be\n",
      "            considered during deserialization.\n",
      "        compile: Boolean, whether to compile the model\n",
      "            after loading.\n",
      "    \n",
      "    # Returns\n",
      "        A Keras model instance. If an optimizer was found\n",
      "        as part of the saved model, the model is already\n",
      "        compiled. Otherwise, the model is uncompiled and\n",
      "        a warning will be displayed. When `compile` is set\n",
      "        to False, the compilation is omitted without any\n",
      "        warning.\n",
      "    \n",
      "    # Raises\n",
      "        ImportError: if h5py is not available.\n",
      "        ValueError: In case of an invalid savefile.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "help(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-14255d3ae73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m`\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msample_weight_mode\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         raise ValueError('Could not interpret optimizer identifier: ' +\n\u001b[0;32m--> 801\u001b[0;31m                          str(identifier))\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: None"
     ]
    }
   ],
   "source": [
    "opt = SGD(lr=.001,decay=.001)\n",
    "model = Model(inputs=inp, outputs=t)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100,10,1)\n",
    "y = np.random.randint(low = 0,high = 2,size = (100,1))\n",
    "y = to_categorical(y,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 0s 266us/step - loss: 1.9940 - out_loss: 1.0740 - out2_loss: 0.9200 - out_acc: 0.4900 - out2_acc: 0.5400\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 240us/step - loss: 1.8754 - out_loss: 0.9813 - out2_loss: 0.8941 - out_acc: 0.5000 - out2_acc: 0.4800\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 233us/step - loss: 1.8163 - out_loss: 0.9265 - out2_loss: 0.8898 - out_acc: 0.5600 - out2_acc: 0.5100\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 242us/step - loss: 1.9404 - out_loss: 1.0064 - out2_loss: 0.9341 - out_acc: 0.5000 - out2_acc: 0.4800\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 266us/step - loss: 1.7900 - out_loss: 0.8932 - out2_loss: 0.8968 - out_acc: 0.5400 - out2_acc: 0.5400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f576854ce50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,[y,y],batch_size=10,epochs=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1.0006565 , 0.9950268 , 1.0006152 , 0.9775875 , 0.99507576,\n",
       "         1.0147973 , 0.9942441 , 0.9988031 , 0.96180874, 0.9970449 ],\n",
       "        dtype=float32)],\n",
       " [array([0.9601198 , 0.99470335, 0.99289495, 0.9861508 , 0.9998297 ,\n",
       "         0.9958785 , 0.96344477, 0.99211186, 0.9646526 , 0.9982504 ],\n",
       "        dtype=float32)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"att\" ).get_weights(),model.get_layer(\"att2\" ).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(\"att\").trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor(np.random.rand(5,10).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'wow_19/Mul:0' shape=(5, 10) dtype=float32>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "att.set_weights(model.get_layer(\"att\" ).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting kernel\n"
     ]
    }
   ],
   "source": [
    "model.get_layer(\"att\" ).set_kernel(model.get_layer(\"att2\" ).kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.get_layer(\"att2\" ).kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confused_Crossentropy(y_true, y_pred):\n",
    "    y_predfused = tf.multiply(y_pred,0)+.5\n",
    "    #y_predfused = tf.convert_to_tensor((np.ones((batch,num_class),dtype=np.float32)*0.5))\n",
    "    #y_truefused = tf.convert_to_tensor( to_categorical(np.ones(batch),num_class) )\n",
    "    return K.abs(K.categorical_crossentropy(y_true, y_pred)-K.categorical_crossentropy(y_true,y_predfused))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(0,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):             \n",
    "    lr0 = .00128437\n",
    "    #print(\"learning rate , lr 0 \", lr, lr0)\n",
    "    a = 1\n",
    "    b = 1\n",
    "    p = epoch/epochs\n",
    "    lrate = lr0/math.pow((1+a*p),b)\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network():\n",
    "    input = Input(shape=(2900, 1))\n",
    "    \n",
    "    input1 = Lambda(lambda x:x[:,:200,:])(input)\n",
    "    input2 = Lambda(lambda x:x[:,200:1000,:])(input)\n",
    "    input3 = Lambda(lambda x:x[:,1000:1200,:])(input)\n",
    "    input4 = Lambda(lambda x:x[:,1200:2900,:])(input)\n",
    "    \n",
    "    input1 = Flatten()(input1)\n",
    "    input2 = Flatten()(input2)\n",
    "    input3 = Flatten()(input3)\n",
    "    input4 = Flatten()(input4)\n",
    "    \n",
    "    t1 = Dense(200)(input1)\n",
    "    t2 = Dense(500)(input2)\n",
    "    t3 = Dense(200)(input3)\n",
    "    t4 = Dense(500)(input4)\n",
    "    \n",
    "    t = Concatenate(axis=1)([t1,t2,t3,t4])\n",
    "    dann_in = GradientReversal(hp_lambda=.5,name='grl')(t)\n",
    "    cls = Dense(2)(t)\n",
    "    dom = Dense(8)(dann_in)\n",
    "    #t1 = Flatten()(t1)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=[cls,dom])\n",
    "    model.compile(optimizer=opt, loss=['categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy'])\n",
    "    \n",
    "#     model = Model(inputs=input, outputs=[t,t1])\n",
    "#     model.compile(optimizer=opt, loss=['categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 2900, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 200, 1)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 800, 1)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 200, 1)       0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1700, 1)      0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 200)          0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 800)          0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 200)          0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 1700)         0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          40200       flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          400500      flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200)          40200       flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 500)          850500      flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1400)         0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "grl (GradientReversal)          (None, 1400)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2)            2802        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8)            11208       grl[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 1,345,410\n",
      "Trainable params: 1,345,410\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    a = net.get_layer('asdf').hp_lambda\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f7aeab54750>,\n",
       " <keras.layers.core.Lambda at 0x7f7aeacf4990>,\n",
       " <keras.layers.core.Lambda at 0x7f7aeab54650>,\n",
       " <keras.layers.core.Lambda at 0x7f7aeab54f50>,\n",
       " <keras.layers.core.Lambda at 0x7f7aeab34ed0>,\n",
       " <keras.layers.core.Flatten at 0x7f7aeab34650>,\n",
       " <keras.layers.core.Flatten at 0x7f7aeaac8550>,\n",
       " <keras.layers.core.Flatten at 0x7f7aeaad8490>,\n",
       " <keras.layers.core.Flatten at 0x7f7aeaae5250>,\n",
       " <keras.layers.core.Dense at 0x7f7aeaaf7e10>,\n",
       " <keras.layers.core.Dense at 0x7f7aeaa9df90>,\n",
       " <keras.layers.core.Dense at 0x7f7aeaaac750>,\n",
       " <keras.layers.core.Dense at 0x7f7aeaa56350>,\n",
       " <keras.layers.merge.Concatenate at 0x7f7aeaa7c890>,\n",
       " <Gradient_Reverse_Layer.GradientReversal at 0x7f7aeaa7c610>,\n",
       " <keras.layers.core.Dense at 0x7f7aeaa7cd10>,\n",
       " <keras.layers.core.Dense at 0x7f7aeaa35990>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
