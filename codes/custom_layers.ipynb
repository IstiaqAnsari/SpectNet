{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from keras import backend as K\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.topology import InputSpec\n",
    "import tensorflow as tf\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Input, MaxPooling1D ,Activation,Dense, activations, initializers, Flatten, regularizers, constraints, Lambda,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from keras.backend.common import normalize_data_format\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    '''Custom Layer for ResNet used for BatchNormalization.\n",
    "\n",
    "    Linear learnable weight vector , does dot multiplication on a vector\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).'''\n",
    "\n",
    "    def __init__(self, weights=None, axis=-1,init='he_normal',**kwargs):\n",
    "        self.axis = axis\n",
    "        self.init = initializers.get(init)\n",
    "        self.kernel = weights\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape)>2:\n",
    "            raise ValueError(\"Input to attention layer hasn't been flattened\")\n",
    "        self.input_dim = input_shape[-1]            \n",
    "        self.kernel = self.add_weight(shape=(self.input_dim,),\n",
    "                                      initializer=initializers.Ones(),\n",
    "                                      name='kernel',\n",
    "                                      constraint=constraints.NonNeg()\n",
    "                                      #constraint=constraints.min_max_norm(min_value=0.0, max_value=1.0)\n",
    "                                      #constraint=constraints.UnitNorm(axis=self.axis)\n",
    "                                     )\n",
    "        self.input_spec = InputSpec(min_ndim=2, axes={-1: self.input_dim})            \n",
    "        self.built = True\n",
    "    def call(self, inputs):\n",
    "        output = tf.multiply(inputs,self.kernel)\n",
    "        return output\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    def get_config(self):\n",
    "        config = {\"kernel\": self.kernel, \"axis\": self.axis}\n",
    "        base_config = super(Attention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = Attention(weights=[np.ones(10)],name = 'wow',trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Const:0' shape=(3,) dtype=float32>,\n",
       " <tf.Tensor 'Const_1:0' shape=(1, 3) dtype=float32>,\n",
       " <tf.Tensor 'Const_2:0' shape=(2, 3) dtype=float32>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.convert_to_tensor(np.array([1,2,3]).astype(np.float32))\n",
    "b = tf.convert_to_tensor(np.array([1,2,3]).astype(np.float32).reshape(1,3))\n",
    "c = tf.convert_to_tensor(np.array([[1,2,3],[4,5,6]]).astype(np.float32).reshape(2,3))\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Lambda(lambda x: x[0] * K.expand_dims(x[1], axis=-1))([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<tf.Tensor 'lambda_1/mul:0' shape=(1, 3, 3) dtype=float32>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.multiply(c,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Multiply()([b,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 4. 9.]]\n"
     ]
    }
   ],
   "source": [
    "print((tf.Session().run(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.1099719,  0.4618892,  0.4047528], dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.50968225"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-.09050519+.05788201-.47705907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'attention_6',\n",
       " 'trainable': True,\n",
       " 'kernel': <tf.Variable 'attention_6/kernel:0' shape=(3,) dtype=float32_ref>,\n",
       " 'axis': -1}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network():\n",
    "    input = Input(shape=(10, 1))\n",
    "    t = BatchNormalization(epsilon=1.1e-5, momentum=.99, axis=-1)(input)\n",
    "    t = Activation('relu')(t)\n",
    "    t = Dropout(rate=.5, seed=1)(t)\n",
    "    t = MaxPooling1D(pool_size=1)(t)\n",
    "    \n",
    "    t = Flatten()(t)\n",
    "    tt = t\n",
    "    t = Attention(weights = [np.ones(10)],name='att',trainable = True)(t)\n",
    "    t2 = Attention(weights = [np.ones(10)],name='att2')(tt)\n",
    "    \n",
    "    t = Dense(2,activation='softmax',name='out')(t)\n",
    "    t2 = Dense(2,activation='softmax',name='out2')(t2)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    model = Model(inputs=input, outputs=[t,t2])\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 10, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 1)        4           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 1)        0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 1)        0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 10, 1)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 10)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "att (Attention)                 (None, 10)           10          flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "att2 (Attention)                (None, 10)           10          flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 2)            22          att[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 2)            22          att2[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 78\n",
      "Trainable params: 66\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.99934375, 0.9946065 , 1.0009376 , 0.9810067 , 0.9955089 ,\n",
       "         1.0147412 , 0.9947194 , 0.996221  , 0.95994973, 0.9970449 ],\n",
       "        dtype=float32)],\n",
       " [array([0.9706804 , 0.9971132 , 0.9925678 , 0.9897004 , 0.9998258 ,\n",
       "         0.99589455, 0.97293645, 0.9946333 , 0.9757878 , 0.9982504 ],\n",
       "        dtype=float32)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"att\").get_weights(),model.get_layer(\"att2\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(5,10,1)\n",
    "y = np.random.randint(low = 0,high = 2,size = (5,1))\n",
    "y = to_categorical(y,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa34c322110>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,[y,y],epochs=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1.0006565 , 0.9950268 , 1.0006152 , 0.9775875 , 0.99507576,\n",
       "         1.0147973 , 0.9942441 , 0.9988031 , 0.96180874, 0.9970449 ],\n",
       "        dtype=float32)],\n",
       " [array([0.9601198 , 0.99470335, 0.99289495, 0.9861508 , 0.9998297 ,\n",
       "         0.9958785 , 0.96344477, 0.99211186, 0.9646526 , 0.9982504 ],\n",
       "        dtype=float32)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"att\" ).get_weights(),model.get_layer(\"att2\" ).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(\"att\").trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor(np.random.rand(5,10).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'wow_19/Mul:0' shape=(5, 10) dtype=float32>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "att.set_weights(model.get_layer(\"att\" ).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting kernel\n"
     ]
    }
   ],
   "source": [
    "model.get_layer(\"att\" ).set_kernel(model.get_layer(\"att2\" ).kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.get_layer(\"att2\" ).kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
