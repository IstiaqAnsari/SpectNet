{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from keras.initializers import Initializer\n",
    "from keras import backend as K\n",
    "from keras.engine.base_layer import Layer\n",
    "from keras.engine.topology import InputSpec\n",
    "import tensorflow as tf,keras\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers import Input, MaxPooling1D,MaxPooling2D,Conv1D,Activation,Dense, activations, initializers,Conv2D\n",
    "from keras.layers import Flatten, regularizers,Reshape, constraints, Dropout,Multiply,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from keras.backend.common import normalize_data_format\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler, CSVLogger, ModelCheckpoint, Callback\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from custom_layers import Conv1D_gammatone, Conv1D_zerophase,Conv1D_gammatone_coeff\n",
    "import scipy\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax\n",
    "from CustomTensorBoard import TensorBoard\n",
    "from custom_layers import Conv1D_zerophase_linear, Conv1D_linearphase, Conv1D_zerophase,\\\n",
    "    DCT1D, Conv1D_gammatone, Conv1D_linearphaseType, Attention\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Activation, AveragePooling1D\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax\n",
    "import numpy as np\n",
    "import tables,h5py\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from ResultAnalyser import Result\n",
    "from utils import Confused_Crossentropy\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))\n",
    "# from clr_callback import CyclicLR\n",
    "# import dill\n",
    "from BalancedDannAudioDataGenerator import BalancedAudioDataGenerator, AudioDataGenerator\n",
    "import os,time\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import math\n",
    "import pandas as pd\n",
    "import tables,h5py\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from keras.utils import plot_model\n",
    "# from Heartnet import heartnet,getAttentionModel\n",
    "from collections import Counter\n",
    "# from torchviz import make_dot\n",
    "def to_numpy(x):\n",
    "    return x.cpu().detach().numpy()\n",
    "def plotf(x):\n",
    "    plt.plot(to_numpy(x))\n",
    "from utils import log_macc, results_log\n",
    "from dataLoader import reshape_folds\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import Evaluator\n",
    "import dataLoader\n",
    "# from custom_layers import Attention\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCC(Layer): \n",
    "    def __init__(self, rank,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 output_format='signal',\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(MFCC, self).__init__(**kwargs)\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n",
    "                                                      'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = K.normalize_data_format(data_format)\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.output_format = output_format\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "    \n",
    "        \n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='kernel',trainable=False)\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = K.pow(K.abs(inputs),2)\n",
    "        outputs = K.conv1d(\n",
    "            outputs,\n",
    "            self.kernel,\n",
    "            strides=self.strides[0],\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format)\n",
    "        outputs = K.log(outputs)\n",
    "#         outputs = tf.signal.dct(outputs,type=2,axis=-1,norm='ortho')\n",
    "        if(self.output_format=='image'):\n",
    "            outputs = K.expand_dims(outputs,axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            if(self.output_format=='image'):\n",
    "                return (input_shape[0],) + tuple(new_space) + (self.filters,) + (1,)\n",
    "            else:\n",
    "                return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "            \n",
    "        if self.data_format == 'channels_first':\n",
    "            raise NotImplementedError(\"Output formate image/signal not handled\")\n",
    "            space = input_shape[2:]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_utils.conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding=self.padding,\n",
    "                    stride=self.strides[i])\n",
    "                new_space.append(new_dim)\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'rank': self.rank,\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'strides': self.strides,\n",
    "            'padding': self.padding,\n",
    "            'data_format': self.data_format,\n",
    "            'output_format':self.output_format,\n",
    "            'kernel_initializer' : initializers.serialize(self.kernel_initializer)\n",
    "        }\n",
    "        base_config = super(MFCC, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_colormap(x):\n",
    "    import matplotlib._cm_listed as cmlist\n",
    "    cm = tf.convert_to_tensor(np.array(cmlist._viridis_data))\n",
    "    b = 255*(x-K.min(x))/(K.max(x)-K.min(x))\n",
    "    b = K.cast(b,dtype='int64')\n",
    "    wow = K.gather(cm,b)\n",
    "    return K.cast(wow,dtype='float32')\n",
    "def colormap_output_shape(input_shape):\n",
    "    return tuple( list(input_shape)+[3] )\n",
    "\n",
    "class TO_colormap(Layer):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super(TO_colormap, self).__init__(**kwargs)\n",
    "        import matplotlib._cm_listed as cmlist\n",
    "        self.cm = tf.convert_to_tensor(np.array(cmlist._viridis_data))\n",
    "        self.input_spec = InputSpec(min_ndim=3)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernelA = self.add_weight(name='kernelA',\n",
    "                                       shape=(input_shape[1], 3),\n",
    "                                       initializer='uniform')\n",
    "        \n",
    "        self.built = True\n",
    "        super(TO_colormap, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        b = 255*(x-K.min(x))/(K.max(x)-K.min(x))\n",
    "        b = K.cast(b,dtype='int64')\n",
    "        wow = K.gather(self.cm,b)\n",
    "        return K.cast(wow,dtype='float32')\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple( list(input_shape)+[3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mfcc_kernel_init(Initializer):\n",
    "#     def __init__(self):\n",
    "        \n",
    "    def __call__(self, shape, dtype=K.floatx()):\n",
    "        self.shape = shape\n",
    "        (kernel_size,in_channels,out_channels) = shape\n",
    "        if(in_channels!=out_channels):\n",
    "            raise ValueError(\"Input and Output Channels must be same. Got {0} input channels and {0} output channels\".format(in_channels,out_channels))\n",
    "        mat = K.eye(in_channels,dtype=dtype)\n",
    "        mat_n = [mat for i in range(kernel_size)]\n",
    "        return K.stack(mat_n)\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"shape\":self.shape\n",
    "        }\n",
    "# def mfcc_kernel_init(shape, dtype=K.floatx()):\n",
    "#     (kernel_size,in_channels,out_channels) = shape\n",
    "#     if(in_channels!=out_channels):\n",
    "#         raise ValueError(\"Input and Output Channels must be same. Got {0} input channels and {0} output channels\".format(in_channels,out_channels))\n",
    "#     mat = K.eye(in_channels,dtype=dtype)\n",
    "#     mat_n = [mat for i in range(kernel_size)]\n",
    "#     return K.stack(mat_n)\n",
    "class Freq_Init(Initializer):\n",
    "    def __init__(self, minf=0., maxf=500):\n",
    "        self.minf = minf\n",
    "        self.maxf = maxf\n",
    "    def __call__(self, shape, dtype=K.floatx()):\n",
    "        (kernel_size,in_channels) = shape\n",
    "        start = self.hz2mel(self.minf)\n",
    "        end = self.hz2mel(self.maxf)\n",
    "        n = ( end-start)/(kernel_size-1)\n",
    "        mel =  K.expand_dims(K.arange(start,end+1,n,dtype=dtype),axis=1)\n",
    "        return self.mel2hz(mel)\n",
    "    def hz2mel(self,hz):\n",
    "        return 2595 * (K.log(1.0+(hz*1.0)/700.)/K.log(10.0))\n",
    "    def mel2hz(self,mel):\n",
    "        return 700*(10**(mel/2595.0)-1)\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'minf': self.minf,\n",
    "            'maxf': self.maxf\n",
    "        }\n",
    "def hz2mel(hz):\n",
    "    return 2595 * np.log10(1+hz/700.)\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "def erb(f):\n",
    "    return 24.7*(4.37*10**-3*f+1)\n",
    "class beta_init(Initializer):\n",
    "    def __init__(self, val = 100):\n",
    "        self.val = val\n",
    "    def __call__(self,shape,dtype=K.floatx()):\n",
    "        (kernel_size,in_channels) = shape\n",
    "        beta_weights = tf.convert_to_tensor(np.ones((kernel_size,1))*self.val,dtype=K.floatx())\n",
    "        return beta_weights\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'val': self.val\n",
    "        }\n",
    "# def beta_init(shape, dtype=K.floatx()):\n",
    "#     (kernel_size,in_channels) = shape\n",
    "#     beta_weights = tf.convert_to_tensor(np.ones((kernel_size,1))*100,dtype=K.floatx())\n",
    "#     return beta_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch(input_tensor,num_filt,filters,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1*filters, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = MaxPooling1D(pool_size=subsam)(t)\n",
    "    t = Conv1D(num_filt2*filters, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = MaxPooling1D(pool_size=subsam)(t)\n",
    "    # t = Flatten()(t)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(kernel_size=5,fs=1000,winlen=0.025,winstep=0.01,filters=64,random_seed=1,padding='valid',bias=False,\n",
    "           lr=0.0012843784,lr_decay=0.0001132885,subsam=2,num_filt=(8,4),num_dense=20,trainable=True,batch_size=1024,\n",
    "           l2_reg=0.0,l2_reg_dense=0.0,bn_momentum=0.99,dropout_rate=0.5,dropout_dense=0.0,eps = 1.1e-5,maxnorm=10000,\n",
    "           activation_function='relu'):\n",
    "    input = Input(shape=(2500, 1))\n",
    "    t = Conv1D_gammatone_coeff(kernel_size=81, strides=1,filters=filters,\n",
    "                         fsHz=fs,use_bias=False,padding='same',\n",
    "                         fc_initializer=Freq_Init(minf=0.0,maxf=fs/2),\n",
    "                         amp_initializer=initializers.constant(10**4),\n",
    "                        beta_initializer=beta_init(val=100),name=\"gamma\"\n",
    "                        )(input)\n",
    "    \n",
    "#     t = Conv1D_gammatone(kernel_size=81, strides=1,filters=filters,\n",
    "#                          fsHz=fs,use_bias=False,padding='same',\n",
    "#                          fc_initializer=Freq_Init(minf=50.0,maxf=fs/2),\n",
    "#                          amp_initializer=initializers.constant(10**4),\n",
    "#                         beta_initializer=beta_init(val=100),name=\"gamma\"\n",
    "#                         )(input)\n",
    "    t = branch(t,num_filt,filters,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    \n",
    "#     t = branch(t,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "#     t = res_block(t,32,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "#     t = res_block(t,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(20,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(t)\n",
    "    t = Dense(2, activation='softmax', name=\"class\")(t)\n",
    "    opt = SGD(lr=.001,decay=.001)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=t)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=5\n",
    "fs=1000\n",
    "winlen=0.025\n",
    "winstep=0.01\n",
    "filters=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/torch/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<tf.Variable 'gamma/weight:0' shape=(81, 1, 64) dtype=float32_ref>\n",
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/torch/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2500, 1)           0         \n",
      "_________________________________________________________________\n",
      "gamma (Conv1D_gammatone_coef (None, 2500, 64)          5184      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2496, 512)         163840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2496, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2496, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2496, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1248, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1244, 256)         655360    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1244, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1244, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1244, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 622, 256)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 622, 256)          1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 159232)            0         \n",
      "_________________________________________________________________\n",
      "class_dense (Dense)          (None, 20)                3184640   \n",
      "_________________________________________________________________\n",
      "class (Dense)                (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 4,013,162\n",
      "Trainable params: 4,011,114\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Network(kernel_size,fs,winlen,winstep,filters)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "path = '../data/fold0_noFIR.mat'\n",
    "data = h5py.File(path, 'r')\n",
    "x_train = data['trainX'][:].astype('float32')\n",
    "x_train = np.expand_dims(x_train.transpose(),2)\n",
    "x_val = data['valX'][:].astype('float32')\n",
    "x_val = np.expand_dims(x_val.transpose(),2)\n",
    "y_train = data['trainY'][:].astype('int32')\n",
    "y_train = y_train.transpose()\n",
    "y_train = y_train[:,0]\n",
    "y_train[y_train<0] = 0\n",
    "y_val = data['valY'][:].astype('int32')\n",
    "y_val = y_val.transpose()\n",
    "y_val = y_val[:,0]\n",
    "y_val[y_val<0] = 0\n",
    "val_parts = data['val_parts'][:].astype('int32').squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,2)\n",
    "y_val = to_categorical(y_val,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = data['val_files'][:].astype('int32').squeeze(0)\n",
    "train_files = data['train_files'][:].astype('int32').squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2500, 1), (100, 2), (6710, 2500, 1), (6710, 2))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[2000:2100]\n",
    "y_train = y_train[2000:2100]\n",
    "train_files = train_files[2000:2100]\n",
    "x_train.shape,y_train.shape,x_val.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = list(Counter(train_files).keys())\n",
    "domainClass = [(cls,dfc) for cls in range(2) for dfc in domains]\n",
    "meta_labels = [domainClass.index((cl,df)) for (cl,df) in zip(np.argmax(y_train,1),train_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 9075,\n",
       "         0: 2883,\n",
       "         1: 2790,\n",
       "         7: 446,\n",
       "         8: 1080,\n",
       "         2: 223,\n",
       "         9: 497,\n",
       "         3: 294,\n",
       "         4: 55347,\n",
       "         10: 2470,\n",
       "         5: 3294,\n",
       "         11: 1411})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(meta_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2883  2790   223   294 55347  3294  9075   446  1080   497  2470  1411]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Chunk size selected as 3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "random_seed = 2\n",
    "datagen = BalancedAudioDataGenerator(shift=.1)\n",
    "flow = datagen.flow(x_train, y_train,\n",
    "                meta_label=meta_labels,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = \"heartnet64 \"+str(datetime.now()).replace(':','.')\n",
    "log_dir = \"../../Heartnet_Results/logs/gammatone_torch_layer/\"\n",
    "model_dir = log_dir+log_name+\"/weights/\"\n",
    "csv_logger = CSVLogger(log_dir + log_name + '/training.csv')\n",
    "tensbd = TensorBoard(log_dir=log_dir + log_name,\n",
    "                     batch_size=batch_size, histogram_freq = 3,\n",
    "                     write_grads=True,\n",
    "                     # embeddings_freq=99,\n",
    "                     # embeddings_layer_names=embedding_layer_names,\n",
    "                     # embeddings_data=x_val,\n",
    "                     # embeddings_metadata=metadata_file,\n",
    "                     write_images=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(log_dir + log_name):\n",
    "    os.makedirs(log_dir + log_name)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_json = model.to_json()\n",
    "# with open(model_dir + log_name+\"/model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Heartnet_Results/logs/gammatone_torch_layer/heartnet64 2020-05-13 03.08.51.172668/weights/'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = model_dir + 'weights.{epoch:04d}-{val_acc:.4f}.pickle'\n",
    "outlayer = ''\n",
    "val_outlayer_acc = 'val_'+outlayer+'acc'\n",
    "modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                monitor=val_outlayer_acc,save_best_only=False, mode='max') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class SaveWeights(Callback):\n",
    "    def __init__(self, checkpoint_name, verbose=0):\n",
    "        super(SaveWeights, self).__init__()\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "    def on_epoch_end(self, epoch,logs):\n",
    "        d = {x.name:x.get_weights() for x in self.model.layers}\n",
    "        with open(self.checkpoint_name.format(epoch=epoch+1, val_acc=logs['val_acc']) , 'wb') as f:\n",
    "            pickle.dump(d,f)\n",
    "saveweight = SaveWeights(checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check point  ../../Heartnet_Results/logs/gammatone_torch_layer/heartnet64 2020-05-13 03.08.51.172668/weights/weights.{epoch:04d}-{val_acc:.4f}.pickle\n",
      "Epoch 1/200\n",
      "18449/18449 [==============================] - 38015s 2s/step - loss: 0.6391 - acc: 0.6300 - val_loss: 0.8176 - val_acc: 0.5265\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:6,TP:132,Macc:0.5501786342436907,F1:0.6683493923783347\n",
      "Epoch 2/200\n",
      "18449/18449 [==============================] - 38149s 2s/step - loss: 0.6267 - acc: 0.6425 - val_loss: 0.8225 - val_acc: 0.5241\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:7,TP:131,Macc:0.5465554461266985,F1:0.6649695755227105\n",
      "Epoch 3/200\n",
      "18449/18449 [==============================] - 38210s 2s/step - loss: 0.6240 - acc: 0.6455 - val_loss: 0.8352 - val_acc: 0.5234\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:7,TP:131,Macc:0.5465554461266985,F1:0.6649695755227105\n",
      "Epoch 4/200\n",
      "18449/18449 [==============================] - 38215s 2s/step - loss: 0.6225 - acc: 0.6475 - val_loss: 0.8351 - val_acc: 0.5227\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:7,TP:131,Macc:0.5465554461266985,F1:0.6649695755227105\n",
      "Epoch 5/200\n",
      "18449/18449 [==============================] - 38240s 2s/step - loss: 0.6213 - acc: 0.6483 - val_loss: 0.8335 - val_acc: 0.5249\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:7,TP:131,Macc:0.5465554461266985,F1:0.6649695755227105\n",
      "Epoch 6/200\n",
      "18449/18449 [==============================] - 38242s 2s/step - loss: 0.6211 - acc: 0.6482 - val_loss: 0.8307 - val_acc: 0.5292\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:22,FP:124,FN:7,TP:131,Macc:0.5499801034029229,F1:0.6666616168561321\n",
      "Epoch 7/200\n",
      "18449/18449 [==============================] - 38250s 2s/step - loss: 0.6205 - acc: 0.6493 - val_loss: 0.8352 - val_acc: 0.5271\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:7,TP:131,Macc:0.5465554461266985,F1:0.6649695755227105\n",
      "Epoch 8/200\n",
      "18449/18449 [==============================] - 38213s 2s/step - loss: 0.6196 - acc: 0.6495 - val_loss: 0.8415 - val_acc: 0.5261\n",
      "6710/6710 [==============================] - 110s 16ms/step\n",
      "TN:21,FP:125,FN:7,TP:131,Macc:0.5465554461266985,F1:0.6649695755227105\n",
      "Epoch 9/200\n",
      " 5461/18449 [=======>......................] - ETA: 7:27:18 - loss: 0.6182 - acc: 0.6532"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-43dbeed872a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                            tensbd, csv_logger],\n\u001b[1;32m     13\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "verbose = 1\n",
    "model.fit_generator(flow,\n",
    "#                 steps_per_epoch=len(x_train) // batch_size,\n",
    "                steps_per_epoch=flow.steps_per_epoch,\n",
    "                # max_queue_size=20,\n",
    "                use_multiprocessing=False,\n",
    "                epochs=epochs,\n",
    "                verbose=verbose,\n",
    "                shuffle=True,\n",
    "                callbacks=[log_macc(val_parts, decision='majority',verbose=verbose,val_files=None,wav_files=None,checkpoint_name = checkpoint_name),\n",
    "                           tensbd, csv_logger],\n",
    "                validation_data=(x_val,y_val),\n",
    "                initial_epoch=0,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils,importlib\n",
    "utils = importlib.reload(utils)\n",
    "from utils import log_macc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 0\n",
      "gamma 1\n",
      "conv1d_1 1\n",
      "batch_normalization_1 4\n",
      "activation_1 0\n",
      "dropout_1 0\n",
      "max_pooling1d_1 0\n",
      "conv1d_2 1\n",
      "batch_normalization_2 4\n",
      "activation_2 0\n",
      "dropout_2 0\n",
      "max_pooling1d_2 0\n",
      "batch_normalization_3 4\n",
      "flatten_1 0\n",
      "class_dense 1\n",
      "class 2\n"
     ]
    }
   ],
   "source": [
    "for x in model.layers:\n",
    "    print(x.name,len(x.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.365681  ,  0.47806203, -0.01162256, ..., -0.21437405,\n",
       "          -0.34076563, -0.18346953]],\n",
       " \n",
       "        [[-0.25358862,  0.2660421 , -0.05660003, ..., -0.2784855 ,\n",
       "          -0.14513469, -0.30135432]],\n",
       " \n",
       "        [[-0.17417923,  0.03223413,  0.07543215, ..., -0.3758643 ,\n",
       "          -0.02395119, -0.2635922 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.03619101, -0.0510463 , -0.22567493, ..., -0.67171764,\n",
       "           0.58033925,  0.14520212]],\n",
       " \n",
       "        [[ 0.17033169, -0.02735857, -0.2820525 , ..., -0.65479845,\n",
       "           0.51989114,  0.19547534]],\n",
       " \n",
       "        [[ 0.2642771 , -0.06712583, -0.22479616, ..., -0.53827477,\n",
       "           0.48296753,  0.25344288]]], dtype=float32)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"gamma\").get_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
