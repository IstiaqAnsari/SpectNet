{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "# %matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import tables\n",
    "from utils import reshape_folds\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "from custom_layers import Conv1D_linearphaseType, Conv1D_linearphase, DCT1D, \\\n",
    "            Conv1D_gammatone, Conv1D_linearphaseType_legacy, Conv1D_zerophase\n",
    "    \n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from scipy import signal\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "sns.set()\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(model, model_inputs, batch_size=64,print_shape_only=True, layer_name=None):\n",
    "    '''\n",
    "    Get activations from a specific layer of a trained model\n",
    "    '''\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        # only one input! let's wrap it in a list.\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if\n",
    "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
    "\n",
    "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    \n",
    "    start_idx = 0\n",
    "    for idx in range(batch_size,len(model_inputs)+batch_size,batch_size):\n",
    "#         print(batch_size)\n",
    "        if model_multi_inputs_cond:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            list_inputs = [model_inputs[start_idx:idx], 0.]\n",
    "\n",
    "        # Learning phase. 0 = Test mode (no dropout or batch normalization)\n",
    "        # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]\n",
    "        layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
    "        for layer_activations in layer_outputs:\n",
    "            activations.append(layer_activations)\n",
    "        start_idx = idx\n",
    "    return np.vstack(activations)\n",
    "\n",
    "\n",
    "def display_activations(activation_maps):\n",
    "    '''\n",
    "    Plot activations\n",
    "    '''\n",
    "    batch_size = activation_maps[0].shape[0]\n",
    "    assert batch_size == 1, 'One image at a time to visualize.'\n",
    "    for i, activation_map in enumerate(activation_maps):\n",
    "        print('Displaying activation map {}'.format(i))\n",
    "        shape = activation_map.shape\n",
    "        if len(shape) == 4:\n",
    "            activations = np.hstack(np.transpose(activation_map[0], (2, 0, 1)))\n",
    "        elif len(shape) == 2:\n",
    "            # try to make it square as much as possible. we can skip some activations.\n",
    "            activations = activation_map[0]\n",
    "            num_activations = len(activations)\n",
    "            if num_activations > 1024:  # too hard to display it on the screen.\n",
    "                square_param = int(np.floor(np.sqrt(num_activations)))\n",
    "                activations = activations[0: square_param * square_param]\n",
    "                activations = np.reshape(activations, (square_param, square_param))\n",
    "            else:\n",
    "                activations = np.expand_dims(activations, axis=0)\n",
    "        else:\n",
    "            raise Exception('len(shape) = 3 has not been implemented.')\n",
    "        plt.imshow(activations, interpolation='None', cmap='jet')\n",
    "    plt.show()\n",
    "\n",
    "def smooth(scalars, weight):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "\n",
    "    return np.asarray(smoothed)\n",
    "    \n",
    "def get_weights(log_name,min_metric=.7,min_epoch=50,verbose=1,log_dir='../logs'):\n",
    "    '''\n",
    "    Load weights from training.csv file\n",
    "    '''\n",
    "    log_dir = '../logs'\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(log_dir,log_name)):\n",
    "        print(\"Looking into logArxiv\")\n",
    "        log_dir = '/media/mhealthra2/Data/heart_sound/logArxiv'\n",
    "    training_csv = os.path.join(log_dir,log_name,\"training.csv\")\n",
    "    df = pd.read_csv(training_csv)\n",
    "    sens_idx = df['val_sensitivity'][df.epoch>min_epoch][df.val_specificity>min_metric].idxmax()\n",
    "    spec_idx = df['val_specificity'][df.epoch>min_epoch][df.val_sensitivity>min_metric].idxmax()\n",
    "    macc_idx = df['val_macc'][df.epoch>min_epoch].idxmax()\n",
    "    val_idx = df['val_acc'][df.epoch>min_epoch].idxmax()\n",
    "    weights = dict()\n",
    "    weights['val_sensitivity'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[sens_idx]+1,df.val_acc.iloc[sens_idx])\n",
    "    weights['val_specificity'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[spec_idx]+1,df.val_acc.iloc[spec_idx])\n",
    "    weights['val_macc'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[macc_idx]+1,df.val_acc.iloc[macc_idx])\n",
    "    weights['val_acc'] = \"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[val_idx]+1,df.val_acc.iloc[val_idx])\n",
    "    weights['epoch'] = [\"weights.%.4d-%.4f.hdf5\" % (df.epoch.iloc[idx]+1,df.val_acc.iloc[idx]) \n",
    "                        for idx in range(df.count()[0])]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Best Sensitivity model: {} \\t\\t{}\".format(df.val_sensitivity.iloc[sens_idx],weights['val_sensitivity']))\n",
    "        print(\"Best Specificity model: {} \\t\\t{}\".format(df.val_specificity.iloc[spec_idx],weights['val_specificity']))\n",
    "        print(\"Best Macc model: {} \\t\\t{}\".format(df.val_macc.iloc[macc_idx],weights['val_macc']))\n",
    "        print(\"Best Val model: {} \\t\\t\\t{}\".format(df.val_acc.iloc[val_idx],weights['val_acc']))\n",
    "    return weights\n",
    "\n",
    "      \n",
    "def load_data(foldname,fold_dir=None,_categorical=True,quality=False):\n",
    "    ## import data\n",
    "    if fold_dir is None:\n",
    "        fold_dir = '/media/mhealthra2/Data/heart_sound/feature/segmented_noFIR/folds_dec_2018/'\n",
    "    else:\n",
    "        print(fold_dir+foldname)\n",
    "    feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "    x_train = feat.root.trainX[:]\n",
    "    y_train = feat.root.trainY[0, :]\n",
    "    q_train = feat.root.trainY[1, :]\n",
    "    x_val = feat.root.valX[:]\n",
    "    y_val = feat.root.valY[0, :]\n",
    "    q_val = feat.root.valY[1, :]\n",
    "    train_parts = feat.root.train_parts[:]\n",
    "    val_parts = feat.root.val_parts[0, :]\n",
    "\n",
    "    ############## Relabeling ################\n",
    "    \n",
    "    for i in range(0, y_train.shape[0]):\n",
    "        if y_train[i] == -1:\n",
    "            y_train[i] = 0  ## Label 0 for normal 1 for abnormal\n",
    "    for i in range(0, y_val.shape[0]):\n",
    "        if y_val[i] == -1:\n",
    "            y_val[i] = 0\n",
    "\n",
    "    ############# Parse Database names ########\n",
    "\n",
    "    train_files = []\n",
    "    for each in feat.root.train_files[:][0]:\n",
    "        train_files.append(chr(each))\n",
    "    print(len(train_files))\n",
    "    val_files = []\n",
    "    for each in feat.root.val_files[:][0]:\n",
    "        val_files.append(chr(each))\n",
    "    print(len(val_files))\n",
    "\n",
    "    ################### Reshaping ############\n",
    "\n",
    "    x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "\n",
    "    if _categorical:\n",
    "        y_train = to_categorical(y_train, num_classes=2)\n",
    "        y_val = to_categorical(y_val, num_classes=2)\n",
    "    \n",
    "    if quality:\n",
    "        return x_train, y_train, train_files, train_parts, q_train, \\\n",
    "                x_val, y_val, val_files, val_parts, q_val\n",
    "    else:\n",
    "        return x_train, y_train, train_files, train_parts, \\\n",
    "                x_val, y_val, val_files, val_parts\n",
    "\n",
    "def load_model(log_name,verbose=0,\n",
    "               model_dir='../models/',\n",
    "               log_dir='../logs/'):\n",
    "    \n",
    "#     model_dir = '/media/mhealthra2/Data/heart_sound/models/'\n",
    "#     log_dir = '/media/mhealthra2/Data/heart_sound/logs/'\n",
    "\n",
    "    if os.path.isdir(model_dir+log_name):\n",
    "        print(\"Model directory found\")\n",
    "        if os.path.isfile(os.path.join(model_dir+log_name,\"model.json\")):\n",
    "            print(\"model.json found. Importing\")\n",
    "        else:\n",
    "            raise ImportError(\"model.json not found\")\n",
    "\n",
    "    with open(os.path.join(model_dir+log_name,\"model.json\")) as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "    try:\n",
    "        model = model_from_json(loaded_model_json,{'Conv1D_linearphase':Conv1D_linearphase,\n",
    "                                               'DCT1D':DCT1D,\n",
    "                                               'Conv1D_linearphaseType':Conv1D_linearphaseType,\n",
    "                                               'Conv1D_gammatone' : Conv1D_gammatone,\n",
    "                                                'Conv1D_zerophase' : Conv1D_zerophase,\n",
    "                                              })\n",
    "    except:\n",
    "        model = model_from_json(loaded_model_json,{'Conv1D_linearphase':Conv1D_linearphase,\n",
    "                                               'DCT1D':DCT1D,\n",
    "                                               'Conv1D_linearphaseType':Conv1D_linearphaseType_legacy,\n",
    "                                               'Conv1D_gammatone' : Conv1D_gammatone,\n",
    "                                                   'Conv1D_zerophase' : Conv1D_zerophase,\n",
    "                                              })\n",
    "    if verbose:\n",
    "        print(log_name)\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "def cc2parts(cc,parts):\n",
    "    \n",
    "    if not len(cc) == sum(parts):\n",
    "        raise ValueError('Number of CC elements are not equal to total number of parts')\n",
    "    \n",
    "    labels = []\n",
    "    start_idx = 0\n",
    "#     cc = np.round(cc)\n",
    "    \n",
    "    for s in parts:\n",
    "        if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "            continue\n",
    "        temp = cc[start_idx:start_idx + int(s)]\n",
    "        try:\n",
    "            labels.append(np.mean(temp,axis=0))\n",
    "        except TypeError: ## TypeError for string input in train_files\n",
    "            labels.append(cc[start_idx])\n",
    "        start_idx = start_idx + int(s)\n",
    "    return np.asarray(labels)\n",
    "\n",
    "def parts2cc(partitioned,parts):\n",
    "    \n",
    "    labels = []\n",
    "    parts = parts[np.nonzero(parts)]\n",
    "    for each,part in zip(partitioned,parts):\n",
    "            labels += list(np.repeat(each,part))\n",
    "    return np.asarray(labels)\n",
    "\n",
    "def predict_parts(model,data,labels,parts,filenames=None,verbose=1,soft=False):\n",
    "    y_pred = model.predict(data, verbose=verbose)\n",
    "    true = []\n",
    "    pred = []\n",
    "    files= []\n",
    "    start_idx = 0\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    y_val = np.transpose(np.argmax(labels, axis=-1))\n",
    "    for s in parts:\n",
    "        if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "            continue\n",
    "        # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "        temp_ = y_val[start_idx:start_idx + int(s)]\n",
    "        temp = y_pred[start_idx:start_idx + int(s)]\n",
    "        if (sum(temp == 0) > sum(temp == 1)):\n",
    "            pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "\n",
    "        if (sum(temp_ == 0) > sum(temp_ == 1)):\n",
    "            true.append(0)\n",
    "        else:\n",
    "            true.append(1)\n",
    "\n",
    "        if filenames is not None:\n",
    "            files.append(filenames[start_idx])\n",
    "        start_idx = start_idx + int(s)\n",
    "    \n",
    "    if soft:\n",
    "        pred = cc2parts(y_pred,parts)\n",
    "    return pred,true,files\n",
    "\n",
    "def eerPred(true,pred,verbose=1):\n",
    "    if pred.ndim > 1:\n",
    "            pred = pred[:,-1]\n",
    "    fpr,tpr,thresh = roc_curve(true,pred)\n",
    "    diff = abs(tpr-(1-fpr))\n",
    "    pred = pred > thresh[np.where(diff == min(diff))[0]]\n",
    "    if verbose:\n",
    "        print('Threshold selected as %f'%thresh[np.where(diff == min(diff))[0]])\n",
    "    return pred\n",
    "\n",
    "def calc_metrics(true,pred,files=None,verbose=1,eps=1E-10,thresh=.5):\n",
    "        if thresh=='EER':\n",
    "            TN, FP, FN, TP = confusion_matrix(true, eerPred(true,pred), labels=[0,1]).ravel()\n",
    "        else:\n",
    "            TN, FP, FN, TP = confusion_matrix(true, np.asarray(pred) > thresh, labels=[0,1]).ravel()\n",
    "        sensitivity = TP / (TP + FN + eps)\n",
    "        specificity = TN / (TN + FP + eps)\n",
    "        precision = TP / (TP + FP + eps)\n",
    "        F1 = 2 * (precision * sensitivity) / (precision + sensitivity + eps)\n",
    "        Macc = (sensitivity + specificity) / 2\n",
    "        MCC = (TP*TN-FP*FN)/((TP+FP)*(FN+TN)*(FP+TN)*(TP+FN))**.5\n",
    "        auc = roc_auc_score(true,pred)\n",
    "        logs = dict()\n",
    "        logs['val_sensitivity'] = np.array(sensitivity)\n",
    "        logs['val_specificity'] = np.array(specificity)\n",
    "        logs['val_precision'] = np.array(precision)\n",
    "        logs['val_F1'] = np.array(F1)\n",
    "        logs['val_macc'] = np.array(Macc)\n",
    "        logs['auc'] = np.array(auc)\n",
    "        logs['val_mcc'] = np.array(MCC).astype(np.float64)\n",
    "        if verbose:\n",
    "            print(\"TN:{},FP:{},FN:{},TP:{},Macc:{},F1:{}\".format(TN, FP, FN, TP,Macc,F1))\n",
    "        if files is not None:\n",
    "            true = np.asarray(true)\n",
    "            pred = np.asarray(pred) > .5\n",
    "            files = np.asarray(files)\n",
    "            tpn = true == pred\n",
    "            avg = 0\n",
    "            for dataset in np.unique(files):\n",
    "                mask = files == dataset\n",
    "                avg = avg + np.sum(tpn[mask])/np.sum(mask)/len(np.unique(files))\n",
    "                logs['acc_'+dataset] = np.sum(tpn[mask])/np.sum(mask)\n",
    "            logs['acc_avg'] = avg\n",
    "        df = pd.Series(logs)\n",
    "        return df\n",
    "\n",
    "\n",
    "def log_fusion(logs,data,labels,fusion_weights=None,min_epoch=20,min_metric=.7,\n",
    "               metric='val_macc',model_dir='../models/',verbose=0):        \n",
    "    '''\n",
    "    Returns fused predictions\n",
    "    '''\n",
    "    if not type(logs) == list:\n",
    "        logs = [logs]\n",
    "    \n",
    "    if fusion_weights is None:\n",
    "        fusion_weights = np.ones((len(logs)))\n",
    "    else:\n",
    "        if not len(logs)==len(fusion_weights):\n",
    "            raise ValueError('Fusion weights not consistent with number of models')\n",
    "    pred = np.zeros((data.shape[0],2))\n",
    "    \n",
    "    for log_name,weight in zip(logs,fusion_weights):\n",
    "        model = load_model(log_name,verbose=verbose)\n",
    "        weights = get_weights(log_name,min_epoch=min_epoch,\n",
    "                              min_metric=min_metric,verbose=verbose)\n",
    "        checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "        model.load_weights(checkpoint_name)\n",
    "        pred += model.predict(data,verbose=verbose)*weight\n",
    "    pred /= sum(fusion_weights)\n",
    "    # pred = np.argmax(pred,axis=-1)\n",
    "    return pred\n",
    "\n",
    "def model_confidence(model,data,labels,verbose=0):\n",
    "    '''\n",
    "    Give confidence score for true class\n",
    "    '''\n",
    "    pred = model.predict(data,verbose=verbose)\n",
    "    \n",
    "    if np.asarray(labels).ndim >1:\n",
    "        labels = np.argmax(labels,axis=-1)\n",
    "    \n",
    "    pred = [pred[idx,each] for idx,each in enumerate(labels)]\n",
    "    \n",
    "    return np.asarray(pred)\n",
    "\n",
    "def plot_coeff(logs,branches=[1,2,3,4],min_epoch=20,min_metric=.7,\n",
    "             metric='val_macc',model_dir='../models/',\n",
    "             figsize=(10,6),verbose=0):\n",
    "    '''\n",
    "    Plot Learnable FIRs for logs\n",
    "    '''\n",
    "    if not type(logs) == list:\n",
    "        logs = [logs]\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, ax = plt.subplots(len(branches), len(logs), sharex='col', sharey='row', figsize=figsize)\n",
    "    \n",
    "    for _idx,log_name in enumerate(logs):\n",
    "        model = load_model(log_name,verbose=verbose)\n",
    "        weights = get_weights(log_name,min_epoch=min_epoch,\n",
    "                              min_metric=min_metric,verbose=verbose)\n",
    "        checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "        model.load_weights(checkpoint_name)\n",
    "        \n",
    "        FIR_coeff = []\n",
    "        layer_name = []\n",
    "        layer_type = []\n",
    "        \n",
    "        ## Get filter coefficients\n",
    "        for branch in branches:\n",
    "            if not 'gammatone' in model.layers[branch].name:\n",
    "                FIR_coeff.append(np.asarray(model.layers[branch].get_weights())[0,:,0,0])\n",
    "                layer_name.append(model.layers[branch].name)\n",
    "            else: # for gammatone\n",
    "                FIR_coeff.append(K.get_session().run(model.layers[branch].impulse_gammatone()))\n",
    "                layer_name.append(model.layers[branch].name)\n",
    "            try:\n",
    "                layer_type.append(model.layers[branch].FIR_type)\n",
    "            except: # if not linear phase\n",
    "                layer_type.append(0)\n",
    "        \n",
    "        for idx,coeff in enumerate(FIR_coeff):\n",
    "            \n",
    "            ## Flip-concat coefficients for Linearphase\n",
    "            if 'linearphase' in layer_name[idx]:\n",
    "                if layer_type[idx] == 1:\n",
    "                    FIR_coeff[idx] = np.concatenate([np.flip(FIR_coeff[idx][1:],axis=0),FIR_coeff[idx]])  \n",
    "                elif layer_type[idx] == 2:\n",
    "                    FIR_coeff[idx] = np.concatenate([np.flip(FIR_coeff[idx],axis=0),FIR_coeff[idx]])\n",
    "                elif layer_type[idx] == 3:\n",
    "                    FIR_coeff[idx] = np.concatenate([-1*np.flip(FIR_coeff[idx][1:],axis=0),FIR_coeff[idx]])  \n",
    "                else:\n",
    "                    FIR_coeff[idx] = np.concatenate([-1*np.flip(FIR_coeff[idx],axis=0),FIR_coeff[idx]])\n",
    "                    \n",
    "            \n",
    "            ax[idx,_idx].plot((FIR_coeff[idx]-np.mean(FIR_coeff[idx]))/np.std(FIR_coeff[idx]))\n",
    "    \n",
    "    plt.tight_layout()     \n",
    "    plt.show()\n",
    "    return ax\n",
    "    \n",
    "def plot_freq(logs,branches=[1,2,3,4],phase=False,min_epoch=20,min_metric=.7,\n",
    "             metric='val_macc',model_dir='../models/',\n",
    "             figsize=(10,6),verbose=0):\n",
    "    '''\n",
    "    Plot Learnable FIRs for logs\n",
    "    '''\n",
    "    if not type(logs) == list:\n",
    "        logs = [logs]\n",
    "    sns.set_style('whitegrid')\n",
    "    fig, ax = plt.subplots(len(branches), len(logs), sharex='col', sharey='row', figsize=figsize)\n",
    "    \n",
    "    for _idx,log_name in enumerate(logs):\n",
    "        model = load_model(log_name,verbose=verbose)\n",
    "        weights = get_weights(log_name,min_epoch=min_epoch,\n",
    "                              min_metric=min_metric,verbose=verbose)\n",
    "        checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "        model.load_weights(checkpoint_name)\n",
    "        \n",
    "        FIR_coeff = []\n",
    "        layer_name = []\n",
    "        layer_type = []\n",
    "        \n",
    "        ## Get filter coefficients\n",
    "        for branch in branches:\n",
    "            if not 'gammatone' in model.layers[branch].name:\n",
    "                FIR_coeff.append(np.asarray(model.layers[branch].get_weights())[0,:,0,0])\n",
    "                layer_name.append(model.layers[branch].name)\n",
    "            else: # for gammatone\n",
    "                FIR_coeff.append(K.get_session().run(model.layers[branch].impulse_gammatone()))\n",
    "                layer_name.append(model.layers[branch].name)\n",
    "            try:\n",
    "                layer_type.append(model.layers[branch].FIR_type)\n",
    "            except: # if not linear phase\n",
    "                layer_type.append(0)\n",
    "        \n",
    "        for idx,coeff in enumerate(FIR_coeff):\n",
    "            \n",
    "            ## Flip-concat coefficients for Linearphase\n",
    "            if 'linearphase' in layer_name[idx]:\n",
    "                if layer_type[idx] == 1:\n",
    "                    FIR_coeff[idx] = np.concatenate([np.flip(FIR_coeff[idx][1:],axis=0),FIR_coeff[idx]])  \n",
    "                elif layer_type[idx] == 2:\n",
    "                    FIR_coeff[idx] = np.concatenate([np.flip(FIR_coeff[idx],axis=0),FIR_coeff[idx]])\n",
    "                elif layer_type[idx] == 3:\n",
    "                    FIR_coeff[idx] = np.concatenate([-1*np.flip(FIR_coeff[idx][1:],axis=0),FIR_coeff[idx]])  \n",
    "                else:\n",
    "                    FIR_coeff[idx] = np.concatenate([-1*np.flip(FIR_coeff[idx],axis=0),FIR_coeff[idx]])\n",
    "            \n",
    "            w,freq_res=signal.freqz(FIR_coeff[idx])\n",
    "            ax[idx,_idx].plot(w/np.pi*500,10*np.log10(abs(freq_res)/max(abs(freq_res))))\n",
    "            if phase:\n",
    "                angles = np.unwrap(np.angle(freq_res))\n",
    "                ax2 = ax[idx,_idx].twinx()\n",
    "                ax2.plot(w/np.pi*500, angles, 'g')\n",
    "\n",
    "    plt.tight_layout()     \n",
    "#     plt.show()\n",
    "    return ax\n",
    "\n",
    "def plot_metric(logs,metric='val_loss',smoothing=0.1,lognames=None,xlim=None,ylim=None,\n",
    "                figsize=(10,6),legendLoc=0,colors=None,ax=None):\n",
    "    '''\n",
    "    Plot specified metric for logs\n",
    "    smooth: smoothing factor for each plot \n",
    "    ''' \n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots(figsize=figsize)\n",
    "    for idx,log in enumerate(logs):\n",
    "        log_dir='../logs'\n",
    "        if not os.path.isdir(os.path.join(log_dir,log)):\n",
    "            log_dir = '/media/mhealthra2/Data/heart_sound/logs'          \n",
    "        training_csv = os.path.join(log_dir,log,\"training.csv\")\n",
    "        df = pd.read_csv(training_csv)\n",
    "        data = np.asarray(df[metric].values)\n",
    "            \n",
    "        if colors is not None:\n",
    "            ax.plot(smooth(data,smoothing),color=colors[idx])\n",
    "        else:\n",
    "            ax.plot(smooth(data,smoothing))\n",
    "\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    if lognames is not None:\n",
    "        ax.legend(lognames,loc=legendLoc)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel(metric)\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "def plot_log_metrics(log,metrics=['acc_a','acc_e'],labels=None,smoothing=0.1,\n",
    "                     xlim=None,ylim=None,figsize=(10,6),legendLoc=0,colors=None,ax=None):\n",
    "    '''\n",
    "    Plot multiple metrics of the same log\n",
    "    '''\n",
    "    log_dir='../logs'\n",
    "    if not os.path.isdir(os.path.join(log_dir,log)):\n",
    "        log_dir = '/media/mhealthra2/Data/heart_sound/logs'          \n",
    "    training_csv = os.path.join(log_dir,log,\"training.csv\")\n",
    "    df = pd.read_csv(training_csv)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots(figsize=figsize)\n",
    "    for idx,metric in enumerate(metrics):\n",
    "        data = np.asarray(df[metric].values)\n",
    "        if colors is not None:\n",
    "            ax.plot(smooth(data,smoothing),color=colors[idx])\n",
    "        else:\n",
    "            ax.plot(smooth(data,smoothing))\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "#     if lognames is not None:\n",
    "#         ax.legend(metrics,loc=legendLoc)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    return ax\n",
    "\n",
    "def idx_parts2cc(partidx,parts):\n",
    "    \n",
    "    if type(partidx) == int:\n",
    "        partidx = [partidx]\n",
    "        \n",
    "    idx = []\n",
    "    for each in partidx:\n",
    "        start_idx = int(sum(parts[:each]))\n",
    "        end_idx = int(start_idx + parts[each])\n",
    "        idx = idx+range(start_idx,end_idx)\n",
    "    return idx\n",
    "\n",
    "def grad_cam(model,layer_name,data,label,scale=True,verbose=0):\n",
    "    \n",
    "    if data.ndim < 3:\n",
    "        data = np.expand_dims(data,axis=0)\n",
    "    output = model.output[:,1-int(label)]\n",
    "    last_conv_layer = model.get_layer(layer_name) ##### have to change the name here\n",
    "    grads = K.gradients(output, last_conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1)) ### no idea what to do here\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([data])\n",
    "    for i in range(pooled_grads_value.shape[0]):\n",
    "        if verbose:\n",
    "            print(\"Iteration %d\" % i)\n",
    "        conv_layer_output_value[ :, i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    if scale:\n",
    "        x = np.linspace(0, data.shape[1], num=len(heatmap))\n",
    "        y = heatmap\n",
    "        f1 = interp1d(x, y, kind='cubic')\n",
    "        xnew = np.linspace(0, data.shape[1], num=data.shape[1])\n",
    "        ynew = f1(xnew)\n",
    "        return ynew\n",
    "    else:\n",
    "        return heatmap\n",
    "\n",
    "def cc2rec(data):\n",
    "    rec = []\n",
    "    for cc in data:\n",
    "        idx = np.where(cc!=0)[0]\n",
    "        cc = cc[:idx[-1],0]\n",
    "        rec.append(cc)\n",
    "    return np.asarray(np.hstack(rec))\n",
    "\n",
    "def cc2rec_labels(data,labels):\n",
    "    gt = []\n",
    "    for i,cc in enumerate(data):\n",
    "        idx = np.where(cc!=0)[0]\n",
    "        cctr = np.ones(idx[-1])*labels[i]\n",
    "        gt.append(cctr)    \n",
    "    return np.asarray(np.hstack(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory found\n",
      "model.json found. Importing\n",
      "Model directory found\n",
      "model.json found. Importing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plot_coeff([\n",
    "            \"potes_fold0_noFIR 2019-03-02 13_01_33.636778\",\n",
    "            \"fold0_noFIR 2019-03-07 14_44_47.022240\"\n",
    "#             \"fold0_noFIR 2019-02-24 18_02_57.053839\",\n",
    "            \n",
    "#           \"fold0_noFIR 2019-02-27 19_52_21.543329\",\n",
    "#           \"fold2_noFIR 2019-01-17 04_16_51.868927\", # random\n",
    "#           \"fold1_noFIR 2019-01-13 15_04_39.094472\", \n",
    "#           \"fold1_noFIR 2019-02-16 12_28_19.127331\", # densenet\n",
    "#             \"fold0_noFIR 2019-03-06 14_21_29.823568\", # bi-conv stage1\n",
    "#            \"fold0_noFIR 2019-03-06 21_42_10.719836\", # bi-conv stage2\n",
    "#           \"fold0_noFIR 2019-03-09 01_34_03.547265\", #gamma stage 1\n",
    "#             \"fold0_noFIR 2019-03-09 07_12_26.773316\", #gamma stage 2\n",
    "#             \"fold0_noFIR 2019-03-08 03_28_46.740442\", #type3\n",
    "#             \"potes_fold0_noFIR 2019-03-16 18_44_45.597226\"\n",
    "         ],min_epoch=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/feature/folds/fold0_noFIR\n",
      "79810\n",
      "6710\n",
      "(79810, 2500, 1)\n",
      "(79810, 1)\n",
      "(6710, 2500, 1)\n",
      "(6710, 1)\n"
     ]
    }
   ],
   "source": [
    "# foldname = 'fold1+compare'\n",
    "fold_dir = '../data/feature/folds/'\n",
    "\n",
    "# x_train, y_train, train_files,train_parts, q_train, \\\n",
    "#     x_val, y_val,val_files,val_parts, q_val = load_data(foldname,fold_dir,quality=True)\n",
    "    \n",
    "# test_parts = train_parts[0][np.asarray(train_files) =='x']\n",
    "# test_parts = np.concatenate([test_parts,val_parts[np.asarray(val_files)=='x']],axis=0)\n",
    "# train_files = parts2cc(train_files,train_parts[0])\n",
    "# val_files = parts2cc(val_files,val_parts)\n",
    "# x_test = x_train[train_files == 'x']\n",
    "# x_test = np.concatenate([x_test,x_val[val_files=='x']])\n",
    "# y_test = y_train[train_files == 'x']\n",
    "# y_test = np.concatenate([y_test,y_val[val_files=='x']])\n",
    "# test_files = np.concatenate([train_files[train_files == 'x'],\n",
    "#                             val_files[val_files == 'x']])\n",
    "# q_test = np.concatenate([q_train[train_files == 'x'],\n",
    "#                             q_val[val_files == 'x']])\n",
    "# del x_train, y_train, train_files,train_parts, q_train, \\\n",
    "#     x_val, y_val,val_files,val_parts, q_val\n",
    "    \n",
    "    \n",
    "foldname = 'fold0_noFIR'\n",
    "x_train, y_train, train_files,train_parts, q_train, \\\n",
    "    x_val, y_val,val_files,val_parts, q_val = load_data(foldname,fold_dir,quality=True) # also return recording quality\n",
    "\n",
    "train_parts = train_parts[np.nonzero(train_parts)] ## Some have zero cardiac cycle\n",
    "val_parts = val_parts[np.nonzero(val_parts)]\n",
    "\n",
    "x_test = x_val\n",
    "y_test = y_val\n",
    "test_parts = val_parts\n",
    "test_files = val_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test2Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# frac=.3\n",
    "# print('Before Test partition')\n",
    "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, train_parts.shape, test_parts.shape)\n",
    "\n",
    "# test_files = np.repeat('g',len(test_files),axis=0)\n",
    "# random_seed = 1\n",
    "# np.random.seed(random_seed)\n",
    "# part_idx = np.random.permutation(range(len(test_parts)))\n",
    "# part_idx = part_idx[:int(len(test_parts) * frac)]\n",
    "# cc_idx = idx_parts2cc(part_idx, test_parts)\n",
    "\n",
    "# # train_parts = np.concatenate([train_parts, test_parts[part_idx]], axis=0)\n",
    "# test_parts = np.delete(test_parts, part_idx, axis=0)\n",
    "# # val_parts = np.concatenate([val_parts, test_parts], axis=0)\n",
    "\n",
    "# # train_files = np.concatenate([train_files, test_files[cc_idx]], axis=0)\n",
    "# test_files = np.delete(test_files, cc_idx, axis=0)\n",
    "# # val_files = np.concatenate([val_files, test_files], axis=0)\n",
    "\n",
    "# # x_train = np.concatenate([x_train, x_test[cc_idx]], axis=0)\n",
    "# x_test = np.delete(x_test, cc_idx, axis=0)\n",
    "# # x_val = np.concatenate([x_val, x_test], axis=0)\n",
    "\n",
    "# # y_train = np.concatenate([y_train, y_test[cc_idx]], axis=0)\n",
    "# y_test = np.delete(y_test, cc_idx, axis=0)\n",
    "# # y_val = np.concatenate([y_val, y_test], axis=0)\n",
    "\n",
    "# print('After Test partition with fraction', frac)\n",
    "# print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, train_parts.shape, test_parts.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model\n",
    "#### To to the McNemer test run Model.Predict with Type2 log_name\n",
    "#### The come back and uncomment the potes log_name then run until Model.Predict again.\n",
    "#### Finally run the McNembers Test block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory found\n",
      "model.json found. Importing\n",
      "fold0_noFIR 2019-03-07 14_44_47.022240\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_1 (Conv (None, 2500, 1)      30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_2 (Conv (None, 2500, 1)      30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_3 (Conv (None, 2500, 1)      30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_linearphase_type_4 (Conv (None, 2500, 1)      30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_type_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_type_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_type_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 2496, 8)      40          conv1d_linearphase_type_4[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2496, 8)      32          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2496, 8)      32          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2496, 8)      32          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2496, 8)      32          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2496, 8)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2496, 8)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2496, 8)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2496, 8)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2496, 8)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2496, 8)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2496, 8)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 2496, 8)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1248, 8)      0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1248, 8)      0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1248, 8)      0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1248, 8)      0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1244, 4)      160         max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1244, 4)      16          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1244, 4)      16          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1244, 4)      16          conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1244, 4)      16          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1244, 4)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1244, 4)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1244, 4)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1244, 4)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1244, 4)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1244, 4)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1244, 4)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1244, 4)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 622, 4)       0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 622, 4)       0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 622, 4)       0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 622, 4)       0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 622, 16)      0           max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "                                                                 max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9952)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           199040      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 20)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            42          dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 200,194\n",
      "Trainable params: 200,098\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n",
      "Best Sensitivity model: 0.9057970292480628 \t\tweights.0085-0.7514.hdf5\n",
      "Best Specificity model: 0.7191780280071348 \t\tweights.0263-0.7565.hdf5\n",
      "Best Macc model: 0.8090628713513744 \t\tweights.0085-0.7514.hdf5\n",
      "Best Val model: 0.7703427713192256 \t\t\tweights.0289-0.7703.hdf5\n"
     ]
    }
   ],
   "source": [
    "## Heartnet\n",
    "log_name = \"fold0_noFIR 2019-03-07 14_44_47.022240\" # Type2 macc 80 epoch\n",
    "\n",
    "## Potes \n",
    "# log_name = \"potes_fold0_noFIR 2019-03-02 13_01_33.636778\"\n",
    "\n",
    "\n",
    "# log_name = \"fold0_noFIR 2019-02-24 18_02_57.053839\"\n",
    "# log_name = \"fold0_noFIR 2019-03-09 01_34_03.547265\"\n",
    "# log_name = \"fold0_noFIR 2019-02-24 18_02_57.053839\" # Type1 macc\n",
    "# log_name = \"potes_fold0_noFIR 2019-03-02 13_01_33.636778\" # potes\n",
    "# log_name = \"fold0_noFIR 2019-03-09 01_34_03.547265\" #gamma stage 1\n",
    "\n",
    "# log_name = \"fold0_noFIR 2019-03-08 03_28_46.740442\" # Type3 sensitivity/spec for balanced\n",
    "# log_name = \"fold0_noFIR 2019-03-08 14_50_52.332924\" # type4 val_acc\n",
    "# log_name = \"fold0_noFIR 2019-03-06 21_42_10.719836\" #zero stage2\n",
    "# log_name = \"potes_fold0_noFIR 2019-03-16 18_44_45.597226\" #potes non balanced\n",
    "\n",
    "### Trained with both train and test\n",
    "\n",
    "# log_name = \"fold0_noFIR 2019-03-24 18_55_14.833080\" #frac=.1\n",
    "# log_name = \"fold0_noFIR 2019-03-24 23_14_47.400720\" #frac=.2\n",
    "# log_name = 'fold0_noFIR 2019-03-25 03_34_29.171850' #frac=.3\n",
    "\n",
    "### Fine tuned with test\n",
    "\n",
    "# log_name = \"fold0_noFIR 2019-04-16 14_48_05.398094\"\n",
    "# log_name = \"fold0_noFIR 2019-04-20 17_44_16.413759\"\n",
    "\n",
    "model = load_model(log_name,verbose=1)\n",
    "weights = get_weights(log_name,min_epoch=80,min_metric=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded:\n",
      " ../models/fold0_noFIR 2019-03-07 14_44_47.022240/weights.0085-0.7514.hdf5\n"
     ]
    }
   ],
   "source": [
    "metric = 'val_macc'\n",
    "model_dir = '../models/'\n",
    "\n",
    "checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "model.load_weights(checkpoint_name)\n",
    "print(\"Checkpoint loaded:\\n %s\" % checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_num = 1\n",
    "# model_dir = '/media/mhealthra2/Data/heart_sound/models/'\n",
    "\n",
    "# checkpoint_name = os.path.join(model_dir+log_name,weights['epoch'][epoch_num])\n",
    "# model.load_weights(checkpoint_name)\n",
    "# print(\"Checkpoint loaded:\\n %s\" % checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6710, 2500, 1), (6710, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Calculating metrics for test\n",
      "6710/6710 [==============================] - 1s 202us/step\n",
      "TN:106,FP:40,FN:16,TP:122,Macc:0.8050426841368145,F1:0.8133333332831112\n",
      "val_sensitivity    0.8840579710138522\n",
      "val_specificity    0.7260273972597767\n",
      "val_precision      0.7530864197526216\n",
      "val_F1             0.8133333332831112\n",
      "val_macc           0.8050426841368145\n",
      "auc                0.8383462378399841\n",
      "val_mcc            0.6159836117125793\n",
      "acc_a                           0.725\n",
      "acc_b                        0.734694\n",
      "acc_c                               1\n",
      "acc_d                             0.7\n",
      "acc_e                         0.94382\n",
      "acc_avg                      0.820703\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print('Calculating metrics for Training set')\n",
    "# pred,true,files = predict_parts(model,x_train,y_train,train_parts,train_files)\n",
    "# res = calc_metrics(true,pred,files)\n",
    "# print(res)\n",
    "\n",
    "\n",
    "# print('Calculating metrics for all of Validation')\n",
    "# pred,true,files = predict_parts(model,x_val,y_val,val_parts,val_files,soft=True)\n",
    "# res = calc_metrics(true,pred,files)\n",
    "# print(res)\n",
    "\n",
    "print('\\n\\nCalculating metrics for test')\n",
    "pred,true,files = predict_parts(model,x_test,y_test,test_parts,test_files,soft=True)\n",
    "res = calc_metrics(true,pred,files)\n",
    "print(res)\n",
    "\n",
    "###########################   added by rakib   #########################\n",
    "## Keeping the results of the validation set\n",
    "## Run with a potes model, and with a proposed model\n",
    "pred_potes = None\n",
    "pred_proposed = None\n",
    "if(\"potes\" in log_name):\n",
    "    pred_potes = pred\n",
    "else:\n",
    "    pred_proposed = pred\n",
    "    \n",
    "##################################################################\n",
    "    \n",
    "# print('\\n\\nCalculating metrics for good quality only')\n",
    "# pred,true,files = predict_parts(model,\n",
    "#                                 x_val[q_val>0],y_val[q_val>0],\n",
    "#                                 val_parts[cc2parts(q_val,val_parts)>0],\n",
    "#                                 np.asarray(val_files)[q_val>0])\n",
    "# res = calc_metrics(true,pred,files)\n",
    "# print(res)\n",
    "\n",
    "##################   Not running the test data  ###############\n",
    "\n",
    "# print('\\n\\nCalculating metrics for test')\n",
    "# pred,true,files = predict_parts(model,x_test,y_test,test_parts,test_files,soft=True)\n",
    "# res = calc_metrics(true,pred,files)\n",
    "# print(res)\n",
    "# pred_fir4 = pred\n",
    "# pred_proposed=pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRoc(y_true, y_pred,ax=None,label='',control=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    By providing an plt.subplot's \"ax\" instance you can plot multiple roc's on the same plot by \n",
    "    calling this function multiple times with the same \"ax\"\n",
    "    If none then it will generate multiple plots\n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score, roc_curve\n",
    "    lr_probs = y_pred\n",
    "    testy = y_true\n",
    "    ns_probs = [0 for _ in range(len(testy))]\n",
    "    # keep probabilities for the positive outcome only\n",
    "    #lr_probs = lr_probs[:, 1]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(testy, ns_probs)\n",
    "    lr_auc = roc_auc_score(testy, lr_probs)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "    # plot the roc curve for the model\n",
    "    if(ax is not None):\n",
    "        if control:\n",
    "            ax.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "        ax.plot(lr_fpr, lr_tpr,  label=label)\n",
    "        # axis labels\n",
    "        ax.set_xlabel('False Positive Rate',fontdict={'size':16})\n",
    "        ax.set_ylabel('True Positive Rate',fontdict={'size':16})\n",
    "        # show the legend\n",
    "        ax.legend( prop={'size':15})\n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "        plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic ')\n",
    "        # axis labels\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        # show the legend\n",
    "        plt.legend()\n",
    "        # show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "if(pred_proposed is not None):\n",
    "    plotRoc(true,pred_proposed,ax=ax,label='Type 2 tConv: AUC 0.83')\n",
    "if(pred_potes is not None):\n",
    "    plotRoc(true,pred_potes,ax=ax,label='Potes-CNN: AUC 0.499',control=False)\n",
    "# plotRoc(true,pred_fir4,ax=ax,label='TypeIV tConv-CNN: AUC 0.864',control=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "fig.savefig('roc.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McNemer Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from mlxtend.evaluate import mcnemar_table\n",
    "def McnemerStats(true,pred1,pred2,threshold = 0.05, lab1='model 1', lab2='model 2'):\n",
    "    \"\"\"\n",
    "    true: true labels of the data. \n",
    "    pred1: predicted values from model 1 ## generated from block 8\n",
    "    pred2: predicted values from model 2 ## generated from block 8\n",
    "    \"\"\"\n",
    "    pred1 = 1*(np.asarray(pred1) > 0.5)\n",
    "    pred2 = 1*(np.asarray(pred2) > .5)\n",
    "    true = np.asarray(true)\n",
    "    print(pred1.shape, pred2.shape, true.shape)\n",
    "    mc_table = mcnemar_table(y_target=true, \n",
    "                   y_model1=pred1, \n",
    "                   y_model2=pred2)\n",
    "    if(np.min(mc_table)<25):\n",
    "        result = mcnemar(mc_table, exact=True)\n",
    "    else:\n",
    "        result = mcnemar(mc_table, exact=False, correction=True)\n",
    "    print('statistic=%.10f, p-value=%.10f' % (result.statistic, result.pvalue))\n",
    "    # interpret the p-value\n",
    "    alpha = threshold\n",
    "    if result.pvalue > alpha:\n",
    "        print('Same proportions of errors, models make similar error (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different proportions of errors, error rates are different (reject H0)')\n",
    "    return result.statistic,result.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run the model with the potes Model\n"
     ]
    }
   ],
   "source": [
    "if(pred_potes is None):\n",
    "    print(\"Please run the model with the potes Model\")\n",
    "if(pred_proposed is None):\n",
    "    print(\"Please run the model with the hearnet type2 Model\")\n",
    "if(pred_potes is not None and pred_proposed is not None):\n",
    "    McnemerStats(true,pred_proposed,pred_potes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gabor vs Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor = pd.read_csv('gabor_result.csv')\n",
    "val_wav = pd.read_csv('val_file_names.txt',header=None)\n",
    "val_wav = [x[0] for x in val_wav.values]\n",
    "gtrue =[(gabor.loc[gabor['filenames']=='train_'+x[:-4],'true'].iloc[0]) for x in val_wav]\n",
    "gpred =[(gabor.loc[gabor['filenames']=='train_'+x[:-4],'pred'].iloc[0]) for x in val_wav]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284,) (284,) (284,)\n",
      "statistic=19.0000000000, p-value=0.0000000000\n",
      "Different proportions of errors, error rates are different (reject H0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.0, 7.697905243845305e-16)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "McnemerStats(true,pred_proposed,gpred,lab1='heartnet',lab2='gabor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.798\n",
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plotRoc(true,pred_proposed,ax=ax,label='GammaTone tConv: AUC 0.798')\n",
    "plotRoc(true,gpred,ax=ax,label=\"Gabor's algorithm: AUC 0.449\",control=False)\n",
    "# plotRoc(true,pred_fir4,ax=ax,label='TypeIV tConv-CNN: AUC 0.864',control=False)\n",
    "fig.savefig('gabor_vs_gammtonetconv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x is neither increasing nor decreasing : [1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1\n 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0\n 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-c12cc4c6d604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mauc\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             raise ValueError(\"x is neither increasing nor decreasing \"\n\u001b[0;32m---> 93\u001b[0;31m                              \": {}.\".format(x))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrapz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x is neither increasing nor decreasing : [1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1\n 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0\n 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]."
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.auc(true,gpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EER\n",
    "# pred = model.predict(x_train)\n",
    "# pred = cc2parts(pred,train_parts)[:,1]\n",
    "# true = cc2parts(y_train,train_parts)[:,1]\n",
    "# files = cc2parts(train_files,train_parts)\n",
    "# res = calc_metrics(true,pred,files,thresh='EER')\n",
    "# print(res)\n",
    "\n",
    "\n",
    "# pred = model.predict(x_val)\n",
    "# pred = cc2parts(pred,val_parts)[:,1]\n",
    "# true = cc2parts(y_val,val_parts)[:,1]\n",
    "# files = cc2parts(val_files,val_parts)\n",
    "# res = calc_metrics(true,pred,files,thresh='EER')\n",
    "# print(res)\n",
    "\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = cc2parts(pred,test_parts)[:,1]\n",
    "true = cc2parts(y_test,test_parts)[:,1]\n",
    "files = cc2parts(test_files,test_parts)\n",
    "res = calc_metrics(true,pred,files,thresh='EER')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calc_metrics(true,np.random.rand(len(true)),thresh='EER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_val)\n",
    "preds = cc2parts(preds[:,1],val_parts)\n",
    "true = cc2parts(y_val[:,1],val_parts)\n",
    "fpr,tpr,thresh = roc_curve(true,preds)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "diff = abs(tpr-(1-fpr))\n",
    "preds = preds > thresh[np.where(diff == min(diff))[0]]\n",
    "print(thresh[np.where(diff == min(diff))[0]])\n",
    "\n",
    "calc_metrics(true,preds,cc2parts(val_files,val_parts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)\n",
    "preds = cc2parts(preds[:,1],test_parts)\n",
    "true = cc2parts(y_test[:,1],test_parts)\n",
    "fpr,tpr,thresh = roc_curve(true,preds)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "diff = abs(tpr-(1-fpr))\n",
    "preds = preds > thresh[np.where(diff == min(diff))[0]]\n",
    "print(thresh[np.where(diff == min(diff))[0]])\n",
    "\n",
    "calc_metrics(true,preds,cc2parts(test_files,test_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=1,return_indices=True)\n",
    "_,y,partidx = rus.fit_resample(np.expand_dims(range(len(test_parts)),axis=-1),cc2parts(y_test[:,1],test_parts))\n",
    "ccidx= idx_parts2cc(partidx,test_parts)\n",
    "_parts = test_parts[partidx]\n",
    "x = x_test[ccidx]\n",
    "y = y_test[ccidx]\n",
    "_files = test_files[ccidx]\n",
    "\n",
    "pred,true,files = predict_parts(model,x,y,_parts,_files,soft=True)\n",
    "res = calc_metrics(true,pred,files,thresh='EER')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Fusion predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fusion Predict Val')\n",
    "model_dir = '../models/'\n",
    "# fusion_weights = [.8,1.2,.8,1.2]\n",
    "fusion_weights = [1,1,.4,1]\n",
    "\n",
    "pred = np.zeros((x_val.shape[0],2))\n",
    "for metric,weight in zip(weights.keys(),fusion_weights):\n",
    "    checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "    model.load_weights(checkpoint_name)\n",
    "    pred += model.predict(x_val,verbose=1)*weight\n",
    "pred /= sum(fusion_weights)\n",
    "# pred = np.argmax(pred,axis=-1)\n",
    "pred = pred[:,1]\n",
    "res = calc_metrics(cc2parts(np.argmax(y_val,axis=-1),val_parts),np.round(cc2parts(pred,val_parts)))\n",
    "print(res)\n",
    "\n",
    "print('\\n\\nFusion Predict Test')\n",
    "pred = np.zeros((x_test.shape[0],2))\n",
    "for metric,weight in zip(weights.keys(),fusion_weights):\n",
    "    checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "    model.load_weights(checkpoint_name)\n",
    "    \n",
    "    pred += model.predict(x_test,verbose=1)*weight\n",
    "pred /= sum(fusion_weights)\n",
    "# pred = np.argmax(pred,axis=-1)\n",
    "pred = pred[:,1]\n",
    "res = calc_metrics(cc2parts(np.argmax(y_test,axis=-1),test_parts),np.round(cc2parts(pred,test_parts)))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold model fusion predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory found\n",
      "model.json found. Importing\n",
      "Best Sensitivity model: 0.876811524312 \t\tweights.0269-0.7440.hdf5\n",
      "Best Specificity model: 0.760273915322 \t\tweights.0145-0.7449.hdf5\n",
      "Best Macc model: 0.794570118883 \t\tweights.0269-0.7440.hdf5\n",
      "Best Val model: 0.752011923428 \t\t\tweights.0206-0.7520.hdf5\n",
      "TN:62,FP:54,FN:241,TP:325,Macc:0.554343852808,F1:0.687830687783\n",
      "auc                0.5519221396368954\n",
      "val_F1             0.6878306877825001\n",
      "val_macc           0.5543438528082969\n",
      "val_mcc            0.0821820010938894\n",
      "val_precision      0.8575197889179795\n",
      "val_sensitivity    0.5742049469963649\n",
      "val_specificity    0.5344827586202289\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "logs=[\n",
    "(0,\"fold0_noFIR 2019-02-24 18:02:57.053839\",'val_macc',100,.7), # Type1 macc\n",
    "(1,\"fold0_noFIR 2019-03-09 01:34:03.547265\",'val_macc',100,.7), #gamma stage 1\n",
    "(0,\"fold0_noFIR 2019-03-07 14:44:47.022240\",'val_macc',80,.7), # Type2 macc 80 epoch\n",
    "(0,\"fold0_noFIR 2019-03-08 03:28:46.740442\",'val_sensitivity',100,.65), # Type3 sensitivity/spec for balanced\n",
    "(0,\"fold0_noFIR 2019-03-08 14:50:52.332924\",'val_acc',100,.7), # type4 val_acc\n",
    "(0,\"fold0_noFIR 2019-03-06 21:42:10.719836\",'val_macc',100,.7), #zero stage2\n",
    "]\n",
    "pred_fusion=0\n",
    "for weight,log,metric,epoch,min_metric in logs:\n",
    "    if not weight:\n",
    "        continue\n",
    "    model=load_model(log_name=log)\n",
    "    model_weights = get_weights(log_name=log,\n",
    "                                min_epoch=epoch,\n",
    "                                min_metric=min_metric)\n",
    "    model_dir = '../models/'\n",
    "    checkpoint_name = os.path.join(model_dir+log,model_weights[metric])\n",
    "    model.load_weights(checkpoint_name)\n",
    "    pred = model.predict(x_test)\n",
    "    pred = cc2parts(pred,test_parts)\n",
    "    pred_fusion += weight*pred\n",
    "\n",
    "pred_fusion /= sum([each[0] for each in logs])\n",
    "# pred_fusion = cc2parts(pred_fusion,test_parts)\n",
    "print(calc_metrics(true=cc2parts(y_test,test_parts)[:,1],pred=pred_fusion[:,1],verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = [\n",
    "    \"fold0_noFIR 2019-02-24 18:02:57.053839\", #Type1\n",
    "#     \"fold1_noFIR 2019-02-23 17:59:17.240365\"\n",
    " \n",
    "           ]\n",
    "pred = log_fusion(logs,x_test,y_test,min_metric=.7,\n",
    "                  metric='val_specificity',verbose=0)\n",
    "pred = pred[:,1]\n",
    "res = calc_metrics(cc2parts(np.argmax(y_test,axis=-1),test_parts),\n",
    "                   np.round(cc2parts(pred,test_parts)))\n",
    "print(res.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logs=[\n",
    "\"potes_fold0_noFIR 2019-03-02 13:01:33.636778\", # potes\n",
    "\"fold0_noFIR 2019-02-24 18:02:57.053839\", # Type1 macc\n",
    "\"fold0_noFIR 2019-03-07 14:44:47.022240\", # Type2 macc 80 epoch\n",
    "\"fold0_noFIR 2019-03-08 03:28:46.740442\", # Type3 sensitivity\n",
    "\"fold0_noFIR 2019-03-08 14:50:52.332924\", # type4 val_acc\n",
    "\"fold0_noFIR 2019-03-09 01:34:03.547265\", # gamma stage 1\n",
    "\"fold0_noFIR 2019-03-06 21:42:10.719836\", # zero stage2\n",
    "]\n",
    "lognames=[\n",
    "\"Static FIR\",\n",
    "\"Type I tConv\",\n",
    "\"Type II tConv\",\n",
    "\"Type III tConv\",\n",
    "\"Type IV tConv\",\n",
    "\"Gammatone tConv\",\n",
    "\"Zero Phase tConv\",\n",
    "]\n",
    "branchnames=[\n",
    "'Branch 1',\n",
    "'Branch 2',\n",
    "'Branch 3',\n",
    "'Branch 4',\n",
    "]\n",
    "ax = plot_freq(logs=logs,min_epoch=100,metric='val_macc',min_metric=.6,figsize=(17,7),phase=True)\n",
    "# ax[3,0].set_ylim([-6,6])\n",
    "# ax[3,2].set_xlim([0,59])\n",
    "# ax[3,4].set_xlim([0,59])\n",
    "# for axes,branch in zip(ax[:,0],branchnames):\n",
    "#     axes.set_ylabel('%s Gain' % branch)\n",
    "for axes,log in zip(ax[3,:],lognames):\n",
    "    axes.set_xlabel('%s Weights' % log)\n",
    "# plt.subplots_adjust(left=0.035,bottom=0.065)\n",
    "# # plt.savefig('coeffs.eps')\n",
    "# # plt.savefig('coeffs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for axes,log in zip(ax[3,:],lognames):\n",
    "#     axes.set_xlabel('%s Weights' % log)\n",
    "# plt.subplots_adjust(left=0.035,bottom=0.065)\n",
    "plt.savefig('coeffsFreq.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=[\n",
    "\"potes_fold0_noFIR 2019-03-16 18:44:45.597226\", # potes non balanced\n",
    "\"potes_fold0_noFIR 2019-03-02 13:01:33.636778\", # potes\n",
    "\"fold0_noFIR 2019-02-27 19:52:21.543329\", # Type1 macc\n",
    "\"fold0_noFIR 2019-03-07 14:44:47.022240\", # Type2 macc 80 epoch\n",
    "\"fold0_noFIR 2019-03-08 03:28:46.740442\", # Type3 sensitivity\n",
    "\"fold0_noFIR 2019-03-08 14:50:52.332924\", # type4 val_acc\n",
    "\"fold0_noFIR 2019-03-09 01:34:03.547265\", # gamma stage 1\n",
    "\"fold0_noFIR 2019-03-06 14:21:29.823568\", # zero stage2\n",
    "]\n",
    "lognames=[\n",
    "\"Potes-CNN\",\n",
    "\"Potes-CNN DBT\",\n",
    "\"Type I tConv\",\n",
    "\"Type II tConv\",\n",
    "\"Type III tConv\",\n",
    "\"Type IV tConv\",\n",
    "\"Gammatone tConv\",\n",
    "\"Zero Phase tConv\",\n",
    "]\n",
    "colors = [\n",
    "'#434B77',\n",
    "'#669966',\n",
    "'#c10061',\n",
    "'#ff51a5',\n",
    "'k',\n",
    "'#ffbe4f',\n",
    "#'#008080',\n",
    "'#DBBBBB',\n",
    "'#008080',\n",
    "         ]\n",
    "plot_metric(logs,lognames=lognames,smoothing=0.5,metric='val_loss',colors=colors,figsize=(10,8.5))\n",
    "plt.ylabel('Validation Loss per Cardiac Cycle')\n",
    "plt.ylim([0.44,0.65])\n",
    "# plt.savefig('validationLoss.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[\n",
    "#     'acc_a',\n",
    "    'acc_b',\n",
    "#     'acc_c',\n",
    "#     'acc_d',\n",
    "    'acc_e'\n",
    "]\n",
    "labels=[\n",
    "    'subset-a',\n",
    "#     'subset-b',\n",
    "#     'subset-c',\n",
    "#     'subset-d',\n",
    "    'subset-e'\n",
    "]\n",
    "ax = plot_metric([logs[0],logs[2]],metrics,smoothing=0.7,legendLoc=0,ylim=[.4,1.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_ylabel('Subset-wise Validation Accuracy')\n",
    "ax.legend(['Subset-a w/o DBT','Subset-e w/o DBT','Subset-a w/ DBT','Subset-e w/ DBT'],loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Activations and TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recBins = [117,385,7,27,1867,80,116,292,104,24,28,151,34,566];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_labels = np.asarray([ord(each)- 97 for each in train_files+val_files+list(test_files)])\n",
    "meta_labels[meta_labels == 23] = 6\n",
    "y = np.argmax(np.concatenate([y_train,y_val,y_test]),axis=-1)\n",
    "\n",
    "for idx,each in enumerate(np.unique(meta_labels)):\n",
    "        indices = np.where(np.logical_and(y==1,meta_labels == each))\n",
    "        meta_labels[indices] = 7 +idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109453, 9952)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = np.array(get_activations(model,np.concatenate([x_train,x_val,x_test],axis=0),\n",
    "                                       batch_size=64,layer_name='flatten_1'))\n",
    "if activations.ndim > 2:\n",
    "    activations = np.reshape(activations,(len(activations),-1))\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_labels=meta_labels[0:len(activations)]\n",
    "quality_labels=np.concatenate([q_train,q_val,q_test],axis=0)[0:len(activations)]\n",
    "\n",
    "idx = []\n",
    "for subset,each in zip(np.unique(meta_labels),recBins):\n",
    "    np.random.seed(1)\n",
    "    idx = idx+list(np.random.choice(np.where([meta_labels==subset])[1],size=(each,),replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:193: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 1441 nearest neighbors...\n",
      "[t-SNE] Indexed 3798 samples in 1.149s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:268: DeprecationWarning: check_pickle is deprecated in joblib 0.12 and will be removed in 0.13\n",
      "  ' removed in 0.13', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 3798 samples in 180.650s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3798\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3798\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3798\n",
      "[t-SNE] Computed conditional probabilities for sample 3798 / 3798\n",
      "[t-SNE] Mean sigma: 12.742890\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 49.317589\n",
      "[t-SNE] KL divergence after 750 iterations: 0.738693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3798, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rus = RandomUnderSampler(random_state=1,return_indices=True)\n",
    "# x,y,idx = rus.fit_resample(activations[quality_labels>0],meta_labels[quality_labels>0])\n",
    "# np.random.seed(1)\n",
    "# idx = np.random.choice(range(len(meta_labels)),size=(3792,),replace=False)\n",
    "x = activations[idx]\n",
    "y = meta_labels[idx]\n",
    "X_embed = scale(x)\n",
    "\n",
    "# X_embedded = PCA(n_components=50).fit_transform(X_embed)\n",
    "\n",
    "X_embedded = TSNE(n_components=2,\n",
    "#                   learning_rate=60,\n",
    "#                   early_exaggeration=1140.,\n",
    "                  perplexity=480, #480-2, 150-3 without exagg and lr\n",
    "                  init='random',\n",
    "                  n_iter=4000,\n",
    "                  verbose=1,\n",
    "                  ).fit_transform(X_embed)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "import matplotlib.font_manager as font_manager\n",
    "font_prop = font_manager.FontProperties(size=14)\n",
    "font_title = font_manager.FontProperties(size=20)\n",
    "\n",
    "colors = ['#434B77',\n",
    "          '#669966',\n",
    "          '#c10061',\n",
    "          '#ff51a5',\n",
    "          'k',\n",
    "          '#ffbe4f',\n",
    "#           '#008080',\n",
    "          '#DBEEEE',\n",
    "          '#008080',\n",
    "         ]\n",
    "# y_ = y_>6\n",
    "subsets = [\"Eko CORE Bluetooth\",\n",
    "\"Welch Allyn Meditron\",\n",
    "\"3M Littmann E4000\",\n",
    "\"AUDIOSCOPE\",\n",
    "\"Infral Corp. Prototype\",\n",
    "\"MLT201/Piezo\",\n",
    "\"JABES\",\n",
    "\"3M Littmann\"]\n",
    "parser = dict(zip(np.unique(y_),subsets))\n",
    "fig = plt.figure(figsize=(11,8))\n",
    "for stage,color in zip(np.unique(y_),colors):\n",
    "    mask = y_ == stage\n",
    "    plt.scatter(X_embedded[mask,0],X_embedded[mask,1],c=color,label=parser[stage],s=30)\n",
    "plt.legend(markerscale=2,fontsize=14)\n",
    "fig.set_tight_layout(tight=1)\n",
    "plt.xlabel('TSNE Component 1',fontproperties=font_prop)\n",
    "plt.ylabel('TSNE Component 2',fontproperties=font_prop)\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('potesTSNE.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('gammaTSNEbal.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] [ 682  409  489   31   55 1867  114  151]\n"
     ]
    }
   ],
   "source": [
    "meta_labels = np.asarray([ord(each)- 97 for each in train_files+val_files+list(test_files)])\n",
    "meta_labels[meta_labels == 23] = 6\n",
    "y = np.argmax(np.concatenate([y_train,y_val,y_test]),axis=-1)\n",
    "\n",
    "for idx,each in enumerate(np.unique(meta_labels)):\n",
    "        indices = np.where(np.logical_and(y==1,meta_labels == each))\n",
    "        meta_labels[indices] = 7 +idx\n",
    "meta_labels=meta_labels[0:len(activations)]\n",
    "quality_labels=np.concatenate([q_train,q_val,q_test],axis=0)[0:len(activations)]\n",
    "\n",
    "idx = []\n",
    "for subset,each in zip(np.unique(meta_labels),recBins):\n",
    "    np.random.seed(1)\n",
    "    idx = idx+list(np.random.choice(np.where([meta_labels==subset])[1],size=(each,),replace=False))\n",
    "    \n",
    "y_= meta_labels[idx]\n",
    "y_[y_==11] = 14\n",
    "y_[y_>6] = y_[y_>6] - 7 # 0-7 steth labels\n",
    "y_ = y_+1\n",
    "y_[y_==7] = 0\n",
    "y_[y_==8] = 7\n",
    "print(np.unique(y_),np.bincount(y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording Level TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.asarray(train_files+val_files+list(test_files))\n",
    "parts = np.asarray(list(train_parts)+list(val_parts)+list(test_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([x_train,x_val,x_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109453, 9952)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = np.array(get_activations(model,data[:-13],\n",
    "                                       batch_size=64,layer_name='flatten_1'))\n",
    "rem = np.array(get_activations(model,data[-13:],\n",
    "                                       batch_size=1,layer_name='flatten_1'))\n",
    "activations = np.concatenate([activations,rem],axis=0)\n",
    "\n",
    "del data, rem\n",
    "\n",
    "if activations.ndim > 2:\n",
    "    activations = np.reshape(activations,(len(activations),-1))\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3798, 9952)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = cc2parts(files,parts)\n",
    "activations = cc2parts(activations,parts)\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] [ 682  409  489   31   55 1867  114  151]\n"
     ]
    }
   ],
   "source": [
    "meta_labels = np.asarray([ord(each)- 97 for each in files])\n",
    "meta_labels[meta_labels == 23] = 6\n",
    "y = cc2parts(np.argmax(np.concatenate([y_train,y_val,y_test]),axis=-1),parts)\n",
    "\n",
    "for idx,each in enumerate(np.unique(meta_labels)):\n",
    "        indices = np.where(np.logical_and(y==1,meta_labels == each))\n",
    "        meta_labels[indices] = 7 +idx\n",
    "np.unique(meta_labels)\n",
    "\n",
    "y_= meta_labels\n",
    "y_[y_==11] = 14\n",
    "y_[y_>6] = y_[y_>6] - 7 # 0-7 steth labels\n",
    "y_ = y_+1\n",
    "y_[y_==7] = 0\n",
    "y_[y_==8] = 7\n",
    "print(np.unique(y_),np.bincount(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('typeII.mat',{'X':activations,'y':y_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 1441 nearest neighbors...\n",
      "[t-SNE] Indexed 3798 samples in 1.111s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py:268: DeprecationWarning: check_pickle is deprecated in joblib 0.12 and will be removed in 0.13\n",
      "  ' removed in 0.13', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 3798 samples in 185.961s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 3798\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 3798\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 3798\n",
      "[t-SNE] Computed conditional probabilities for sample 3798 / 3798\n",
      "[t-SNE] Mean sigma: 10.413417\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 50.269279\n",
      "[t-SNE] KL divergence after 1550 iterations: 0.619612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3798, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embed = scale(activations)\n",
    "# X_embedded = PCA(n_components=50).fit_transform(X_embed)\n",
    "X_embedded = TSNE(n_components=2,\n",
    "#                   learning_rate=60,\n",
    "#                   early_exaggeration=1140.,\n",
    "                  perplexity=480, #480-2, 150-3 without exagg and lr\n",
    "                  init='random',\n",
    "                  n_iter=4000,\n",
    "                  verbose=1,\n",
    "                  ).fit_transform(X_embed)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "import matplotlib.font_manager as font_manager\n",
    "font_prop = font_manager.FontProperties(size=14)\n",
    "font_title = font_manager.FontProperties(size=20)\n",
    "\n",
    "colors = ['#434B77',\n",
    "          '#669966',\n",
    "          '#c10061',\n",
    "          '#ff51a5',\n",
    "          'k',\n",
    "          '#ffbe4f',\n",
    "#           '#008080',\n",
    "          '#DBEEEE',\n",
    "          '#008080',\n",
    "         ]\n",
    "# y_ = y_>6\n",
    "subsets = [\"Eko CORE Bluetooth\",\n",
    "\"Welch Allyn Meditron\",\n",
    "\"3M Littmann E4000\",\n",
    "\"AUDIOSCOPE\",\n",
    "\"Infral Corp. Prototype\",\n",
    "\"MLT201/Piezo\",\n",
    "\"JABES\",\n",
    "\"3M Littmann\"]\n",
    "parser = dict(zip(np.unique(y_),subsets))\n",
    "fig = plt.figure(figsize=(11,7))\n",
    "for stage,color in zip(np.unique(y_),colors):\n",
    "    mask = y_ == stage\n",
    "    plt.scatter(X_embedded[mask,0],X_embedded[mask,1],c=color,label=parser[stage])\n",
    "plt.legend(markerscale=2,fontsize=14)\n",
    "fig.set_tight_layout(tight=1)\n",
    "plt.xlabel('TSNE Component 1',fontproperties=font_prop)\n",
    "plt.ylabel('TSNE Component 2',fontproperties=font_prop)\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('rec_gammatoneTSNE.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('rec_typeIITSNE.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "conf = model_confidence(model,x_val,y_val)\n",
    "conf = cc2parts(conf,val_parts)\n",
    "plt.hist(conf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potes = \"/media/mhealthra2/Data/Heart_Sound/Physionet/answers.txt\"\n",
    "pdf = pd.read_csv(potes, header=None)\n",
    "pdf.set_index(0,inplace=True)\n",
    "gt = \"/media/mhealthra2/Data/Heart_Sound/Physionet/2016-07-25_Updated files for Challenge 2016/Online Appendix_training set.csv\"\n",
    "gtdf = pd.read_csv(gt)\n",
    "gtdf.set_index('Challenge record name',inplace=True)\n",
    "pdf = pdf.join(gtdf,how='left')\n",
    "files = pdf.index.str\n",
    "calc_metrics(true=pdf['Class (-1=normal 1=abnormal)']>0,pred=pdf[1]>0,files=pdf.index.str[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_rec(model,layer_name,cc,label,output_class='true',normalize=True,verbose=0):\n",
    "    '''\n",
    "    Generate class activation maps for whole recording\n",
    "    \n",
    "    Inputs:\n",
    "    model: model object\n",
    "    layer_name: layer to take grads of\n",
    "    cc: segmented cardiac cycles\n",
    "    label: corresponding class for each cc to generate activations w.r.t\n",
    "    \n",
    "    Outputs:\n",
    "    rec: concatenated cc\n",
    "    acti: concatenated CAMs\n",
    "    '''\n",
    "    \n",
    "    rec = []\n",
    "    activations = []\n",
    "    for idx,data in enumerate(cc):\n",
    "        if verbose:\n",
    "            print(\"Grad-CAM on CC-%d\" % idx)\n",
    "        data = np.expand_dims(data,axis=0)\n",
    "        \n",
    "        if output_class == 'true':\n",
    "            output = model.output[:,-(int(label[idx])+1)]\n",
    "        elif output_class == 'pred':\n",
    "            pred = np.argmax(model.predict(data,verbose=0),axis=-1)\n",
    "            output = model.output[:,-(int(pred)+1)]\n",
    "        else:\n",
    "            raise ValueError('output_class should be `true` or `pred`')\n",
    "        \n",
    "        last_conv_layer = model.get_layer(layer_name) ##### have to change the name here\n",
    "        grads = K.gradients(output, last_conv_layer.output)[0]\n",
    "        pooled_grads = K.mean(grads, axis=(0, 1)) ### no idea what to do here\n",
    "        iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "        pooled_grads_value, conv_layer_output_value = iterate([data])\n",
    "        for i in range(pooled_grads_value.shape[0]):\n",
    "            if verbose:\n",
    "                print(\"Iteration %d\" % i)\n",
    "            conv_layer_output_value[ :, i] *= pooled_grads_value[i]\n",
    "        heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        if normalize:\n",
    "            print('normalizing')\n",
    "            try:\n",
    "                heatmap /= (np.std(heatmap)+ 1E-10)\n",
    "            except RuntimeWarning:\n",
    "                heatmap = heatmap\n",
    "        \n",
    "        \n",
    "        x = np.linspace(0, data.shape[1], num=len(heatmap))\n",
    "        y = heatmap\n",
    "        f1 = interp1d(x, y, kind='cubic')\n",
    "        xnew = np.linspace(0, data.shape[1], num=data.shape[1])\n",
    "        ynew = f1(xnew)\n",
    "        \n",
    "        end_idx = np.where(data!=0)[1][-1]\n",
    "        data = data[0,:end_idx,0]\n",
    "        ynew = ynew[:end_idx]\n",
    "        rec.append(data)\n",
    "        activations.append(ynew)\n",
    "    \n",
    "    return np.asarray(np.hstack(rec)),np.asarray(np.hstack(activations))\n",
    "\n",
    "def grad_cam_logs(logs,layer_name,cc,label,min_epoch=80,min_metric=.7,output_class='true',normalize=True,\n",
    "                  xlim=None,figsize=(12,8),lognames=None,colors=None,window='flat',win_size=50,\n",
    "                metric='val_macc',model_dir='../models/',verbose=0):\n",
    "    '''\n",
    "    Plot Grad_CAM for logs with predictions\n",
    "    '''\n",
    "    parser={0:'Normal',1:'Abnormal'}\n",
    "    \n",
    "    if not type(logs) == list:\n",
    "        logs = [logs]\n",
    "    \n",
    "    activations = []\n",
    "    predictions = []\n",
    "    for log_name in logs:\n",
    "        model = load_model(log_name,verbose=verbose)\n",
    "        weights = get_weights(log_name,min_epoch=min_epoch,\n",
    "                              min_metric=min_metric,verbose=verbose)\n",
    "        checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "        model.load_weights(checkpoint_name)\n",
    "        if verbose:\n",
    "            print(\"GRAD CAM for %s\" % log_name)\n",
    "        _,acti = grad_cam_rec(model,layer_name,cc,label,\n",
    "                              verbose=verbose,\n",
    "                              normalize=normalize,\n",
    "                              output_class=output_class)\n",
    "        pred = cc2rec_labels(cc,model.predict(cc)[:,1])\n",
    "        activations.append(acti)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    rec = cc2rec(cc)\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    grid = plt.GridSpec(3, 4, hspace=0.2, wspace=0.2,)\n",
    "    main_ax = fig.add_subplot(grid[0,:],\n",
    "                              ylabel='PCG',\n",
    "#                               ylabel='%s PCG'%parser[label[0]]\n",
    "                             )\n",
    "    pred_ax = fig.add_subplot(grid[1, :], ylabel='Predictions', sharex=main_ax)\n",
    "    acti_ax = fig.add_subplot(grid[2, :], ylabel='Activations', sharex=main_ax)\n",
    "    \n",
    "\n",
    "    t = np.linspace(0,len(rec)/1000,num=len(rec))\n",
    "    main_ax.plot(t,rec)\n",
    "    main_ax.set_xlim([0,t[-1]])\n",
    "    \n",
    "    if colors is not None:\n",
    "        for acti,pred,color in zip(activations,predictions,colors):\n",
    "            acti_ax.plot(t,smooth_win(acti/np.std(acti),window_len=win_size,window=window),color=color)\n",
    "            pred_ax.plot(t,pred,color=color)\n",
    "            \n",
    "    else:\n",
    "        for acti,pred in zip(activations,predictions):\n",
    "            acti_ax.plot(t,smooth_win(acti/np.std(acti),window_len=win_size,window=window))\n",
    "            pred_ax.plot(t,pred)\n",
    "    \n",
    "    pred_ax.set_ylim([0,1])\n",
    "    if xlim is not None:\n",
    "        main_ax.set_xlim(xlim)\n",
    "    if lognames is not None:\n",
    "        acti_ax.legend(lognames)\n",
    "        \n",
    "    return [main_ax,pred_ax,acti_ax]\n",
    "\n",
    "def smooth_win(x,window_len=11,window='hanning'):\n",
    "        if x.ndim != 1:\n",
    "                raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "        if x.size < window_len:\n",
    "                raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "        if window_len<3:\n",
    "                return x\n",
    "        if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        return y[window_len:-window_len+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "conf = model_confidence(model=model,data=x_val,labels=y_val, verbose=1)\n",
    "conf = cc2parts(conf,val_parts)\n",
    "plt.hist(conf,40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = np.logical_and(conf>.8,conf<.9)\n",
    "_,idx = np.where([cond])\n",
    "print('Number of Recordings within condition',len(idx))\n",
    "\n",
    "target_idx = np.random.randint(len(idx))\n",
    "print('Target Recording from subset-',cc2parts(val_files,val_parts)[idx[target_idx]])\n",
    "\n",
    "cc_idx = idx_parts2cc([idx[target_idx]],val_parts)\n",
    "\n",
    "target_data = x_val[cc_idx]\n",
    "target_labels = y_val[:,1][cc_idx]\n",
    "print('Target Recording Class',target_labels[0])\n",
    "target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Training Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0,len(target_data)/1000,num=len(target_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2parts(train_files,train_parts).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'a0182.wav'\n",
    "\n",
    "filenames = pd.read_csv('../data/feature/folds/text/train_files.txt',header=None)\n",
    "idx = np.where(filenames[0]==target)[0]\n",
    "print(idx)\n",
    "cc_idx = idx_parts2cc(idx,train_parts)\n",
    "target_data = x_train[cc_idx]\n",
    "target_labels = y_train[:,1][cc_idx]\n",
    "print('Target Recording Class',target_labels[0])\n",
    "print('Number of cc',target_data.shape[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "rec = cc2rec(target_data[:6])\n",
    "plt.plot(np.linspace(0,len(rec)/1000,num=len(rec)),rec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Validation Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'b0003'\n",
    "filenames = pd.read_csv('../data/feature/folds/text/validation0.txt',header=None)\n",
    "idx = np.where(filenames[0]==target)[0]\n",
    "cc_idx = idx_parts2cc(idx,val_parts)\n",
    "\n",
    "target_data = x_val[cc_idx]\n",
    "target_labels = y_val[:,1][cc_idx]\n",
    "print('Target Recording Class',target_labels[0])\n",
    "print('Target Recording cc',target_labels.shape)\n",
    "target_data.shape\n",
    "\n",
    "fig = plt.figure()\n",
    "rec = cc2rec(target_data)\n",
    "plt.plot(np.linspace(0,len(rec)/1000,num=len(rec)),rec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 188\n",
    "cc_idx = idx_parts2cc(idx,test_parts)\n",
    "\n",
    "target_data = x_test[cc_idx]\n",
    "target_labels = y_test[:,1][cc_idx]\n",
    "print('Target Recording Class',target_labels[0])\n",
    "target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs=[\n",
    "\"potes_fold0_noFIR 2019-03-16 18:44:45.597226\", # potes non balanced\n",
    "\"potes_fold0_noFIR 2019-03-02 13:01:33.636778\", # potes\n",
    "\"fold0_noFIR 2019-02-27 19:52:21.543329\", # Type1 macc\n",
    "# \"fold0_noFIR 2019-03-07 14:44:47.022240\", # Type2 macc 80 epoch\n",
    "# \"fold0_noFIR 2019-03-08 03:28:46.740442\", # Type3 sensitivity\n",
    "# \"fold0_noFIR 2019-03-08 14:50:52.332924\", # type4 val_acc\n",
    "# \"fold0_noFIR 2019-03-09 01:34:03.547265\", # gamma stage 1\n",
    "\"fold0_noFIR 2019-03-06 14:21:29.823568\", # zero stage2\n",
    "]\n",
    "lognames=[\n",
    "\"Potes-CNN\",\n",
    "\"Potes-CNN DBT\",\n",
    "\"Type I tConv\",\n",
    "# \"Type II tConv\",\n",
    "# \"Type III tConv\",\n",
    "# \"Type IV tConv\",\n",
    "# \"Gammatone tConv\",\n",
    "\"Zero Phase tConv\",\n",
    "]\n",
    "colors = [\n",
    "'#434B77',\n",
    "'#669966',\n",
    "'#c10061',\n",
    "'#ff51a5',\n",
    "'k',\n",
    "'#ffbe4f',\n",
    "'#DBBBBB',\n",
    "'#008080',\n",
    "         ]\n",
    "\n",
    "cc_start = 0\n",
    "cc_end = 8\n",
    "ax = grad_cam_logs(logs,'concatenate_1',target_data[cc_start:cc_end],target_labels[cc_start:cc_end],win_size=10,\n",
    "                   lognames=lognames,colors=colors,output_class='pred',normalize=True)\n",
    "ax[1].set_yticks([0,.25,.5,.75,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(3.5,5)\n",
    "ax[1].set_yticks([0,.25,.5,.75,1])\n",
    "ax[2].set_ylim([-.1,6])\n",
    "# fig.savefig('Normal.eps')\n",
    "\n",
    "# plt.savefig('MRgradCAM.eps')\n",
    "# plt.xlim([0,4.7])\n",
    "\n",
    "ax[2].legend_ = None\n",
    "# ax[2].legend(lognames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confidence_logs(logs,lognames,bins=5,figsize=(10,2),verbose=0):\n",
    "    fig,ax = plt.subplots(1,len(logs),sharey='row',figsize=figsize)\n",
    "    for axes,log_name,model_name in zip(ax,logs,lognames):\n",
    "        model = load_model(log_name,verbose=0)\n",
    "        weights = get_weights(log_name,min_epoch=100,min_metric=.7)\n",
    "        metric = 'val_macc'\n",
    "        model_dir = '../models/'\n",
    "        checkpoint_name = os.path.join(model_dir+log_name,weights[metric])\n",
    "        model.load_weights(checkpoint_name)\n",
    "\n",
    "        for subset in np.unique(val_files):\n",
    "            mask = np.asarray(val_files) == subset\n",
    "            part_mask = cc2parts(val_files,val_parts) == subset\n",
    "            conf = model_confidence(model=model,data=x_val[mask],labels=y_val[mask], verbose=verbose)\n",
    "            conf = cc2parts(conf,val_parts[part_mask])\n",
    "            sns.distplot(conf,bins=bins,label=\"Subset-%s\"%subset,ax=axes)\n",
    "\n",
    "        conf = model_confidence(model=model,data=x_test,labels=y_test, verbose=verbose)\n",
    "        conf = cc2parts(conf,test_parts)\n",
    "        sns.distplot(conf,bins=bins,label='HSSDB',ax=axes)\n",
    "        axes.set_title('%s C-DIST'%model_name)\n",
    "#         axes.legend(loc='upper center', bbox_to_anchor=(0.5, 1.00),&nbsp; shadow=True, ncol=2)\n",
    "    return ax\n",
    "ax = plot_confidence_logs(logs,lognames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chartBox = ax[2].get_position()\n",
    "# ax[0].set_position([chartBox.x0, chartBox.y0, chartBox.width*0.6, chartBox.height])\n",
    "ax[2].legend(loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
