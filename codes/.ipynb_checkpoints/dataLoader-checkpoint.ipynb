{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,tables,numpy as np,matplotlib.pyplot as plt,pandas as pd,json,h5py\n",
    "from scipy.io import loadmat\n",
    "from collections import Counter\n",
    "from  itertools import combinations\n",
    "from dataholder import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/mhealthra2/Data/heart_sound/Adversarial-Heart-Sound-Classification/codes'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compare.mat',\n",
       " 'fold_a.mat',\n",
       " 'fold_b.mat',\n",
       " 'fold_c.mat',\n",
       " 'fold_d.mat',\n",
       " 'fold_e.mat',\n",
       " 'fold_f.mat',\n",
       " 'pascalA.mat',\n",
       " 'pascalB.mat',\n",
       " 'readme.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_dir = '../../feature/potes_1DCNN/balancedCV/folds/folds_phys_compare_pascal/'\n",
    "os.listdir(fold_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(fold_dir+'compare.mat', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5872.0, (2500, 17061))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['val_parts'][0]),data['trainX'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt,h5py,numpy as np\n",
    "from collections import Counter\n",
    "class Data():\n",
    "    def __init__(self,path,f,n,severe = False,split=0):\n",
    "        \n",
    "        if(split>=1 or split<0):\n",
    "            print(\"make sure split follow  1<split<=0 \")\n",
    "            raise ValueError\n",
    "        self.split = split\n",
    "        self.data = h5py.File(path+f, 'r')\n",
    "        self.file = f\n",
    "        self.dom = n\n",
    "        self.trainX = np.array(self.data['trainX'][:]).astype('float32')\n",
    "        self.trainY = self.data['trainY'][:][0].astype('int8')\n",
    "        self.train_parts = self.data['train_parts'][0].astype('int32')\n",
    "        self.valX = None\n",
    "        self.valY = None\n",
    "        self.valdomY = None\n",
    "        self.val_parts = None\n",
    "        self.normfiles, self.abnormfiles = self.parts()\n",
    "        self.domainY = [n]*self.trainY.shape[0]\n",
    "        self.normal = Counter(self.trainY)[0]\n",
    "        self.abnormal = Counter(self.trainY)[1]\n",
    "        self.total = self.normal+self.abnormal\n",
    "        if('fold_e' in f): self.processE()\n",
    "        if(f[:3]=='com'):self.processCompare(severe) ### select severe files only\n",
    "        else:\n",
    "            self.trainY[self.trainY<0] = 0\n",
    "        if(split>0):self.split_data(split)\n",
    "        \n",
    "    def split_data(self,split):\n",
    "        if(self.file[:3]=='com'):\n",
    "            self.valX = self.data['valX'][:]\n",
    "            self.valY = self.data['valY'][:][0]\n",
    "            self.valY[self.valY>0] = 1\n",
    "            self.val_parts = self.data['val_parts'][0].astype('int32')\n",
    "            self.valdomY = [self.dom]*self.valY.shape[0]\n",
    "            return\n",
    "        taken = 0\n",
    "        left = 0\n",
    "        tmpX = None\n",
    "        tmpY = None\n",
    "        parts = []\n",
    "        self.val_parts = []\n",
    "        for x in self.train_parts:\n",
    "            if(taken<split*self.total):\n",
    "                taken = taken + x\n",
    "                if(self.valX is None):\n",
    "                    self.valX = self.trainX[:,left:x+left]\n",
    "                    self.valY = self.trainY[left:x+left]\n",
    "                else:\n",
    "                    \n",
    "                    self.valX = np.concatenate((self.valX,self.trainX[:,left:x+left]),axis=1)\n",
    "                    self.valY = np.concatenate((self.valY,self.trainY[left:x+left]),axis=0)\n",
    "                self.val_parts.append(x)\n",
    "            else:\n",
    "                if(tmpX is None):\n",
    "                    tmpX = self.trainX[:,left:x+left]\n",
    "                    tmpY = self.trainY[left:x+left]\n",
    "                else:\n",
    "                    tmpX = np.concatenate((tmpX,self.trainX[:,left:x+left]),axis=1)\n",
    "                    tmpY = np.concatenate((tmpY,self.trainY[left:x+left]),axis=0)\n",
    "                parts.append(x)\n",
    "            left = left + x\n",
    "        self.trainX = tmpX\n",
    "        self.trainY = tmpY\n",
    "        self.train_parts = parts\n",
    "        self.domainY = [self.dom]*self.trainY.shape[0]\n",
    "        self.valdomY = [self.dom]*self.valY.shape[0]\n",
    "        del tmpX,tmpY,parts\n",
    "    def processCompare(self,severe):\n",
    "        if(severe):\n",
    "            self.sevX = None\n",
    "            self.sevY = self.trainY[self.trainY<2]\n",
    "            self.sev_parts = []\n",
    "            left = int(0)\n",
    "            for x in self.train_parts:\n",
    "                x = int(x)\n",
    "                if(all([i==2 for i in self.trainY[left:x+left]])):\n",
    "                    if(self.sevX is None):\n",
    "                        self.sevX = self.trainX[:,left:x+left]\n",
    "                    else: \n",
    "                        self.sevX = np.concatenate((self.sevX,self.trainX[:,left:x+left]),axis=1)\n",
    "                else:self.sev_parts.append(x)\n",
    "                left = x + left\n",
    "            self.trainX = self.sevX\n",
    "            self.trainY = self.sevY\n",
    "            self.train_parts = self.sev_parts\n",
    "            self.domainY = [self.dom]*self.trainY.shape[0]\n",
    "            self.normal = Counter(self.trainY)[0]\n",
    "            self.abnormal = Counter(self.trainY)[1]\n",
    "            self.total = self.normal+self.abnormal\n",
    "            self.normfiles, self.abnormfiles = self.parts()\n",
    "        else:\n",
    "            self.trainY[self.trainY>0] = 1\n",
    "    def processE(self):\n",
    "        self.trainY[self.trainY<0] = 0\n",
    "        nn = ab = 0\n",
    "        idx = []\n",
    "        left = 0\n",
    "        parts = []\n",
    "        for x in self.train_parts:\n",
    "            if(all([(l == 0) for l in self.trainY[left:left+x]])):\n",
    "                if(nn<self.abnormal):\n",
    "                    idx = idx + [True]*x\n",
    "                    nn = nn + x\n",
    "                    parts.append(x)\n",
    "                else:idx = idx + [False]*x\n",
    "            else:\n",
    "                if(ab<self.abnormal):\n",
    "                    idx = idx + [True]*x\n",
    "                    ab = ab + x\n",
    "                    parts.append(x)\n",
    "                else:idx = idx + [False]*x\n",
    "            left = left + x\n",
    "        self.trainY = self.trainY[idx]\n",
    "        self.trainX = np.transpose(np.transpose(self.trainX)[idx])\n",
    "        self.train_parts = parts\n",
    "        self.total = nn+ab\n",
    "        self.domainY = self.domainY[:self.total]\n",
    "    def parts(self):\n",
    "        y = 0\n",
    "        nn = 0\n",
    "        ab = 0\n",
    "        for x in self.train_parts:\n",
    "            if(sum(self.trainY[y:y+int(x)])>0):\n",
    "                ab = ab + 1\n",
    "            else: nn = nn +1 \n",
    "            y = int(x)+y\n",
    "        #print(nn+ab,nn,ab)\n",
    "        return nn,ab\n",
    "    def pie(self):\n",
    "        colors = ['gold','lightskyblue']\n",
    "        explode = (0.07, 0)\n",
    "        size = [self.normal,self.abnormal]\n",
    "        labels = ['N', 'Ab']\n",
    "        plt.pie(size,labels=labels,colors = colors,startangle=140,explode=explode,\n",
    "               shadow=True,autopct=self.value)\n",
    "        plt.title(self.dom)\n",
    "    def value(self,val):\n",
    "        return int(self.total*val/100)\n",
    "    def details(self):\n",
    "        if(self.trainX is  None):print(\"TrainX None/ \",end='')\n",
    "        if(self.trainY is  None):print(\"trainY None/ \",end='')\n",
    "        if(self.domainY is None):print(\"Dom Y/ \",end='')\n",
    "        if(self.train_parts is  None):print(\"train parts/ \")\n",
    "        if(self.valX is None):print(\"valX/ \",end='')\n",
    "        if(self.valY is None) :print(\"valY/ \",end='')\n",
    "        if(self.valdomY is None):print(\"Valdom/ \",end='')\n",
    "        if(self.val_parts is  None):print(\"val parts/ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainX', 'trainY', 'train_files', 'train_parts', 'valX', 'valY', 'val_files', 'val_parts']\n"
     ]
    }
   ],
   "source": [
    "d = Data(fold_dir,'compare.mat','i',split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11204,), (2963,), 2963)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.trainY.shape, d.valY.shape,len(d.valdomY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainX', 'trainY', 'train_files', 'train_parts', 'valX', 'valY', 'val_files', 'val_parts']\n",
      "val parts None\n"
     ]
    }
   ],
   "source": [
    "dd = Data(fold_dir,'compare.mat','i',True)\n",
    "dd.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.trainY[10:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations(dd.train_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataMerge():\n",
    "    def __init__(self,split = 0):\n",
    "        self.split = split\n",
    "        self.x_train = self.y_train = self.y_domain = self.train_parts = None\n",
    "        self.x_val = self.y_val = self.y_valdom = self.val_parts = None\n",
    "    def merge(self,data,train_test):\n",
    "        if(train_test):\n",
    "            print(\"HMM\")\n",
    "            if(self.x_val is None):self.x_val = data.trainX;\n",
    "            else:self.x_val = np.concatenate((self.x_val,data.trainX),axis = 1)\n",
    "            if(self.y_val is None):self.y_val = data.trainY\n",
    "            else:self.y_val = np.concatenate((self.y_val,data.trainY),axis = 0)\n",
    "            if(self.y_valdom is None):self.y_valdom = data.domainY\n",
    "            else:self.y_valdom = self.y_valdom+data.domainY\n",
    "            if(self.val_parts is None):\n",
    "                if(data.train_parts is not None):self.val_parts = data.train_parts\n",
    "            else:\n",
    "                if(data.train_parts is not None):\n",
    "                    self.val_parts = np.concatenate((self.val_parts,data.train_parts),axis = 0)\n",
    "                else:\n",
    "                    print(\"Data train parts unavailable\")\n",
    "            if(self.split>0):        \n",
    "                if(self.x_train is None):self.x_train = data.valX\n",
    "                else:self.x_train = np.concatenate((self.x_train,data.valX),axis = 1)\n",
    "                if(self.y_train is None):self.y_train =  data.valY\n",
    "                else:self.y_train = np.concatenate((self.y_train,data.valY),axis = 0)\n",
    "                if(self.y_domain is None):self.y_domain  =  data.valdomY\n",
    "                else:self.y_domain = self.y_domain+data.valdomY\n",
    "                if(self.train_parts is None):self.train_parts = data.val_parts;\n",
    "                else:\n",
    "                    if(data.val_parts is not None):\n",
    "                        self.train_parts = np.concatenate((self.train_parts,data.val_parts),axis = 0) \n",
    "                    else:\n",
    "                        print(\"Data train parts unavailable\")\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if(self.x_train is None):self.x_train = data.trainX;\n",
    "            else:self.x_train = np.concatenate((self.x_train,data.trainX),axis = 1)\n",
    "            if(self.y_train is None):self.y_train = data.trainY;\n",
    "            else:self.y_train = np.concatenate((self.y_train,data.trainY),axis = 0)\n",
    "            if(self.y_domain):self.y_domain = data.domainY;\n",
    "            else:self.y_domain = self.y_domain+data.domainY\n",
    "            if(self.train_parts is None):\n",
    "                self.train_parts = data.train_parts;\n",
    "            else:\n",
    "                if(data.train_parts is not None):\n",
    "                    self.train_parts = np.concatenate((self.train_parts,data.train_parts),axis = 0) \n",
    "                else:\n",
    "                    print(\"Data train parts nai Train mergee \")\n",
    "\n",
    "def getData(fold_dir, train_folds, test_folds, split = 0):\n",
    "    try:\n",
    "        with open('../data/domain_filename.json', 'r') as fp:\n",
    "            foldname = json.load(fp)\n",
    "    except:\n",
    "        raise FileNotFoundError(\"The json file that maps domain character to filename is not here\")\n",
    "\n",
    "    allData = DataMerge(split)\n",
    "    for c in test_folds:\n",
    "        allData.merge(Data(fold_dir,foldname[c],c,severe = False,split=split),True)\n",
    "    for c in train_folds:\n",
    "        allData.merge(Data(fold_dir,foldname[c],c),False)\n",
    "        \n",
    "    return allData.x_train, allData.y_train, allData.y_domain, allData.train_parts,allData.x_val,allData.y_val,allData.y_valdom,allData.val_parts \n",
    "\n",
    "\n",
    "def reshape_folds(x, y):\n",
    "    x_train = []\n",
    "    for x1 in x:\n",
    "        x1 = np.transpose(x1[:, :])\n",
    "        x1 = np.reshape(x1, [x1.shape[0], x1.shape[1], 1])\n",
    "        x_train.append(x1)\n",
    "        print(\"reshaped x \", x1.shape)\n",
    "    y_train = []\n",
    "    for y1 in y:\n",
    "        y1 = np.reshape(y1, [y1.shape[0], 1])\n",
    "        y_train.append(y1)\n",
    "        print(\"reshaped Y \", y1.shape)\n",
    "\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "['trainX', 'trainY', 'train_files', 'train_parts', 'valX', 'valY', 'val_files', 'val_parts']\n",
      "HMM\n",
      "abcdefgh\n",
      "a\n",
      "['trainX', 'trainY', 'train_files', 'train_parts']\n",
      "b\n",
      "['trainX', 'trainY', 'train_files', 'train_parts']\n",
      "c\n",
      "['trainX', 'trainY', 'train_files', 'train_parts']\n",
      "d\n",
      "['trainX', 'trainY', 'train_files', 'train_parts']\n",
      "e\n",
      "['trainX', 'trainY', 'train_files', 'train_parts']\n",
      "f\n",
      "['trainX', 'trainY', 'train_files', 'train_parts']\n",
      "g\n",
      "['#refs#', '#subsystem#', 'file_name', 'states', 'trainX', 'trainY', 'train_parts']\n",
      "h\n",
      "['#refs#', '#subsystem#', 'file_name', 'states', 'trainX', 'trainY', 'train_parts']\n"
     ]
    }
   ],
   "source": [
    "u,i,o,p,uu,ii,oo,pp = getData(fold_dir,'abcdefgh','i',split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 20275), (2500, 4159))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, uu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500, 19734), (2500, 4700))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, uu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails = ['fold_a.mat',\n",
    " 'fold_b.mat',\n",
    " 'fold_c.mat',\n",
    " 'fold_d.mat',\n",
    " 'fold_e.mat',\n",
    " 'fold_f.mat',\n",
    " 'pascalA.mat',\n",
    " 'pascalB.mat',\n",
    " 'compare.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_a.mat\n",
      "fold_b.mat\n",
      "fold_c.mat\n",
      "fold_d.mat\n",
      "fold_e.mat\n",
      "fold_f.mat\n",
      "pascalA.mat\n",
      "pascalB.mat\n",
      "compare.mat\n"
     ]
    }
   ],
   "source": [
    "for (x,n) in zip(fails,'abcdefghi'):\n",
    "    d = Data(fold_dir,x,n,split=0.3)\n",
    "    print(x)\n",
    "    d.details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = [2,2,2,2]\n",
    "all([x==2 for x in ww])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'fold_e' in \"fold_e_dfasfd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
