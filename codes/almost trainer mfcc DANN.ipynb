{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))\n",
    "# from clr_callback import CyclicLR\n",
    "# import dill\n",
    "from BalancedDannAudioDataGenerator import BalancedAudioDataGenerator, AudioDataGenerator\n",
    "import os,time\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import math\n",
    "import pandas as pd\n",
    "import tables,h5py\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from keras.utils import plot_model\n",
    "# from Heartnet import heartnet,getAttentionModel\n",
    "from collections import Counter\n",
    "# from torchviz import make_dot\n",
    "def to_numpy(x):\n",
    "    return x.cpu().detach().numpy()\n",
    "def plotf(x):\n",
    "    plt.plot(to_numpy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import log_macc, results_log\n",
    "from dataLoader import reshape_folds\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import Evaluator\n",
    "import dataLoader\n",
    "# from custom_layers import Attention\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wow():\n",
    "    def __init__(self):\n",
    "        self.dann = True\n",
    "        self.self = False\n",
    "        self.reduce = None\n",
    "        self.shuffle = 1\n",
    "        self.mfcc = False\n",
    "args = wow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_domains = 'a'\n",
    "train_domains = 'bcdef'\n",
    "source_domain = train_domains\n",
    "target_domain = test_domains\n",
    "\n",
    "test_split = 0\n",
    "fold_dir = '../data/all_folds_wav_name/'\n",
    "\n",
    "if(args.self):\n",
    "    print(\"Self training activated\")\n",
    "    x_train, y_train, y_domain, train_parts, x_val, y_val, val_domain, val_parts,val_wav_files = dataLoader.getData(fold_dir,'',test_domains,0.9,shuffle=args.shuffle)\n",
    "    print(x_train.shape, x_val.shape)\n",
    "else:\n",
    "    x_train, y_train, y_domain, train_parts,x_val, y_val, val_domain, val_parts, val_wav_files = dataLoader.getData(fold_dir,train_domains,test_domains,test_split,shuffle = args.shuffle)\n",
    "\n",
    "if(args.reduce):\n",
    "    print(\"Reduction \", args.reduce)\n",
    "    x_train,_,y_train,_,y_domain,_ = train_test_split(x_train.transpose(),y_train,y_domain,stratify=y_train,test_size = args.reduce)\n",
    "    x_train = x_train.transpose()\n",
    "\n",
    "    #x_val,_,y_val,_,val_domain,_ = train_test_split(x_val.transpose(),y_val,val_domain,stratify=y_val,test_size = args.reduce)\n",
    "    #x_val = x_val.transpose()\n",
    "\n",
    "val_files = val_domain\n",
    "#Create meta labels and domain labels\n",
    "\n",
    "if(test_split>0):\n",
    "    source_domain = \"\".join(set(source_domain).union(set(target_domain)))\n",
    "    #domains = domains + test_domains\n",
    "\n",
    "if(args.self):\n",
    "    print(\"self training\")\n",
    "    source_domain = test_domains\n",
    "\n",
    "domains = set(source_domain + target_domain)\n",
    "#num_class_domain = len(set(train_domains + test_domains))\n",
    "num_class_domain = len(domains)\n",
    "num_class = 2\n",
    "\n",
    "domainClass_source = [(cls,dfc) for cls in range(2) for dfc in source_domain]\n",
    "domainClass_target = [(cls,dfc) for cls in range(2) for dfc in target_domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_labels_source = [domainClass_source.index((cl,df)) for (cl,df) in zip(y_train,y_domain)]\n",
    "meta_labels_target = None\n",
    "if(args.dann):\n",
    "    meta_labels_target = [domainClass_target.index((cl,df)) for (cl,df) in zip((y_val),(val_domain))]\n",
    "    \n",
    "\n",
    "domains = \"\".join(set(source_domain).union(set(target_domain)))\n",
    "\n",
    "y_domain_source = np.array([list(domains).index(lab) for lab in y_domain])\n",
    "\n",
    "y_domain_target = np.array([list(domains).index(lab) for lab in val_domain])\n",
    "\n",
    "################### Reshaping ############\n",
    "\n",
    "if(args.mfcc):\n",
    "    [], [y_train,y_domain,y_val] = reshape_folds([],[y_train,y_domain_source,y_val])\n",
    "else:\n",
    "    [x_train,x_val], [y_train,y_domain,y_val] = reshape_folds([x_train,x_val],[y_train,y_domain_source,y_val])\n",
    "y_train = to_categorical(y_train, num_classes=num_class)\n",
    "\n",
    "print(\"Y domain \", Counter([x[0] for x in y_domain]))\n",
    "print(\"Val domain \", Counter(val_domain))\n",
    "print(\"Source Meta labels \", Counter(meta_labels_source))\n",
    "print(\"Target Meta labels \", Counter(meta_labels_target))\n",
    "y_domain_source = to_categorical(y_domain_source,num_classes=num_class_domain)\n",
    "\n",
    "y_val = to_categorical(y_val, num_classes=num_class)\n",
    "y_domain_target = to_categorical(y_domain_target,num_classes=num_class_domain)\n",
    "\n",
    "\n",
    "val_domain = y_domain_target\n",
    "print(\"Train files \", y_train.shape, \"  Domain \", y_domain.shape)\n",
    "print(\"Test files \", y_val.shape, \"  Domain \", val_domain.shape)\n",
    "\n",
    "### Batch Size limmiter \n",
    "batch_size = 1000\n",
    "if(batch_size > max(y_train.shape)):\n",
    "    print(\"Batch size if given greater than train files size. limiting batch size\")\n",
    "    batch_size = max(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## change 2500 axis for pytorch \n",
    "x_train = x_train.transpose((0,2,1))\n",
    "x_val = x_val.transpose((0,2,1))\n",
    "\n",
    "y_train = np.argmax(y_train,1)\n",
    "y_val = np.argmax(y_val,1)\n",
    "y_domain_target = np.argmax(y_domain_target,1)\n",
    "y_domain_source = np.argmax(y_domain_source,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12*10\n",
    "datagen_source = BalancedAudioDataGenerator(shift=.1,data_format = 'channels_first')\n",
    "flow_source = datagen_source.flow(x_train, (y_train,y_domain_source),\n",
    "                meta_label=meta_labels_source,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=1)\n",
    "datagen_target = BalancedAudioDataGenerator(shift=.1,data_format = 'channels_first')\n",
    "flow_target = datagen_target.flow(x_val, (y_val,y_domain_target),\n",
    "                meta_label=None,\n",
    "                batch_size=batch_size, shuffle=True,\n",
    "                seed=1)\n",
    "try:\n",
    "    flow_source.steps_per_epoch = len(flow_source)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HeartCepTorch,importlib\n",
    "HeartCepTorch = importlib.reload(HeartCepTorch)\n",
    "from HeartCepTorch import MFCC_Gen,Network,MFCC_Gen_coeff\n",
    "from utils import log_macc, trainLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(2,num_class_domain)\n",
    "mfcc_gen = MFCC_Gen_coeff(fs=1000,filters=64,momentum=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from datetime import datetime\n",
    "import CSVLogger\n",
    "CSVLogger = importlib.reload(CSVLogger)\n",
    "from CSVLogger import CSVLogger\n",
    "fold = \"fold0_noFIR requires grad on batch 12x30\"\n",
    "path = \"../../Heartnet_Results/logs/DANN_gammatone_torch_layer/\"\n",
    "fold = fold+'_'+str(datetime.now()).replace(':','.')\n",
    "path = path + fold\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(os.path.join(path,'weights'))\n",
    "logger = CSVLogger(path+'/'+'training.csv')\n",
    "checkpoint_name = os.path.join(path,'weights') + \"/\" + 'weights.{epoch:04d}-acc_{val_acc:.4f}-macc_{macc:.4f}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "mfcc_gen.cuda()\n",
    "mfcc_gen.eval()\n",
    "epochs = 200\n",
    "hp_lambda = 0.05\n",
    "print(\"steps \", flow_source.steps_per_epoch)\n",
    "logger.on_train_begin()\n",
    "for e in range(epochs):\n",
    "    print(\"EPOCH   \",e+1)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    acc = 0\n",
    "    y_pred = None\n",
    "    y_true = None\n",
    "    N = 0\n",
    "    for i in range(flow_source.steps_per_epoch+1):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x,[y,yd] = flow_source.next()\n",
    "        x,y,yd = torch.from_numpy(x),torch.from_numpy(y),torch.from_numpy(yd)\n",
    "        x = x.type(torch.FloatTensor).cuda()\n",
    "        y = y.long().cuda()\n",
    "        yd = yd.long().cuda()\n",
    "        x = mfcc_gen(x)\n",
    "        x = x.transpose(2,1)\n",
    "        x = x.unsqueeze(1)\n",
    "        x,y,yd = Variable(x),Variable(y),Variable(yd)\n",
    "        y = y.long().cuda()\n",
    "        \n",
    "        cls = model(x)\n",
    "        \n",
    "        cls, dom = model(x)\n",
    "        class_loss = class_criterion(cls,y)\n",
    "        domain_loss_source = domain_criterion(dom,yd)\n",
    "        \n",
    "        if(y_pred is None):\n",
    "            y_pred = torch.argmax(cls,axis=1)\n",
    "            y_true = y\n",
    "        else:\n",
    "            y_pred = torch.cat((y_pred,torch.argmax(cls,axis=1)))\n",
    "            y_true = torch.cat((y_true,y))\n",
    "        acc = acc + torch.sum(y==torch.argmax(cls,axis=1))\n",
    "        N = N+len(y)\n",
    "        \n",
    "        if(args.dann):\n",
    "            x,[y,yd] = flow_target.next()\n",
    "            x,y,yd = torch.from_numpy(x),torch.from_numpy(y),torch.from_numpy(yd)\n",
    "            x = x.type(torch.FloatTensor).cuda()\n",
    "            y = y.long().cuda()\n",
    "            yd = yd.long().cuda()\n",
    "            x = mfcc_gen(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = x.unsqueeze(1)\n",
    "            x,y,yd = Variable(x),Variable(y),Variable(yd)\n",
    "            \n",
    "            cls, dom = model(x,hp_lambda)\n",
    "            domain_loss_target = domain_criterion(dom,yd)\n",
    "            loss = class_loss + domain_loss_source+domain_loss_target\n",
    "        else:\n",
    "            loss = class_loss\n",
    "        epoch_loss = epoch_loss + loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_loss_print = (epoch_loss.item()) if (type(epoch_loss)==torch.Tensor) else epoch_loss\n",
    "    acc_print = (acc.item()) if (type(acc)==torch.Tensor) else acc\n",
    "    print(\"Training loss\", \"%.2f\"%(epoch_loss_print/flow_source.steps_per_epoch),end=' ')\n",
    "    print(\"Training Acc \", \"%.2f\"%(acc_print/N),end=' ')\n",
    "    trainLog(y_true,y_pred)\n",
    "    logger.logs['train_loss'] = (epoch_loss_print/flow_source.steps_per_epoch)\n",
    "    logger.logs['train_acc'] = (acc_print/N)\n",
    "    \n",
    "    \n",
    "    # Validate \n",
    "    # Validate \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    acc = 0\n",
    "    N = 0\n",
    "    y_pred = None\n",
    "    y_true = None\n",
    "    with torch.no_grad():\n",
    "        start_idx = 0\n",
    "        for i,s in enumerate(val_parts):\n",
    "            if(s==0):\n",
    "                continue\n",
    "            x,y,yd = x_val[start_idx:start_idx+s],y_val[start_idx:start_idx+s],y_domain_target[start_idx:start_idx+s]\n",
    "            start_idx = start_idx+s\n",
    "            \n",
    "            x,y,yd = torch.from_numpy(x),torch.from_numpy(y),torch.from_numpy(yd)\n",
    "            x = x.type(torch.FloatTensor).cuda()\n",
    "            x = mfcc_gen(x)\n",
    "            x = x.transpose(2,1)\n",
    "            x = x.unsqueeze(1)\n",
    "            x,y = Variable(x),Variable(y)\n",
    "            #x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2])\n",
    "            \n",
    "#             y = y.cuda()\n",
    "            y = y.long().cuda()\n",
    "            cls= model(x)\n",
    "            # val_class_loss = class_criterion(cls,torch.argmax(y,axis=1))\n",
    "            val_class_loss = class_criterion(cls,y)\n",
    "            \n",
    "            if(str(class_criterion) in ['MSELoss()','BCELoss()']):\n",
    "                y = torch.argmax(y,axis=1)\n",
    "            \n",
    "            acc = acc + torch.sum(y==torch.argmax(cls,axis=1))\n",
    "            N = N+len(y)\n",
    "            epoch_loss = epoch_loss + val_class_loss\n",
    "            if(y_pred is None):\n",
    "                y_pred = torch.argmax(cls,axis=1)\n",
    "                y_true = y\n",
    "            else:\n",
    "                y_pred = torch.cat((y_pred,torch.argmax(cls,axis=1)))\n",
    "                y_true = torch.cat((y_true,y))\n",
    "        Macc,sensitivity,specificity,precision,F1 = log_macc(y_pred,y_true,val_parts)\n",
    "        \n",
    "        print(\"Validation loss\", \"%.2f\"%(epoch_loss.item()/len(val_parts)),end=' ')\n",
    "        print(\"Validation Acc \", \"%.2f\"%(acc.item()/N))\n",
    "        logger.logs['val_loss'] = (epoch_loss.item()/len(val_parts))\n",
    "        logger.logs['val_acc'] = (acc.item()/N)\n",
    "        acc = (acc.item()/N)\n",
    "        logger.logs['val_macc'] = Macc\n",
    "        logger.logs['precision'] = precision\n",
    "        logger.logs['sensitivity'] = sensitivity\n",
    "        logger.logs['specificity'] = specificity\n",
    "        logger.logs['F1'] = F1\n",
    "    lr_schedule.step()\n",
    "    torch.save(model.state_dict(),checkpoint_name.format(epoch=e,val_acc=acc,macc=Macc))\n",
    "    logger.on_epoch_end(e)\n",
    "    flow_source.reset()\n",
    "logger.on_train_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
