{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))\n",
    "# from clr_callback import CyclicLR\n",
    "# import dill\n",
    "from BalancedDannAudioDataGenerator import BalancedAudioDataGenerator\n",
    "import os,time\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import math\n",
    "import pandas as pd\n",
    "import tables,h5py\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from keras.callbacks import TensorBoard, Callback, ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from Heartnet import heartnet,getAttentionModel\n",
    "from utils import log_macc, results_log\n",
    "from dataLoader import reshape_folds\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import Evaluator\n",
    "import dataLoader\n",
    "from custom_layers import Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set()\n",
    "import tensorflow as tf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_layers import Conv1D_zerophase_linear, Conv1D_linearphase, Conv1D_zerophase,\\\n",
    "    DCT1D, Conv1D_gammatone, Conv1D_linearphaseType, Attention\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Activation, AveragePooling1D, Add\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax\n",
    "import numpy as np\n",
    "import tables,h5py\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from ResultAnalyser import Result\n",
    "from utils import Confused_Crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(16, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    # t = Flatten()(t)\n",
    "    return t\n",
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=2)\n",
    "\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filt = (8, 4)\n",
    "num_dense = 20\n",
    "lr = 0.01\n",
    "bn_momentum = 0.99\n",
    "eps = 1.1e-5\n",
    "bias = False\n",
    "l2_reg = 0.04864911065093751\n",
    "l2_reg_dense = 0.\n",
    "kernel_size = 5\n",
    "maxnorm = 10000.\n",
    "dropout_rate = 0.5\n",
    "dropout_rate_dense = 0.\n",
    "padding = 'valid'\n",
    "activation_function = 'relu'\n",
    "subsam = 2\n",
    "FIR_train= True\n",
    "trainable = True\n",
    "hp_lambda = np.float32(0)\n",
    "lr_decay =0.0001132885\n",
    "random_seed = 1\n",
    "num_class =2\n",
    "num_class_domain = 18\n",
    "tipe= 1\n",
    "decision = 'majority' \n",
    "channels = '0101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling1D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad, output_shape=zeropad_output_shape)(p)\n",
    "    \n",
    "    t = Add()([t,p])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heartnet(load_path,activation_function='relu', bn_momentum=0.99, bias=False, dropout_rate=0.5, dropout_rate_dense=0.0,\n",
    "             eps=1.1e-5, kernel_size=5, l2_reg=0.0, l2_reg_dense=0.0,lr=0.0012843784, lr_decay=0.0001132885, maxnorm=10000.,\n",
    "             padding='valid', random_seed=1, subsam=2, num_filt=(8, 4), num_dense=20,FIR_train=False,trainable=True,type=1,\n",
    "             num_class=2, num_class_domain=1,hp_lambda=0,batch_size=1024,optim='SGD',segments = channels):\n",
    "    \n",
    "    #num_dense = 20 default \n",
    "    input = Input(shape=(2500, 1))\n",
    "\n",
    "    input2 = Lambda(lambda x:x[:,200:1000,:])(input)\n",
    "    input4 = Lambda(lambda x:x[:,1200:2900,:])(input)\n",
    "    X = []\n",
    "    for i in range(2):\n",
    "        if(i==0):\n",
    "            xx = branch(input2,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "                   eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "        else:\n",
    "            xx = branch(input4,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "                   eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "        xx = branch(input,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "               eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "        xx = res_block(xx,32,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "               eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "        xx = res_block(xx,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "               eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "        xx = MaxPooling1D(pool_size=2)(xx)\n",
    "\n",
    "    #     xx = res_block(xx,128,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "    #            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    #     xx = res_block(xx,128,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "    #            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "\n",
    "    #     xx = res_block(xx,128,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "    #            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=False)\n",
    "    #     xx = res_block(xx,128,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "    #            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=False)\n",
    "\n",
    "        xx = Conv1D(64, kernel_size=kernel_size,\n",
    "                    kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                    padding=padding,\n",
    "                    strides=2,\n",
    "                    use_bias=bias,\n",
    "                    kernel_constraint=max_norm(maxnorm),\n",
    "                    trainable=trainable,\n",
    "                    kernel_regularizer=l2(l2_reg))(xx)\n",
    "        xx = MaxPooling1D(pool_size=2)(xx)\n",
    "        X.append(xx)\n",
    "    merged = Concatenate(axis=-1)([X[0], X[1]])\n",
    "    merged = Flatten()(merged)\n",
    "    merged = Dropout(rate=dropout_rate, seed=random_seed)(merged)\n",
    "    \n",
    "    \n",
    "    dann_in = GradientReversal(hp_lambda=hp_lambda,name='grl')(merged)\n",
    "    dsc = Dense(80,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'domain_dense')(dann_in)   \n",
    "    dsc = Dense(num_class_domain, activation='softmax', name = \"domain\")(dsc)          \n",
    "    merged = Dense(50,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(merged)\n",
    "    merged = Dense(num_class, activation='softmax', name=\"class\")(merged)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=[merged,dsc])\n",
    "    \n",
    "    if load_path:\n",
    "        model.load_weights(filepath=load_path, by_name=False)\n",
    "    \n",
    "    #if load_path:  # If path for loading model was specified\n",
    "    #model.load_weights(filepath='../../models_dbt_dann/fold_a_gt 2019-09-09 16:53:52.063276/weights.0041-0.6907.hdf5', by_name=True)\n",
    "    # models/fold_a_gt 2019-09-04 17:36:52.860817/weights.0200-0.7135.hdf5\n",
    "    \n",
    "    if optim=='Adam':\n",
    "        opt = Adam(lr=lr, decay=lr_decay)\n",
    "    else:  \n",
    "        opt = SGD(lr=lr,decay=lr_decay)\n",
    "    if(num_class_domain>1):\n",
    "        domain_loss_function = 'categorical_crossentropy'\n",
    "    else:\n",
    "        domain_loss_function = 'binary_crossentropy'\n",
    "    model.compile(optimizer=opt, loss={'class':'categorical_crossentropy','domain':domain_loss_function}, metrics=['accuracy'])\n",
    "    #model.compile(optimizer=opt, loss=['categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = heartnet(None,activation_function, bn_momentum, bias, dropout_rate, dropout_rate_dense,\n",
    "                             eps, kernel_size, l2_reg, l2_reg_dense, lr, lr_decay, maxnorm,\n",
    "                             padding, random_seed, subsam, num_filt, num_dense, FIR_train, trainable, tipe,\n",
    "                             num_class=num_class,num_class_domain=9,hp_lambda=hp_lambda,segments=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a387f4fc89dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'smallNetS1S2.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='smallNetS1S2.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 2496, 8)      40          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 2496, 8)      40          input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 2496, 8)      32          conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 2496, 8)      32          conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 2496, 8)      0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 2496, 8)      0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 2496, 8)      0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 2496, 8)      0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 2492, 16)     640         dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_67 (Conv1D)              (None, 2492, 16)     640         dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 2492, 16)     64          conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 2492, 16)     64          conv1d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 2492, 16)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 2492, 16)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 2492, 16)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 2492, 16)     0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 1246, 32)     2560        dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_68 (Conv1D)              (None, 1246, 32)     2560        dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1246, 32)     128         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1246, 32)     128         conv1d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1246, 32)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1246, 32)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 1246, 32)     0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1246, 32)     0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1246, 32)     5120        dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_69 (Conv1D)              (None, 1246, 32)     5120        dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1246, 32)     128         conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1246, 32)     128         conv1d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 1246, 32)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 1246, 16)     0           dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1246, 32)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 1246, 16)     0           dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 1246, 32)     0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1246, 32)     0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 1246, 32)     0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1246, 32)     0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1246, 32)     0           dropout_56[0][0]                 \n",
      "                                                                 lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1246, 32)     0           dropout_64[0][0]                 \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 623, 64)      10240       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 623, 64)      10240       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 623, 64)      256         conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 623, 64)      256         conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 623, 64)      0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 623, 64)      0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 623, 64)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 623, 64)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 623, 64)      20480       dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 623, 64)      20480       dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 623, 64)      256         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 623, 64)      256         conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 623, 64)      0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 623, 32)      0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 623, 64)      0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 623, 32)      0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 623, 64)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 623, 64)      0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 623, 64)      0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 623, 64)      0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 623, 64)      0           dropout_58[0][0]                 \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 623, 64)      0           dropout_66[0][0]                 \n",
      "                                                                 lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 311, 64)      0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 311, 64)      0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 154, 64)      20480       max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 154, 64)      20480       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 77, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 77, 64)       0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 77, 128)      0           max_pooling1d_28[0][0]           \n",
      "                                                                 max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 9856)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 9856)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "grl (GradientReversal)          (None, 9856)         0           dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "class_dense (Dense)             (None, 50)           492800      dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "domain_dense (Dense)            (None, 80)           788480      grl[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 2)            102         class_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "domain (Dense)                  (None, 9)            729         domain_dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,402,959\n",
      "Trainable params: 1,402,095\n",
      "Non-trainable params: 864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HeartSegNet import heartnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/mhealthra2/anaconda3/envs/tensor/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = heartnet(None,activation_function, bn_momentum, bias, dropout_rate, dropout_rate_dense,\n",
    "                             eps, kernel_size, l2_reg, l2_reg_dense, lr, lr_decay, maxnorm,\n",
    "                             padding, random_seed, subsam, num_filt, num_dense, FIR_train, trainable, tipe,\n",
    "                             num_class=num_class,num_class_domain=9,hp_lambda=hp_lambda,segments=channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del heartnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(heartnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
