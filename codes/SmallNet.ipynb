{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))\n",
    "# from clr_callback import CyclicLR\n",
    "# import dill\n",
    "from BalancedDannAudioDataGenerator import BalancedAudioDataGenerator\n",
    "import os,time\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import math\n",
    "import pandas as pd\n",
    "import tables,h5py\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "from keras.callbacks import TensorBoard, Callback, ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "from Heartnet import heartnet,getAttentionModel\n",
    "from utils import log_macc, results_log\n",
    "from dataLoader import reshape_folds\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import Evaluator\n",
    "import dataLoader\n",
    "from custom_layers import Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set()\n",
    "import tensorflow as tf\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_layers import Conv1D_zerophase_linear, Conv1D_linearphase, Conv1D_zerophase,\\\n",
    "    DCT1D, Conv1D_gammatone, Conv1D_linearphaseType, Attention\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Dense, Dropout, Flatten, Activation, AveragePooling1D, Add\n",
    "from keras import initializers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import max_norm\n",
    "from keras.optimizers import Adam, SGD # Nadam, Adamax\n",
    "import numpy as np\n",
    "import tables,h5py\n",
    "from Gradient_Reverse_Layer import GradientReversal\n",
    "from ResultAnalyser import Result\n",
    "from utils import Confused_Crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch(input_tensor,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable):\n",
    "\n",
    "    num_filt1, num_filt2 = num_filt\n",
    "    t = Conv1D(num_filt1, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(16, kernel_size=kernel_size,\n",
    "               kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "               padding=padding,\n",
    "               use_bias=bias,\n",
    "               trainable=trainable,\n",
    "               kernel_constraint=max_norm(maxnorm),\n",
    "               kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    # t = Flatten()(t)\n",
    "    return t\n",
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis=2)\n",
    "\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filt = (8, 4)\n",
    "num_dense = 20\n",
    "lr = 0.01\n",
    "bn_momentum = 0.99\n",
    "eps = 1.1e-5\n",
    "bias = False\n",
    "l2_reg = 0.04864911065093751\n",
    "l2_reg_dense = 0.\n",
    "kernel_size = 5\n",
    "maxnorm = 10000.\n",
    "dropout_rate = 0.5\n",
    "dropout_rate_dense = 0.\n",
    "padding = 'valid'\n",
    "activation_function = 'relu'\n",
    "subsam = 2\n",
    "FIR_train= True\n",
    "trainable = True\n",
    "hp_lambda = np.float32(0)\n",
    "lr_decay =0.0001132885\n",
    "random_seed = 1\n",
    "num_class =2\n",
    "num_class_domain = 18\n",
    "tipe= 1\n",
    "decision = 'majority' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(input_tensor,num_filt,kernel_size,stride,padding,random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=True):\n",
    "\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=stride,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(input_tensor)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    t = Conv1D(num_filt, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=1,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(t)\n",
    "    t = BatchNormalization(epsilon=eps, momentum=bn_momentum, axis=-1)(t)\n",
    "    t = Activation(activation_function)(t)\n",
    "    t = Dropout(rate=dropout_rate, seed=random_seed)(t)\n",
    "    \n",
    "    p = MaxPooling1D(pool_size=stride)(input_tensor)\n",
    "    if(stride>1):\n",
    "        if(cat):\n",
    "            p = Lambda(zeropad, output_shape=zeropad_output_shape)(p)\n",
    "    \n",
    "    t = Add()([t,p])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heartnet(load_path,activation_function='relu', bn_momentum=0.99, bias=False, dropout_rate=0.5, dropout_rate_dense=0.0,\n",
    "             eps=1.1e-5, kernel_size=5, l2_reg=0.0, l2_reg_dense=0.0,lr=0.0012843784, lr_decay=0.0001132885, maxnorm=10000.,\n",
    "             padding='valid', random_seed=1, subsam=2, num_filt=(8, 4), num_dense=20,FIR_train=False,trainable=True,type=1,\n",
    "             num_class=2, num_class_domain=1,hp_lambda=0,batch_size=1024,optim='SGD'):\n",
    "    \n",
    "    #num_dense = 20 default \n",
    "    input = Input(shape=(2500, 1))\n",
    "\n",
    "    \n",
    "    xx = branch(input,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    xx = branch(input,num_filt,kernel_size,random_seed,padding,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    xx = res_block(xx,32,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    xx = res_block(xx,64,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "           eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "    xx = MaxPooling1D(pool_size=2)(xx)\n",
    "    \n",
    "#     xx = res_block(xx,128,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "#     xx = res_block(xx,128,kernel_size,1,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable)\n",
    "    \n",
    "#     xx = res_block(xx,128,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=False)\n",
    "#     xx = res_block(xx,128,kernel_size,2,'same',random_seed,bias,maxnorm,l2_reg,\n",
    "#            eps,bn_momentum,activation_function,dropout_rate,subsam,trainable,cat=False)\n",
    "    \n",
    "    xx = Conv1D(128, kernel_size=kernel_size,\n",
    "                kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                padding=padding,\n",
    "                strides=2,\n",
    "                use_bias=bias,\n",
    "                kernel_constraint=max_norm(maxnorm),\n",
    "                trainable=trainable,\n",
    "                kernel_regularizer=l2(l2_reg))(xx)\n",
    "    xx = MaxPooling1D(pool_size=2)(xx)\n",
    "    merged = Flatten()(xx)\n",
    "    merged = Dropout(rate=dropout_rate, seed=random_seed)(merged)\n",
    "    \n",
    "    \n",
    "    dann_in = GradientReversal(hp_lambda=hp_lambda,name='grl')(merged)\n",
    "    dsc = Dense(80,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'domain_dense')(dann_in)   \n",
    "    dsc = Dense(num_class_domain, activation='softmax', name = \"domain\")(dsc)          \n",
    "    merged = Dense(50,\n",
    "                   activation=activation_function,\n",
    "                   kernel_initializer=initializers.he_normal(seed=random_seed),\n",
    "                   use_bias=bias,\n",
    "                   kernel_constraint=max_norm(maxnorm),\n",
    "                   kernel_regularizer=l2(l2_reg_dense),\n",
    "                   name = 'class_dense')(merged)\n",
    "    merged = Dense(num_class, activation='softmax', name=\"class\")(merged)\n",
    "    \n",
    "    model = Model(inputs=input, outputs=[merged,dsc])\n",
    "    \n",
    "    if load_path:\n",
    "        model.load_weights(filepath=load_path, by_name=False)\n",
    "    \n",
    "    #if load_path:  # If path for loading model was specified\n",
    "    #model.load_weights(filepath='../../models_dbt_dann/fold_a_gt 2019-09-09 16:53:52.063276/weights.0041-0.6907.hdf5', by_name=True)\n",
    "    # models/fold_a_gt 2019-09-04 17:36:52.860817/weights.0200-0.7135.hdf5\n",
    "    \n",
    "    if optim=='Adam':\n",
    "        opt = Adam(lr=lr, decay=lr_decay)\n",
    "    else:  \n",
    "        opt = SGD(lr=lr,decay=lr_decay)\n",
    "    model.compile(optimizer=opt, loss=['categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy'])\n",
    "    #model.compile(optimizer=opt, loss={'class':'categorical_crossentropy','domain':'categorical_crossentropy'}, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = heartnet(None,activation_function, bn_momentum, bias, dropout_rate, dropout_rate_dense,\n",
    "                             eps, kernel_size, l2_reg, l2_reg_dense, lr, lr_decay, maxnorm,\n",
    "                             padding, random_seed, subsam, num_filt, num_dense, FIR_train, trainable, tipe,\n",
    "                             num_class=num_class,num_class_domain=9,hp_lambda=hp_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='smallNet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 2500, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_176 (Conv1D)             (None, 2496, 8)      40          input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 2496, 8)      32          conv1d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 2496, 8)      0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 2496, 8)      0           activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_177 (Conv1D)             (None, 2492, 16)     640         dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 2492, 16)     64          conv1d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 2492, 16)     0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 2492, 16)     0           activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_178 (Conv1D)             (None, 1246, 32)     2560        dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 1246, 32)     128         conv1d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 1246, 32)     0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 1246, 32)     0           activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_179 (Conv1D)             (None, 1246, 32)     5120        dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 1246, 32)     128         conv1d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 1246, 32)     0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 1246, 16)     0           dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 1246, 32)     0           activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1246, 32)     0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 1246, 32)     0           dropout_173[0][0]                \n",
      "                                                                 lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_180 (Conv1D)             (None, 623, 64)      10240       add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 623, 64)      256         conv1d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 623, 64)      0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 623, 64)      0           activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_181 (Conv1D)             (None, 623, 64)      20480       dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 623, 64)      256         conv1d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 623, 64)      0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 623, 32)      0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 623, 64)      0           activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 623, 64)      0           max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 623, 64)      0           dropout_175[0][0]                \n",
      "                                                                 lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 311, 64)      0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_182 (Conv1D)             (None, 154, 128)     40960       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 77, 128)      0           conv1d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 9856)         0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 9856)         0           flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "grl (GradientReversal)          (None, 9856)         0           dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "class_dense (Dense)             (None, 50)           492800      dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "domain_dense (Dense)            (None, 80)           788480      grl[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 2)            102         class_dense[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "domain (Dense)                  (None, 9)            729         domain_dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,363,015\n",
      "Trainable params: 1,362,583\n",
      "Non-trainable params: 432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
